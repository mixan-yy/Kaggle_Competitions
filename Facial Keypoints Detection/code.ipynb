{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/training.csv')\n",
    "df_test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left_eye_center_x</th>\n",
       "      <th>left_eye_center_y</th>\n",
       "      <th>right_eye_center_x</th>\n",
       "      <th>right_eye_center_y</th>\n",
       "      <th>left_eye_inner_corner_x</th>\n",
       "      <th>left_eye_inner_corner_y</th>\n",
       "      <th>left_eye_outer_corner_x</th>\n",
       "      <th>left_eye_outer_corner_y</th>\n",
       "      <th>right_eye_inner_corner_x</th>\n",
       "      <th>right_eye_inner_corner_y</th>\n",
       "      <th>...</th>\n",
       "      <th>nose_tip_y</th>\n",
       "      <th>mouth_left_corner_x</th>\n",
       "      <th>mouth_left_corner_y</th>\n",
       "      <th>mouth_right_corner_x</th>\n",
       "      <th>mouth_right_corner_y</th>\n",
       "      <th>mouth_center_top_lip_x</th>\n",
       "      <th>mouth_center_top_lip_y</th>\n",
       "      <th>mouth_center_bottom_lip_x</th>\n",
       "      <th>mouth_center_bottom_lip_y</th>\n",
       "      <th>Image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66.033564</td>\n",
       "      <td>39.002274</td>\n",
       "      <td>30.227008</td>\n",
       "      <td>36.421678</td>\n",
       "      <td>59.582075</td>\n",
       "      <td>39.647423</td>\n",
       "      <td>73.130346</td>\n",
       "      <td>39.969997</td>\n",
       "      <td>36.356571</td>\n",
       "      <td>37.389402</td>\n",
       "      <td>...</td>\n",
       "      <td>57.066803</td>\n",
       "      <td>61.195308</td>\n",
       "      <td>79.970165</td>\n",
       "      <td>28.614496</td>\n",
       "      <td>77.388992</td>\n",
       "      <td>43.312602</td>\n",
       "      <td>72.935459</td>\n",
       "      <td>43.130707</td>\n",
       "      <td>84.485774</td>\n",
       "      <td>238 236 237 238 240 240 239 241 241 243 240 23...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   left_eye_center_x  left_eye_center_y  right_eye_center_x  \\\n",
       "0          66.033564          39.002274           30.227008   \n",
       "\n",
       "   right_eye_center_y  left_eye_inner_corner_x  left_eye_inner_corner_y  \\\n",
       "0           36.421678                59.582075                39.647423   \n",
       "\n",
       "   left_eye_outer_corner_x  left_eye_outer_corner_y  right_eye_inner_corner_x  \\\n",
       "0                73.130346                39.969997                 36.356571   \n",
       "\n",
       "   right_eye_inner_corner_y  ...  nose_tip_y  mouth_left_corner_x  \\\n",
       "0                 37.389402  ...   57.066803            61.195308   \n",
       "\n",
       "   mouth_left_corner_y  mouth_right_corner_x  mouth_right_corner_y  \\\n",
       "0            79.970165             28.614496             77.388992   \n",
       "\n",
       "   mouth_center_top_lip_x  mouth_center_top_lip_y  mouth_center_bottom_lip_x  \\\n",
       "0               43.312602               72.935459                  43.130707   \n",
       "\n",
       "   mouth_center_bottom_lip_y  \\\n",
       "0                  84.485774   \n",
       "\n",
       "                                               Image  \n",
       "0  238 236 237 238 240 240 239 241 241 243 240 23...  \n",
       "\n",
       "[1 rows x 31 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we have columns with many missing values\n",
    "#What we can do is fill the missing values with the mean of the column\n",
    "#by dropping the Image column\n",
    "lables_train = df_train.drop('Image', axis=1,)\n",
    "labels_test = df_test.drop('Image', axis=1, )\n",
    "\n",
    "#fillna\n",
    "lables_train.fillna(lables_train.mean(), inplace=True)\n",
    "labels_test.fillna(labels_test.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get image from the dataframe\n",
    "\n",
    "def get_image(Image:pd.Series):\n",
    "    images = []\n",
    "    for i in range(len(Image)):\n",
    "        img = Image[i].split(' ')\n",
    "        img = np.array(img, dtype=float).reshape(96,96)\n",
    "        images.append(img)\n",
    "    return np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_train = get_image(df_train['Image'])\n",
    "images_test = get_image(df_test['Image'])\n",
    "labels_train = lables_train.values\n",
    "labels_test = labels_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot figure function\n",
    "def plot_figure(img:np.array, keypoints: np.array):\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.scatter(keypoints[::2], keypoints[1::2], s=10, marker='*', c='r')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot a figure with the keypoints\n",
    "plot_figure(images_train[0], labels_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load necessary pytorch libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.Tensor(images_train).view(-1, 1, 96, 96)\n",
    "X_test = torch.Tensor(images_test).view(-1, 1, 96, 96)\n",
    "y_train = torch.Tensor(labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and test dataset\n",
    "train_set = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "test_set = torch.utils.data.TensorDataset(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and test dataloader\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=30, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load pretrained ResNet34\n",
    "import torchvision\n",
    "model = torchvision.models.resnet34(pretrained=True)\n",
    "#input channel is 1\n",
    "model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "#output layer gives 30 keypoints\n",
    "model.fc = nn.Linear(512, 30)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Step [2/111], Loss: 3.6462\n",
      "Epoch [1/100], Step [4/111], Loss: 3.6277\n",
      "Epoch [1/100], Step [6/111], Loss: 3.3084\n",
      "Epoch [1/100], Step [8/111], Loss: 2.0880\n",
      "Epoch [1/100], Step [10/111], Loss: 3.3071\n",
      "Epoch [1/100], Step [12/111], Loss: 6.6097\n",
      "Epoch [1/100], Step [14/111], Loss: 2.4291\n",
      "Epoch [1/100], Step [16/111], Loss: 2.3974\n",
      "Epoch [1/100], Step [18/111], Loss: 3.7344\n",
      "Epoch [1/100], Step [20/111], Loss: 2.0682\n",
      "Epoch [1/100], Step [22/111], Loss: 2.7171\n",
      "Epoch [1/100], Step [24/111], Loss: 4.2108\n",
      "Epoch [1/100], Step [26/111], Loss: 2.3788\n",
      "Epoch [1/100], Step [28/111], Loss: 2.7452\n",
      "Epoch [1/100], Step [30/111], Loss: 1.8373\n",
      "Epoch [1/100], Step [32/111], Loss: 2.0971\n",
      "Epoch [1/100], Step [34/111], Loss: 2.8345\n",
      "Epoch [1/100], Step [36/111], Loss: 2.0078\n",
      "Epoch [1/100], Step [38/111], Loss: 2.4825\n",
      "Epoch [1/100], Step [40/111], Loss: 2.1837\n",
      "Epoch [1/100], Step [42/111], Loss: 5.6119\n",
      "Epoch [1/100], Step [44/111], Loss: 2.5889\n",
      "Epoch [1/100], Step [46/111], Loss: 3.3755\n",
      "Epoch [1/100], Step [48/111], Loss: 2.1522\n",
      "Epoch [1/100], Step [50/111], Loss: 2.1328\n",
      "Epoch [1/100], Step [52/111], Loss: 1.8313\n",
      "Epoch [1/100], Step [54/111], Loss: 11.8437\n",
      "Epoch [1/100], Step [56/111], Loss: 2.2985\n",
      "Epoch [1/100], Step [58/111], Loss: 3.3307\n",
      "Epoch [1/100], Step [60/111], Loss: 2.3296\n",
      "Epoch [1/100], Step [62/111], Loss: 7.4815\n",
      "Epoch [1/100], Step [64/111], Loss: 2.1117\n",
      "Epoch [1/100], Step [66/111], Loss: 2.4415\n",
      "Epoch [1/100], Step [68/111], Loss: 2.0024\n",
      "Epoch [1/100], Step [70/111], Loss: 2.8353\n",
      "Epoch [1/100], Step [72/111], Loss: 2.1576\n",
      "Epoch [1/100], Step [74/111], Loss: 2.3660\n",
      "Epoch [1/100], Step [76/111], Loss: 2.0141\n",
      "Epoch [1/100], Step [78/111], Loss: 2.7591\n",
      "Epoch [1/100], Step [80/111], Loss: 1.9876\n",
      "Epoch [1/100], Step [82/111], Loss: 1.6142\n",
      "Epoch [1/100], Step [84/111], Loss: 2.1939\n",
      "Epoch [1/100], Step [86/111], Loss: 1.9110\n",
      "Epoch [1/100], Step [88/111], Loss: 7.4663\n",
      "Epoch [1/100], Step [90/111], Loss: 2.6833\n",
      "Epoch [1/100], Step [92/111], Loss: 2.5985\n",
      "Epoch [1/100], Step [94/111], Loss: 2.6621\n",
      "Epoch [1/100], Step [96/111], Loss: 1.9431\n",
      "Epoch [1/100], Step [98/111], Loss: 1.6784\n",
      "Epoch [1/100], Step [100/111], Loss: 2.0238\n",
      "Epoch [1/100], Step [102/111], Loss: 2.0080\n",
      "Epoch [1/100], Step [104/111], Loss: 2.4464\n",
      "Epoch [1/100], Step [106/111], Loss: 2.6269\n",
      "Epoch [1/100], Step [108/111], Loss: 2.3871\n",
      "Epoch [1/100], Step [110/111], Loss: 1.8379\n",
      "Epoch [2/100], Step [2/111], Loss: 6.3329\n",
      "Epoch [2/100], Step [4/111], Loss: 2.3140\n",
      "Epoch [2/100], Step [6/111], Loss: 3.2783\n",
      "Epoch [2/100], Step [8/111], Loss: 2.9955\n",
      "Epoch [2/100], Step [10/111], Loss: 2.8667\n",
      "Epoch [2/100], Step [12/111], Loss: 2.2327\n",
      "Epoch [2/100], Step [14/111], Loss: 2.5253\n",
      "Epoch [2/100], Step [16/111], Loss: 1.8866\n",
      "Epoch [2/100], Step [18/111], Loss: 2.4624\n",
      "Epoch [2/100], Step [20/111], Loss: 2.6406\n",
      "Epoch [2/100], Step [22/111], Loss: 7.3745\n",
      "Epoch [2/100], Step [24/111], Loss: 1.7964\n",
      "Epoch [2/100], Step [26/111], Loss: 1.8147\n",
      "Epoch [2/100], Step [28/111], Loss: 1.4869\n",
      "Epoch [2/100], Step [30/111], Loss: 2.2961\n",
      "Epoch [2/100], Step [32/111], Loss: 2.3970\n",
      "Epoch [2/100], Step [34/111], Loss: 2.1930\n",
      "Epoch [2/100], Step [36/111], Loss: 2.3161\n",
      "Epoch [2/100], Step [38/111], Loss: 1.9444\n",
      "Epoch [2/100], Step [40/111], Loss: 1.3161\n",
      "Epoch [2/100], Step [42/111], Loss: 2.3772\n",
      "Epoch [2/100], Step [44/111], Loss: 3.2485\n",
      "Epoch [2/100], Step [46/111], Loss: 1.5198\n",
      "Epoch [2/100], Step [48/111], Loss: 1.9620\n",
      "Epoch [2/100], Step [50/111], Loss: 2.1379\n",
      "Epoch [2/100], Step [52/111], Loss: 1.5203\n",
      "Epoch [2/100], Step [54/111], Loss: 1.7063\n",
      "Epoch [2/100], Step [56/111], Loss: 2.8777\n",
      "Epoch [2/100], Step [58/111], Loss: 1.5307\n",
      "Epoch [2/100], Step [60/111], Loss: 1.9799\n",
      "Epoch [2/100], Step [62/111], Loss: 2.9284\n",
      "Epoch [2/100], Step [64/111], Loss: 1.8439\n",
      "Epoch [2/100], Step [66/111], Loss: 4.0842\n",
      "Epoch [2/100], Step [68/111], Loss: 1.8949\n",
      "Epoch [2/100], Step [70/111], Loss: 1.8722\n",
      "Epoch [2/100], Step [72/111], Loss: 2.7693\n",
      "Epoch [2/100], Step [74/111], Loss: 3.0446\n",
      "Epoch [2/100], Step [76/111], Loss: 6.5444\n",
      "Epoch [2/100], Step [78/111], Loss: 2.2666\n",
      "Epoch [2/100], Step [80/111], Loss: 1.7193\n",
      "Epoch [2/100], Step [82/111], Loss: 1.6210\n",
      "Epoch [2/100], Step [84/111], Loss: 1.8315\n",
      "Epoch [2/100], Step [86/111], Loss: 1.5959\n",
      "Epoch [2/100], Step [88/111], Loss: 4.5460\n",
      "Epoch [2/100], Step [90/111], Loss: 1.8479\n",
      "Epoch [2/100], Step [92/111], Loss: 1.7960\n",
      "Epoch [2/100], Step [94/111], Loss: 2.6584\n",
      "Epoch [2/100], Step [96/111], Loss: 1.8531\n",
      "Epoch [2/100], Step [98/111], Loss: 3.6818\n",
      "Epoch [2/100], Step [100/111], Loss: 1.3116\n",
      "Epoch [2/100], Step [102/111], Loss: 2.0439\n",
      "Epoch [2/100], Step [104/111], Loss: 2.6550\n",
      "Epoch [2/100], Step [106/111], Loss: 2.0120\n",
      "Epoch [2/100], Step [108/111], Loss: 2.4165\n",
      "Epoch [2/100], Step [110/111], Loss: 1.9645\n",
      "Epoch [3/100], Step [2/111], Loss: 1.8900\n",
      "Epoch [3/100], Step [4/111], Loss: 1.8588\n",
      "Epoch [3/100], Step [6/111], Loss: 4.7472\n",
      "Epoch [3/100], Step [8/111], Loss: 2.3809\n",
      "Epoch [3/100], Step [10/111], Loss: 5.3461\n",
      "Epoch [3/100], Step [12/111], Loss: 3.0229\n",
      "Epoch [3/100], Step [14/111], Loss: 3.0624\n",
      "Epoch [3/100], Step [16/111], Loss: 2.1178\n",
      "Epoch [3/100], Step [18/111], Loss: 1.7096\n",
      "Epoch [3/100], Step [20/111], Loss: 2.4357\n",
      "Epoch [3/100], Step [22/111], Loss: 1.6563\n",
      "Epoch [3/100], Step [24/111], Loss: 2.2692\n",
      "Epoch [3/100], Step [26/111], Loss: 1.7514\n",
      "Epoch [3/100], Step [28/111], Loss: 1.7041\n",
      "Epoch [3/100], Step [30/111], Loss: 2.0491\n",
      "Epoch [3/100], Step [32/111], Loss: 1.6583\n",
      "Epoch [3/100], Step [34/111], Loss: 2.8642\n",
      "Epoch [3/100], Step [36/111], Loss: 1.9608\n",
      "Epoch [3/100], Step [38/111], Loss: 1.9968\n",
      "Epoch [3/100], Step [40/111], Loss: 2.7442\n",
      "Epoch [3/100], Step [42/111], Loss: 1.7265\n",
      "Epoch [3/100], Step [44/111], Loss: 2.0728\n",
      "Epoch [3/100], Step [46/111], Loss: 2.1329\n",
      "Epoch [3/100], Step [48/111], Loss: 4.5931\n",
      "Epoch [3/100], Step [50/111], Loss: 3.5489\n",
      "Epoch [3/100], Step [52/111], Loss: 1.6992\n",
      "Epoch [3/100], Step [54/111], Loss: 1.4382\n",
      "Epoch [3/100], Step [56/111], Loss: 1.8863\n",
      "Epoch [3/100], Step [58/111], Loss: 2.6960\n",
      "Epoch [3/100], Step [60/111], Loss: 2.0630\n",
      "Epoch [3/100], Step [62/111], Loss: 1.8786\n",
      "Epoch [3/100], Step [64/111], Loss: 1.6315\n",
      "Epoch [3/100], Step [66/111], Loss: 2.0794\n",
      "Epoch [3/100], Step [68/111], Loss: 1.9775\n",
      "Epoch [3/100], Step [70/111], Loss: 1.9017\n",
      "Epoch [3/100], Step [72/111], Loss: 2.2442\n",
      "Epoch [3/100], Step [74/111], Loss: 2.0138\n",
      "Epoch [3/100], Step [76/111], Loss: 6.8142\n",
      "Epoch [3/100], Step [78/111], Loss: 2.4554\n",
      "Epoch [3/100], Step [80/111], Loss: 2.1721\n",
      "Epoch [3/100], Step [82/111], Loss: 1.9862\n",
      "Epoch [3/100], Step [84/111], Loss: 1.4029\n",
      "Epoch [3/100], Step [86/111], Loss: 1.5749\n",
      "Epoch [3/100], Step [88/111], Loss: 2.0061\n",
      "Epoch [3/100], Step [90/111], Loss: 1.6612\n",
      "Epoch [3/100], Step [92/111], Loss: 1.4192\n",
      "Epoch [3/100], Step [94/111], Loss: 1.5123\n",
      "Epoch [3/100], Step [96/111], Loss: 2.2535\n",
      "Epoch [3/100], Step [98/111], Loss: 2.1263\n",
      "Epoch [3/100], Step [100/111], Loss: 1.3079\n",
      "Epoch [3/100], Step [102/111], Loss: 1.6131\n",
      "Epoch [3/100], Step [104/111], Loss: 3.4514\n",
      "Epoch [3/100], Step [106/111], Loss: 2.4386\n",
      "Epoch [3/100], Step [108/111], Loss: 2.8675\n",
      "Epoch [3/100], Step [110/111], Loss: 1.5391\n",
      "Epoch [4/100], Step [2/111], Loss: 1.8993\n",
      "Epoch [4/100], Step [4/111], Loss: 2.0909\n",
      "Epoch [4/100], Step [6/111], Loss: 1.7255\n",
      "Epoch [4/100], Step [8/111], Loss: 1.4670\n",
      "Epoch [4/100], Step [10/111], Loss: 1.4218\n",
      "Epoch [4/100], Step [12/111], Loss: 1.3077\n",
      "Epoch [4/100], Step [14/111], Loss: 1.8137\n",
      "Epoch [4/100], Step [16/111], Loss: 2.6460\n",
      "Epoch [4/100], Step [18/111], Loss: 2.0241\n",
      "Epoch [4/100], Step [20/111], Loss: 1.8559\n",
      "Epoch [4/100], Step [22/111], Loss: 1.8957\n",
      "Epoch [4/100], Step [24/111], Loss: 1.8466\n",
      "Epoch [4/100], Step [26/111], Loss: 2.0408\n",
      "Epoch [4/100], Step [28/111], Loss: 1.2293\n",
      "Epoch [4/100], Step [30/111], Loss: 1.5422\n",
      "Epoch [4/100], Step [32/111], Loss: 7.0290\n",
      "Epoch [4/100], Step [34/111], Loss: 1.9989\n",
      "Epoch [4/100], Step [36/111], Loss: 2.8187\n",
      "Epoch [4/100], Step [38/111], Loss: 1.4338\n",
      "Epoch [4/100], Step [40/111], Loss: 2.6603\n",
      "Epoch [4/100], Step [42/111], Loss: 1.6083\n",
      "Epoch [4/100], Step [44/111], Loss: 1.8620\n",
      "Epoch [4/100], Step [46/111], Loss: 1.7887\n",
      "Epoch [4/100], Step [48/111], Loss: 2.3279\n",
      "Epoch [4/100], Step [50/111], Loss: 1.5161\n",
      "Epoch [4/100], Step [52/111], Loss: 1.5863\n",
      "Epoch [4/100], Step [54/111], Loss: 2.7728\n",
      "Epoch [4/100], Step [56/111], Loss: 1.7944\n",
      "Epoch [4/100], Step [58/111], Loss: 1.3785\n",
      "Epoch [4/100], Step [60/111], Loss: 5.5250\n",
      "Epoch [4/100], Step [62/111], Loss: 10.1459\n",
      "Epoch [4/100], Step [64/111], Loss: 1.3048\n",
      "Epoch [4/100], Step [66/111], Loss: 3.8083\n",
      "Epoch [4/100], Step [68/111], Loss: 2.8103\n",
      "Epoch [4/100], Step [70/111], Loss: 1.5256\n",
      "Epoch [4/100], Step [72/111], Loss: 3.4704\n",
      "Epoch [4/100], Step [74/111], Loss: 1.7440\n",
      "Epoch [4/100], Step [76/111], Loss: 1.9866\n",
      "Epoch [4/100], Step [78/111], Loss: 1.4900\n",
      "Epoch [4/100], Step [80/111], Loss: 1.4322\n",
      "Epoch [4/100], Step [82/111], Loss: 1.2932\n",
      "Epoch [4/100], Step [84/111], Loss: 1.5162\n",
      "Epoch [4/100], Step [86/111], Loss: 2.9993\n",
      "Epoch [4/100], Step [88/111], Loss: 3.3805\n",
      "Epoch [4/100], Step [90/111], Loss: 1.3109\n",
      "Epoch [4/100], Step [92/111], Loss: 2.0219\n",
      "Epoch [4/100], Step [94/111], Loss: 1.9064\n",
      "Epoch [4/100], Step [96/111], Loss: 1.8840\n",
      "Epoch [4/100], Step [98/111], Loss: 2.6590\n",
      "Epoch [4/100], Step [100/111], Loss: 1.9635\n",
      "Epoch [4/100], Step [102/111], Loss: 2.7549\n",
      "Epoch [4/100], Step [104/111], Loss: 1.4112\n",
      "Epoch [4/100], Step [106/111], Loss: 1.9981\n",
      "Epoch [4/100], Step [108/111], Loss: 8.1820\n",
      "Epoch [4/100], Step [110/111], Loss: 1.5951\n",
      "Epoch [5/100], Step [2/111], Loss: 1.5537\n",
      "Epoch [5/100], Step [4/111], Loss: 1.4819\n",
      "Epoch [5/100], Step [6/111], Loss: 2.1697\n",
      "Epoch [5/100], Step [8/111], Loss: 2.1669\n",
      "Epoch [5/100], Step [10/111], Loss: 1.6760\n",
      "Epoch [5/100], Step [12/111], Loss: 1.1585\n",
      "Epoch [5/100], Step [14/111], Loss: 3.3247\n",
      "Epoch [5/100], Step [16/111], Loss: 1.7216\n",
      "Epoch [5/100], Step [18/111], Loss: 4.3043\n",
      "Epoch [5/100], Step [20/111], Loss: 1.7893\n",
      "Epoch [5/100], Step [22/111], Loss: 1.3850\n",
      "Epoch [5/100], Step [24/111], Loss: 1.9508\n",
      "Epoch [5/100], Step [26/111], Loss: 1.9478\n",
      "Epoch [5/100], Step [28/111], Loss: 1.8911\n",
      "Epoch [5/100], Step [30/111], Loss: 1.0333\n",
      "Epoch [5/100], Step [32/111], Loss: 1.1182\n",
      "Epoch [5/100], Step [34/111], Loss: 2.7396\n",
      "Epoch [5/100], Step [36/111], Loss: 1.3055\n",
      "Epoch [5/100], Step [38/111], Loss: 1.1508\n",
      "Epoch [5/100], Step [40/111], Loss: 1.5492\n",
      "Epoch [5/100], Step [42/111], Loss: 2.5489\n",
      "Epoch [5/100], Step [44/111], Loss: 1.2712\n",
      "Epoch [5/100], Step [46/111], Loss: 1.2977\n",
      "Epoch [5/100], Step [48/111], Loss: 1.4246\n",
      "Epoch [5/100], Step [50/111], Loss: 1.2879\n",
      "Epoch [5/100], Step [52/111], Loss: 1.7322\n",
      "Epoch [5/100], Step [54/111], Loss: 1.2405\n",
      "Epoch [5/100], Step [56/111], Loss: 1.4996\n",
      "Epoch [5/100], Step [58/111], Loss: 1.2052\n",
      "Epoch [5/100], Step [60/111], Loss: 1.9561\n",
      "Epoch [5/100], Step [62/111], Loss: 1.2573\n",
      "Epoch [5/100], Step [64/111], Loss: 1.3673\n",
      "Epoch [5/100], Step [66/111], Loss: 1.2652\n",
      "Epoch [5/100], Step [68/111], Loss: 5.8612\n",
      "Epoch [5/100], Step [70/111], Loss: 1.2663\n",
      "Epoch [5/100], Step [72/111], Loss: 1.7673\n",
      "Epoch [5/100], Step [74/111], Loss: 1.6850\n",
      "Epoch [5/100], Step [76/111], Loss: 3.3956\n",
      "Epoch [5/100], Step [78/111], Loss: 1.0862\n",
      "Epoch [5/100], Step [80/111], Loss: 2.3551\n",
      "Epoch [5/100], Step [82/111], Loss: 1.1199\n",
      "Epoch [5/100], Step [84/111], Loss: 1.5680\n",
      "Epoch [5/100], Step [86/111], Loss: 1.3445\n",
      "Epoch [5/100], Step [88/111], Loss: 1.7233\n",
      "Epoch [5/100], Step [90/111], Loss: 2.2318\n",
      "Epoch [5/100], Step [92/111], Loss: 1.5103\n",
      "Epoch [5/100], Step [94/111], Loss: 1.5196\n",
      "Epoch [5/100], Step [96/111], Loss: 2.0088\n",
      "Epoch [5/100], Step [98/111], Loss: 1.3587\n",
      "Epoch [5/100], Step [100/111], Loss: 1.7407\n",
      "Epoch [5/100], Step [102/111], Loss: 1.3801\n",
      "Epoch [5/100], Step [104/111], Loss: 1.7530\n",
      "Epoch [5/100], Step [106/111], Loss: 1.3901\n",
      "Epoch [5/100], Step [108/111], Loss: 1.5968\n",
      "Epoch [5/100], Step [110/111], Loss: 2.4363\n",
      "Epoch [6/100], Step [2/111], Loss: 1.1937\n",
      "Epoch [6/100], Step [4/111], Loss: 1.3511\n",
      "Epoch [6/100], Step [6/111], Loss: 1.6917\n",
      "Epoch [6/100], Step [8/111], Loss: 1.1585\n",
      "Epoch [6/100], Step [10/111], Loss: 1.9432\n",
      "Epoch [6/100], Step [12/111], Loss: 1.5905\n",
      "Epoch [6/100], Step [14/111], Loss: 1.7432\n",
      "Epoch [6/100], Step [16/111], Loss: 1.1721\n",
      "Epoch [6/100], Step [18/111], Loss: 3.3931\n",
      "Epoch [6/100], Step [20/111], Loss: 1.3081\n",
      "Epoch [6/100], Step [22/111], Loss: 2.5379\n",
      "Epoch [6/100], Step [24/111], Loss: 1.2767\n",
      "Epoch [6/100], Step [26/111], Loss: 1.5785\n",
      "Epoch [6/100], Step [28/111], Loss: 1.5927\n",
      "Epoch [6/100], Step [30/111], Loss: 6.1481\n",
      "Epoch [6/100], Step [32/111], Loss: 1.4492\n",
      "Epoch [6/100], Step [34/111], Loss: 1.2317\n",
      "Epoch [6/100], Step [36/111], Loss: 1.9317\n",
      "Epoch [6/100], Step [38/111], Loss: 1.1097\n",
      "Epoch [6/100], Step [40/111], Loss: 1.3450\n",
      "Epoch [6/100], Step [42/111], Loss: 1.0863\n",
      "Epoch [6/100], Step [44/111], Loss: 1.6495\n",
      "Epoch [6/100], Step [46/111], Loss: 0.9187\n",
      "Epoch [6/100], Step [48/111], Loss: 1.2801\n",
      "Epoch [6/100], Step [50/111], Loss: 1.1928\n",
      "Epoch [6/100], Step [52/111], Loss: 3.5514\n",
      "Epoch [6/100], Step [54/111], Loss: 2.1393\n",
      "Epoch [6/100], Step [56/111], Loss: 1.0332\n",
      "Epoch [6/100], Step [58/111], Loss: 1.2612\n",
      "Epoch [6/100], Step [60/111], Loss: 1.0995\n",
      "Epoch [6/100], Step [62/111], Loss: 1.5137\n",
      "Epoch [6/100], Step [64/111], Loss: 1.9209\n",
      "Epoch [6/100], Step [66/111], Loss: 2.1312\n",
      "Epoch [6/100], Step [68/111], Loss: 2.0733\n",
      "Epoch [6/100], Step [70/111], Loss: 2.8839\n",
      "Epoch [6/100], Step [72/111], Loss: 1.6022\n",
      "Epoch [6/100], Step [74/111], Loss: 1.1506\n",
      "Epoch [6/100], Step [76/111], Loss: 1.4167\n",
      "Epoch [6/100], Step [78/111], Loss: 1.1617\n",
      "Epoch [6/100], Step [80/111], Loss: 1.0792\n",
      "Epoch [6/100], Step [82/111], Loss: 1.7038\n",
      "Epoch [6/100], Step [84/111], Loss: 1.2232\n",
      "Epoch [6/100], Step [86/111], Loss: 1.9102\n",
      "Epoch [6/100], Step [88/111], Loss: 1.0350\n",
      "Epoch [6/100], Step [90/111], Loss: 1.4682\n",
      "Epoch [6/100], Step [92/111], Loss: 1.1610\n",
      "Epoch [6/100], Step [94/111], Loss: 3.1117\n",
      "Epoch [6/100], Step [96/111], Loss: 1.3495\n",
      "Epoch [6/100], Step [98/111], Loss: 1.1654\n",
      "Epoch [6/100], Step [100/111], Loss: 2.8554\n",
      "Epoch [6/100], Step [102/111], Loss: 1.1379\n",
      "Epoch [6/100], Step [104/111], Loss: 1.0210\n",
      "Epoch [6/100], Step [106/111], Loss: 1.4372\n",
      "Epoch [6/100], Step [108/111], Loss: 1.2077\n",
      "Epoch [6/100], Step [110/111], Loss: 8.2080\n",
      "Epoch [7/100], Step [2/111], Loss: 2.1587\n",
      "Epoch [7/100], Step [4/111], Loss: 1.3694\n",
      "Epoch [7/100], Step [6/111], Loss: 2.0417\n",
      "Epoch [7/100], Step [8/111], Loss: 3.2956\n",
      "Epoch [7/100], Step [10/111], Loss: 1.2318\n",
      "Epoch [7/100], Step [12/111], Loss: 1.3465\n",
      "Epoch [7/100], Step [14/111], Loss: 1.5547\n",
      "Epoch [7/100], Step [16/111], Loss: 1.5466\n",
      "Epoch [7/100], Step [18/111], Loss: 1.8820\n",
      "Epoch [7/100], Step [20/111], Loss: 1.5939\n",
      "Epoch [7/100], Step [22/111], Loss: 2.2825\n",
      "Epoch [7/100], Step [24/111], Loss: 1.3117\n",
      "Epoch [7/100], Step [26/111], Loss: 1.2727\n",
      "Epoch [7/100], Step [28/111], Loss: 1.8735\n",
      "Epoch [7/100], Step [30/111], Loss: 1.9005\n",
      "Epoch [7/100], Step [32/111], Loss: 1.2106\n",
      "Epoch [7/100], Step [34/111], Loss: 1.8904\n",
      "Epoch [7/100], Step [36/111], Loss: 0.9384\n",
      "Epoch [7/100], Step [38/111], Loss: 2.0752\n",
      "Epoch [7/100], Step [40/111], Loss: 4.7727\n",
      "Epoch [7/100], Step [42/111], Loss: 1.5126\n",
      "Epoch [7/100], Step [44/111], Loss: 1.2920\n",
      "Epoch [7/100], Step [46/111], Loss: 2.1049\n",
      "Epoch [7/100], Step [48/111], Loss: 1.2448\n",
      "Epoch [7/100], Step [50/111], Loss: 1.6305\n",
      "Epoch [7/100], Step [52/111], Loss: 1.0959\n",
      "Epoch [7/100], Step [54/111], Loss: 1.0764\n",
      "Epoch [7/100], Step [56/111], Loss: 1.0352\n",
      "Epoch [7/100], Step [58/111], Loss: 2.3548\n",
      "Epoch [7/100], Step [60/111], Loss: 1.4749\n",
      "Epoch [7/100], Step [62/111], Loss: 1.1385\n",
      "Epoch [7/100], Step [64/111], Loss: 1.8501\n",
      "Epoch [7/100], Step [66/111], Loss: 1.8490\n",
      "Epoch [7/100], Step [68/111], Loss: 0.9380\n",
      "Epoch [7/100], Step [70/111], Loss: 0.9346\n",
      "Epoch [7/100], Step [72/111], Loss: 1.3167\n",
      "Epoch [7/100], Step [74/111], Loss: 1.0627\n",
      "Epoch [7/100], Step [76/111], Loss: 1.0630\n",
      "Epoch [7/100], Step [78/111], Loss: 1.1216\n",
      "Epoch [7/100], Step [80/111], Loss: 6.2988\n",
      "Epoch [7/100], Step [82/111], Loss: 1.3301\n",
      "Epoch [7/100], Step [84/111], Loss: 1.3586\n",
      "Epoch [7/100], Step [86/111], Loss: 1.0757\n",
      "Epoch [7/100], Step [88/111], Loss: 2.8735\n",
      "Epoch [7/100], Step [90/111], Loss: 1.1809\n",
      "Epoch [7/100], Step [92/111], Loss: 0.9390\n",
      "Epoch [7/100], Step [94/111], Loss: 1.1645\n",
      "Epoch [7/100], Step [96/111], Loss: 1.1612\n",
      "Epoch [7/100], Step [98/111], Loss: 1.1706\n",
      "Epoch [7/100], Step [100/111], Loss: 1.7865\n",
      "Epoch [7/100], Step [102/111], Loss: 0.9788\n",
      "Epoch [7/100], Step [104/111], Loss: 1.0824\n",
      "Epoch [7/100], Step [106/111], Loss: 1.3226\n",
      "Epoch [7/100], Step [108/111], Loss: 1.0608\n",
      "Epoch [7/100], Step [110/111], Loss: 1.1499\n",
      "Epoch [8/100], Step [2/111], Loss: 2.2396\n",
      "Epoch [8/100], Step [4/111], Loss: 2.4100\n",
      "Epoch [8/100], Step [6/111], Loss: 1.9968\n",
      "Epoch [8/100], Step [8/111], Loss: 1.4933\n",
      "Epoch [8/100], Step [10/111], Loss: 1.5372\n",
      "Epoch [8/100], Step [12/111], Loss: 1.1821\n",
      "Epoch [8/100], Step [14/111], Loss: 1.5278\n",
      "Epoch [8/100], Step [16/111], Loss: 1.4535\n",
      "Epoch [8/100], Step [18/111], Loss: 1.8472\n",
      "Epoch [8/100], Step [20/111], Loss: 1.6089\n",
      "Epoch [8/100], Step [22/111], Loss: 1.8285\n",
      "Epoch [8/100], Step [24/111], Loss: 2.4840\n",
      "Epoch [8/100], Step [26/111], Loss: 3.7058\n",
      "Epoch [8/100], Step [28/111], Loss: 1.2882\n",
      "Epoch [8/100], Step [30/111], Loss: 2.1133\n",
      "Epoch [8/100], Step [32/111], Loss: 1.4423\n",
      "Epoch [8/100], Step [34/111], Loss: 1.5184\n",
      "Epoch [8/100], Step [36/111], Loss: 2.5711\n",
      "Epoch [8/100], Step [38/111], Loss: 1.2667\n",
      "Epoch [8/100], Step [40/111], Loss: 1.8602\n",
      "Epoch [8/100], Step [42/111], Loss: 1.1869\n",
      "Epoch [8/100], Step [44/111], Loss: 1.2392\n",
      "Epoch [8/100], Step [46/111], Loss: 1.1953\n",
      "Epoch [8/100], Step [48/111], Loss: 1.4765\n",
      "Epoch [8/100], Step [50/111], Loss: 1.5804\n",
      "Epoch [8/100], Step [52/111], Loss: 11.2918\n",
      "Epoch [8/100], Step [54/111], Loss: 1.6150\n",
      "Epoch [8/100], Step [56/111], Loss: 1.5366\n",
      "Epoch [8/100], Step [58/111], Loss: 1.3943\n",
      "Epoch [8/100], Step [60/111], Loss: 2.0426\n",
      "Epoch [8/100], Step [62/111], Loss: 1.6482\n",
      "Epoch [8/100], Step [64/111], Loss: 1.1603\n",
      "Epoch [8/100], Step [66/111], Loss: 1.3513\n",
      "Epoch [8/100], Step [68/111], Loss: 1.3275\n",
      "Epoch [8/100], Step [70/111], Loss: 1.8508\n",
      "Epoch [8/100], Step [72/111], Loss: 1.6056\n",
      "Epoch [8/100], Step [74/111], Loss: 1.4736\n",
      "Epoch [8/100], Step [76/111], Loss: 1.7372\n",
      "Epoch [8/100], Step [78/111], Loss: 1.1476\n",
      "Epoch [8/100], Step [80/111], Loss: 1.5037\n",
      "Epoch [8/100], Step [82/111], Loss: 1.2991\n",
      "Epoch [8/100], Step [84/111], Loss: 1.2187\n",
      "Epoch [8/100], Step [86/111], Loss: 1.4810\n",
      "Epoch [8/100], Step [88/111], Loss: 2.1829\n",
      "Epoch [8/100], Step [90/111], Loss: 1.5352\n",
      "Epoch [8/100], Step [92/111], Loss: 4.3717\n",
      "Epoch [8/100], Step [94/111], Loss: 1.9292\n",
      "Epoch [8/100], Step [96/111], Loss: 2.0796\n",
      "Epoch [8/100], Step [98/111], Loss: 1.5937\n",
      "Epoch [8/100], Step [100/111], Loss: 1.6486\n",
      "Epoch [8/100], Step [102/111], Loss: 1.9620\n",
      "Epoch [8/100], Step [104/111], Loss: 1.2575\n",
      "Epoch [8/100], Step [106/111], Loss: 1.4220\n",
      "Epoch [8/100], Step [108/111], Loss: 1.7520\n",
      "Epoch [8/100], Step [110/111], Loss: 1.2997\n",
      "Epoch [9/100], Step [2/111], Loss: 2.1649\n",
      "Epoch [9/100], Step [4/111], Loss: 2.2514\n",
      "Epoch [9/100], Step [6/111], Loss: 3.0026\n",
      "Epoch [9/100], Step [8/111], Loss: 9.0410\n",
      "Epoch [9/100], Step [10/111], Loss: 2.4801\n",
      "Epoch [9/100], Step [12/111], Loss: 1.7244\n",
      "Epoch [9/100], Step [14/111], Loss: 2.6692\n",
      "Epoch [9/100], Step [16/111], Loss: 1.5633\n",
      "Epoch [9/100], Step [18/111], Loss: 1.5178\n",
      "Epoch [9/100], Step [20/111], Loss: 1.3025\n",
      "Epoch [9/100], Step [22/111], Loss: 0.9339\n",
      "Epoch [9/100], Step [24/111], Loss: 1.0514\n",
      "Epoch [9/100], Step [26/111], Loss: 1.3381\n",
      "Epoch [9/100], Step [28/111], Loss: 1.5720\n",
      "Epoch [9/100], Step [30/111], Loss: 1.4978\n",
      "Epoch [9/100], Step [32/111], Loss: 1.7058\n",
      "Epoch [9/100], Step [34/111], Loss: 1.9644\n",
      "Epoch [9/100], Step [36/111], Loss: 1.2891\n",
      "Epoch [9/100], Step [38/111], Loss: 2.2557\n",
      "Epoch [9/100], Step [40/111], Loss: 1.1472\n",
      "Epoch [9/100], Step [42/111], Loss: 2.1362\n",
      "Epoch [9/100], Step [44/111], Loss: 2.3993\n",
      "Epoch [9/100], Step [46/111], Loss: 1.0916\n",
      "Epoch [9/100], Step [48/111], Loss: 1.4976\n",
      "Epoch [9/100], Step [50/111], Loss: 1.2096\n",
      "Epoch [9/100], Step [52/111], Loss: 1.6521\n",
      "Epoch [9/100], Step [54/111], Loss: 1.1035\n",
      "Epoch [9/100], Step [56/111], Loss: 1.4912\n",
      "Epoch [9/100], Step [58/111], Loss: 1.2697\n",
      "Epoch [9/100], Step [60/111], Loss: 1.2409\n",
      "Epoch [9/100], Step [62/111], Loss: 1.3784\n",
      "Epoch [9/100], Step [64/111], Loss: 1.8671\n",
      "Epoch [9/100], Step [66/111], Loss: 2.4171\n",
      "Epoch [9/100], Step [68/111], Loss: 1.2214\n",
      "Epoch [9/100], Step [70/111], Loss: 1.3231\n",
      "Epoch [9/100], Step [72/111], Loss: 1.1253\n",
      "Epoch [9/100], Step [74/111], Loss: 1.3742\n",
      "Epoch [9/100], Step [76/111], Loss: 1.3732\n",
      "Epoch [9/100], Step [78/111], Loss: 3.1115\n",
      "Epoch [9/100], Step [80/111], Loss: 1.0252\n",
      "Epoch [9/100], Step [82/111], Loss: 0.8953\n",
      "Epoch [9/100], Step [84/111], Loss: 1.4952\n",
      "Epoch [9/100], Step [86/111], Loss: 1.1505\n",
      "Epoch [9/100], Step [88/111], Loss: 1.7997\n",
      "Epoch [9/100], Step [90/111], Loss: 1.1607\n",
      "Epoch [9/100], Step [92/111], Loss: 1.0861\n",
      "Epoch [9/100], Step [94/111], Loss: 2.8879\n",
      "Epoch [9/100], Step [96/111], Loss: 1.2041\n",
      "Epoch [9/100], Step [98/111], Loss: 1.0570\n",
      "Epoch [9/100], Step [100/111], Loss: 0.8354\n",
      "Epoch [9/100], Step [102/111], Loss: 4.3661\n",
      "Epoch [9/100], Step [104/111], Loss: 1.4594\n",
      "Epoch [9/100], Step [106/111], Loss: 1.5289\n",
      "Epoch [9/100], Step [108/111], Loss: 1.4243\n",
      "Epoch [9/100], Step [110/111], Loss: 1.3665\n",
      "Epoch [10/100], Step [2/111], Loss: 1.3751\n",
      "Epoch [10/100], Step [4/111], Loss: 1.1349\n",
      "Epoch [10/100], Step [6/111], Loss: 1.4430\n",
      "Epoch [10/100], Step [8/111], Loss: 1.0286\n",
      "Epoch [10/100], Step [10/111], Loss: 1.0732\n",
      "Epoch [10/100], Step [12/111], Loss: 0.8054\n",
      "Epoch [10/100], Step [14/111], Loss: 1.3471\n",
      "Epoch [10/100], Step [16/111], Loss: 1.7585\n",
      "Epoch [10/100], Step [18/111], Loss: 10.8783\n",
      "Epoch [10/100], Step [20/111], Loss: 1.1824\n",
      "Epoch [10/100], Step [22/111], Loss: 0.8984\n",
      "Epoch [10/100], Step [24/111], Loss: 1.4259\n",
      "Epoch [10/100], Step [26/111], Loss: 1.6899\n",
      "Epoch [10/100], Step [28/111], Loss: 1.4137\n",
      "Epoch [10/100], Step [30/111], Loss: 1.1465\n",
      "Epoch [10/100], Step [32/111], Loss: 1.0599\n",
      "Epoch [10/100], Step [34/111], Loss: 0.8488\n",
      "Epoch [10/100], Step [36/111], Loss: 0.9928\n",
      "Epoch [10/100], Step [38/111], Loss: 1.4126\n",
      "Epoch [10/100], Step [40/111], Loss: 1.1824\n",
      "Epoch [10/100], Step [42/111], Loss: 0.9227\n",
      "Epoch [10/100], Step [44/111], Loss: 1.3484\n",
      "Epoch [10/100], Step [46/111], Loss: 0.9211\n",
      "Epoch [10/100], Step [48/111], Loss: 2.7214\n",
      "Epoch [10/100], Step [50/111], Loss: 1.0490\n",
      "Epoch [10/100], Step [52/111], Loss: 2.1879\n",
      "Epoch [10/100], Step [54/111], Loss: 1.1761\n",
      "Epoch [10/100], Step [56/111], Loss: 3.1789\n",
      "Epoch [10/100], Step [58/111], Loss: 0.9140\n",
      "Epoch [10/100], Step [60/111], Loss: 1.1296\n",
      "Epoch [10/100], Step [62/111], Loss: 2.0778\n",
      "Epoch [10/100], Step [64/111], Loss: 1.3576\n",
      "Epoch [10/100], Step [66/111], Loss: 0.9068\n",
      "Epoch [10/100], Step [68/111], Loss: 0.8755\n",
      "Epoch [10/100], Step [70/111], Loss: 1.0398\n",
      "Epoch [10/100], Step [72/111], Loss: 0.9462\n",
      "Epoch [10/100], Step [74/111], Loss: 1.1652\n",
      "Epoch [10/100], Step [76/111], Loss: 1.5290\n",
      "Epoch [10/100], Step [78/111], Loss: 1.4594\n",
      "Epoch [10/100], Step [80/111], Loss: 2.1646\n",
      "Epoch [10/100], Step [82/111], Loss: 1.1657\n",
      "Epoch [10/100], Step [84/111], Loss: 1.3724\n",
      "Epoch [10/100], Step [86/111], Loss: 0.7933\n",
      "Epoch [10/100], Step [88/111], Loss: 0.8063\n",
      "Epoch [10/100], Step [90/111], Loss: 0.9882\n",
      "Epoch [10/100], Step [92/111], Loss: 1.2967\n",
      "Epoch [10/100], Step [94/111], Loss: 1.1577\n",
      "Epoch [10/100], Step [96/111], Loss: 1.2238\n",
      "Epoch [10/100], Step [98/111], Loss: 1.8046\n",
      "Epoch [10/100], Step [100/111], Loss: 1.0549\n",
      "Epoch [10/100], Step [102/111], Loss: 0.8632\n",
      "Epoch [10/100], Step [104/111], Loss: 0.9889\n",
      "Epoch [10/100], Step [106/111], Loss: 1.0885\n",
      "Epoch [10/100], Step [108/111], Loss: 0.7700\n",
      "Epoch [10/100], Step [110/111], Loss: 1.2192\n",
      "Epoch [11/100], Step [2/111], Loss: 0.7937\n",
      "Epoch [11/100], Step [4/111], Loss: 1.5331\n",
      "Epoch [11/100], Step [6/111], Loss: 1.0266\n",
      "Epoch [11/100], Step [8/111], Loss: 0.8854\n",
      "Epoch [11/100], Step [10/111], Loss: 1.0059\n",
      "Epoch [11/100], Step [12/111], Loss: 1.3043\n",
      "Epoch [11/100], Step [14/111], Loss: 1.0059\n",
      "Epoch [11/100], Step [16/111], Loss: 1.4687\n",
      "Epoch [11/100], Step [18/111], Loss: 1.0091\n",
      "Epoch [11/100], Step [20/111], Loss: 1.1126\n",
      "Epoch [11/100], Step [22/111], Loss: 1.0084\n",
      "Epoch [11/100], Step [24/111], Loss: 0.8487\n",
      "Epoch [11/100], Step [26/111], Loss: 1.0127\n",
      "Epoch [11/100], Step [28/111], Loss: 0.9543\n",
      "Epoch [11/100], Step [30/111], Loss: 1.1181\n",
      "Epoch [11/100], Step [32/111], Loss: 0.9560\n",
      "Epoch [11/100], Step [34/111], Loss: 1.6986\n",
      "Epoch [11/100], Step [36/111], Loss: 1.6297\n",
      "Epoch [11/100], Step [38/111], Loss: 0.7847\n",
      "Epoch [11/100], Step [40/111], Loss: 0.9620\n",
      "Epoch [11/100], Step [42/111], Loss: 0.7923\n",
      "Epoch [11/100], Step [44/111], Loss: 1.2751\n",
      "Epoch [11/100], Step [46/111], Loss: 0.8868\n",
      "Epoch [11/100], Step [48/111], Loss: 0.9563\n",
      "Epoch [11/100], Step [50/111], Loss: 0.7781\n",
      "Epoch [11/100], Step [52/111], Loss: 0.7978\n",
      "Epoch [11/100], Step [54/111], Loss: 0.9525\n",
      "Epoch [11/100], Step [56/111], Loss: 1.2876\n",
      "Epoch [11/100], Step [58/111], Loss: 0.8787\n",
      "Epoch [11/100], Step [60/111], Loss: 1.2534\n",
      "Epoch [11/100], Step [62/111], Loss: 0.8247\n",
      "Epoch [11/100], Step [64/111], Loss: 2.7991\n",
      "Epoch [11/100], Step [66/111], Loss: 5.7175\n",
      "Epoch [11/100], Step [68/111], Loss: 3.9666\n",
      "Epoch [11/100], Step [70/111], Loss: 0.7774\n",
      "Epoch [11/100], Step [72/111], Loss: 2.7796\n",
      "Epoch [11/100], Step [74/111], Loss: 0.9435\n",
      "Epoch [11/100], Step [76/111], Loss: 1.6037\n",
      "Epoch [11/100], Step [78/111], Loss: 0.9844\n",
      "Epoch [11/100], Step [80/111], Loss: 0.9741\n",
      "Epoch [11/100], Step [82/111], Loss: 0.8685\n",
      "Epoch [11/100], Step [84/111], Loss: 0.8270\n",
      "Epoch [11/100], Step [86/111], Loss: 1.0638\n",
      "Epoch [11/100], Step [88/111], Loss: 1.2321\n",
      "Epoch [11/100], Step [90/111], Loss: 0.9392\n",
      "Epoch [11/100], Step [92/111], Loss: 5.4033\n",
      "Epoch [11/100], Step [94/111], Loss: 1.3146\n",
      "Epoch [11/100], Step [96/111], Loss: 1.1396\n",
      "Epoch [11/100], Step [98/111], Loss: 0.8808\n",
      "Epoch [11/100], Step [100/111], Loss: 0.8727\n",
      "Epoch [11/100], Step [102/111], Loss: 0.9896\n",
      "Epoch [11/100], Step [104/111], Loss: 0.8965\n",
      "Epoch [11/100], Step [106/111], Loss: 2.2118\n",
      "Epoch [11/100], Step [108/111], Loss: 0.8777\n",
      "Epoch [11/100], Step [110/111], Loss: 0.9360\n",
      "Epoch [12/100], Step [2/111], Loss: 2.6728\n",
      "Epoch [12/100], Step [4/111], Loss: 1.2721\n",
      "Epoch [12/100], Step [6/111], Loss: 1.2201\n",
      "Epoch [12/100], Step [8/111], Loss: 0.7809\n",
      "Epoch [12/100], Step [10/111], Loss: 1.0970\n",
      "Epoch [12/100], Step [12/111], Loss: 0.7968\n",
      "Epoch [12/100], Step [14/111], Loss: 0.8394\n",
      "Epoch [12/100], Step [16/111], Loss: 0.7909\n",
      "Epoch [12/100], Step [18/111], Loss: 0.9629\n",
      "Epoch [12/100], Step [20/111], Loss: 3.9636\n",
      "Epoch [12/100], Step [22/111], Loss: 1.1642\n",
      "Epoch [12/100], Step [24/111], Loss: 1.0976\n",
      "Epoch [12/100], Step [26/111], Loss: 0.8128\n",
      "Epoch [12/100], Step [28/111], Loss: 0.7253\n",
      "Epoch [12/100], Step [30/111], Loss: 0.7874\n",
      "Epoch [12/100], Step [32/111], Loss: 1.2567\n",
      "Epoch [12/100], Step [34/111], Loss: 0.9034\n",
      "Epoch [12/100], Step [36/111], Loss: 0.8941\n",
      "Epoch [12/100], Step [38/111], Loss: 1.2919\n",
      "Epoch [12/100], Step [40/111], Loss: 0.7656\n",
      "Epoch [12/100], Step [42/111], Loss: 0.7025\n",
      "Epoch [12/100], Step [44/111], Loss: 2.5240\n",
      "Epoch [12/100], Step [46/111], Loss: 0.7897\n",
      "Epoch [12/100], Step [48/111], Loss: 0.6839\n",
      "Epoch [12/100], Step [50/111], Loss: 0.9262\n",
      "Epoch [12/100], Step [52/111], Loss: 4.8918\n",
      "Epoch [12/100], Step [54/111], Loss: 0.6237\n",
      "Epoch [12/100], Step [56/111], Loss: 0.8821\n",
      "Epoch [12/100], Step [58/111], Loss: 0.9871\n",
      "Epoch [12/100], Step [60/111], Loss: 0.6307\n",
      "Epoch [12/100], Step [62/111], Loss: 1.0976\n",
      "Epoch [12/100], Step [64/111], Loss: 0.7339\n",
      "Epoch [12/100], Step [66/111], Loss: 0.8949\n",
      "Epoch [12/100], Step [68/111], Loss: 1.1135\n",
      "Epoch [12/100], Step [70/111], Loss: 1.1694\n",
      "Epoch [12/100], Step [72/111], Loss: 1.1191\n",
      "Epoch [12/100], Step [74/111], Loss: 1.3645\n",
      "Epoch [12/100], Step [76/111], Loss: 0.7683\n",
      "Epoch [12/100], Step [78/111], Loss: 0.7792\n",
      "Epoch [12/100], Step [80/111], Loss: 0.9938\n",
      "Epoch [12/100], Step [82/111], Loss: 0.7787\n",
      "Epoch [12/100], Step [84/111], Loss: 0.6686\n",
      "Epoch [12/100], Step [86/111], Loss: 0.8802\n",
      "Epoch [12/100], Step [88/111], Loss: 0.8042\n",
      "Epoch [12/100], Step [90/111], Loss: 0.6816\n",
      "Epoch [12/100], Step [92/111], Loss: 0.9937\n",
      "Epoch [12/100], Step [94/111], Loss: 0.7953\n",
      "Epoch [12/100], Step [96/111], Loss: 0.7036\n",
      "Epoch [12/100], Step [98/111], Loss: 1.0370\n",
      "Epoch [12/100], Step [100/111], Loss: 1.1627\n",
      "Epoch [12/100], Step [102/111], Loss: 0.9496\n",
      "Epoch [12/100], Step [104/111], Loss: 0.7841\n",
      "Epoch [12/100], Step [106/111], Loss: 0.8616\n",
      "Epoch [12/100], Step [108/111], Loss: 0.8473\n",
      "Epoch [12/100], Step [110/111], Loss: 1.0591\n",
      "Epoch [13/100], Step [2/111], Loss: 0.6729\n",
      "Epoch [13/100], Step [4/111], Loss: 0.7629\n",
      "Epoch [13/100], Step [6/111], Loss: 2.2239\n",
      "Epoch [13/100], Step [8/111], Loss: 0.7357\n",
      "Epoch [13/100], Step [10/111], Loss: 0.9653\n",
      "Epoch [13/100], Step [12/111], Loss: 0.7000\n",
      "Epoch [13/100], Step [14/111], Loss: 1.5603\n",
      "Epoch [13/100], Step [16/111], Loss: 0.9756\n",
      "Epoch [13/100], Step [18/111], Loss: 0.8913\n",
      "Epoch [13/100], Step [20/111], Loss: 0.8373\n",
      "Epoch [13/100], Step [22/111], Loss: 0.6513\n",
      "Epoch [13/100], Step [24/111], Loss: 0.6625\n",
      "Epoch [13/100], Step [26/111], Loss: 0.7552\n",
      "Epoch [13/100], Step [28/111], Loss: 0.7099\n",
      "Epoch [13/100], Step [30/111], Loss: 1.4062\n",
      "Epoch [13/100], Step [32/111], Loss: 0.6453\n",
      "Epoch [13/100], Step [34/111], Loss: 0.6678\n",
      "Epoch [13/100], Step [36/111], Loss: 0.9941\n",
      "Epoch [13/100], Step [38/111], Loss: 0.9080\n",
      "Epoch [13/100], Step [40/111], Loss: 0.8538\n",
      "Epoch [13/100], Step [42/111], Loss: 0.8752\n",
      "Epoch [13/100], Step [44/111], Loss: 0.8343\n",
      "Epoch [13/100], Step [46/111], Loss: 0.7822\n",
      "Epoch [13/100], Step [48/111], Loss: 0.6633\n",
      "Epoch [13/100], Step [50/111], Loss: 1.3301\n",
      "Epoch [13/100], Step [52/111], Loss: 2.5893\n",
      "Epoch [13/100], Step [54/111], Loss: 2.6339\n",
      "Epoch [13/100], Step [56/111], Loss: 0.9580\n",
      "Epoch [13/100], Step [58/111], Loss: 0.7872\n",
      "Epoch [13/100], Step [60/111], Loss: 1.1057\n",
      "Epoch [13/100], Step [62/111], Loss: 0.6640\n",
      "Epoch [13/100], Step [64/111], Loss: 3.6276\n",
      "Epoch [13/100], Step [66/111], Loss: 1.1331\n",
      "Epoch [13/100], Step [68/111], Loss: 2.1998\n",
      "Epoch [13/100], Step [70/111], Loss: 4.7374\n",
      "Epoch [13/100], Step [72/111], Loss: 0.8407\n",
      "Epoch [13/100], Step [74/111], Loss: 0.8562\n",
      "Epoch [13/100], Step [76/111], Loss: 0.9399\n",
      "Epoch [13/100], Step [78/111], Loss: 2.7323\n",
      "Epoch [13/100], Step [80/111], Loss: 0.8625\n",
      "Epoch [13/100], Step [82/111], Loss: 1.1314\n",
      "Epoch [13/100], Step [84/111], Loss: 1.2936\n",
      "Epoch [13/100], Step [86/111], Loss: 0.9135\n",
      "Epoch [13/100], Step [88/111], Loss: 0.9249\n",
      "Epoch [13/100], Step [90/111], Loss: 0.6113\n",
      "Epoch [13/100], Step [92/111], Loss: 1.0368\n",
      "Epoch [13/100], Step [94/111], Loss: 0.8644\n",
      "Epoch [13/100], Step [96/111], Loss: 0.7754\n",
      "Epoch [13/100], Step [98/111], Loss: 0.7615\n",
      "Epoch [13/100], Step [100/111], Loss: 1.3756\n",
      "Epoch [13/100], Step [102/111], Loss: 0.8531\n",
      "Epoch [13/100], Step [104/111], Loss: 0.7736\n",
      "Epoch [13/100], Step [106/111], Loss: 0.7600\n",
      "Epoch [13/100], Step [108/111], Loss: 0.7299\n",
      "Epoch [13/100], Step [110/111], Loss: 0.8886\n",
      "Epoch [14/100], Step [2/111], Loss: 0.6399\n",
      "Epoch [14/100], Step [4/111], Loss: 1.0275\n",
      "Epoch [14/100], Step [6/111], Loss: 1.1791\n",
      "Epoch [14/100], Step [8/111], Loss: 0.6706\n",
      "Epoch [14/100], Step [10/111], Loss: 1.2474\n",
      "Epoch [14/100], Step [12/111], Loss: 1.1250\n",
      "Epoch [14/100], Step [14/111], Loss: 0.8545\n",
      "Epoch [14/100], Step [16/111], Loss: 1.0034\n",
      "Epoch [14/100], Step [18/111], Loss: 0.9440\n",
      "Epoch [14/100], Step [20/111], Loss: 0.7878\n",
      "Epoch [14/100], Step [22/111], Loss: 0.7024\n",
      "Epoch [14/100], Step [24/111], Loss: 0.9326\n",
      "Epoch [14/100], Step [26/111], Loss: 0.6680\n",
      "Epoch [14/100], Step [28/111], Loss: 1.7474\n",
      "Epoch [14/100], Step [30/111], Loss: 1.4594\n",
      "Epoch [14/100], Step [32/111], Loss: 0.6546\n",
      "Epoch [14/100], Step [34/111], Loss: 1.2148\n",
      "Epoch [14/100], Step [36/111], Loss: 2.2388\n",
      "Epoch [14/100], Step [38/111], Loss: 2.1905\n",
      "Epoch [14/100], Step [40/111], Loss: 0.6868\n",
      "Epoch [14/100], Step [42/111], Loss: 0.8308\n",
      "Epoch [14/100], Step [44/111], Loss: 1.1836\n",
      "Epoch [14/100], Step [46/111], Loss: 0.7250\n",
      "Epoch [14/100], Step [48/111], Loss: 0.9510\n",
      "Epoch [14/100], Step [50/111], Loss: 0.7379\n",
      "Epoch [14/100], Step [52/111], Loss: 0.6427\n",
      "Epoch [14/100], Step [54/111], Loss: 0.6948\n",
      "Epoch [14/100], Step [56/111], Loss: 0.8097\n",
      "Epoch [14/100], Step [58/111], Loss: 0.9009\n",
      "Epoch [14/100], Step [60/111], Loss: 0.6676\n",
      "Epoch [14/100], Step [62/111], Loss: 0.7544\n",
      "Epoch [14/100], Step [64/111], Loss: 1.1977\n",
      "Epoch [14/100], Step [66/111], Loss: 0.9339\n",
      "Epoch [14/100], Step [68/111], Loss: 0.7799\n",
      "Epoch [14/100], Step [70/111], Loss: 2.2076\n",
      "Epoch [14/100], Step [72/111], Loss: 0.8220\n",
      "Epoch [14/100], Step [74/111], Loss: 1.4500\n",
      "Epoch [14/100], Step [76/111], Loss: 0.8822\n",
      "Epoch [14/100], Step [78/111], Loss: 1.2423\n",
      "Epoch [14/100], Step [80/111], Loss: 0.6713\n",
      "Epoch [14/100], Step [82/111], Loss: 0.9463\n",
      "Epoch [14/100], Step [84/111], Loss: 0.7853\n",
      "Epoch [14/100], Step [86/111], Loss: 0.9372\n",
      "Epoch [14/100], Step [88/111], Loss: 1.0577\n",
      "Epoch [14/100], Step [90/111], Loss: 0.8201\n",
      "Epoch [14/100], Step [92/111], Loss: 0.9679\n",
      "Epoch [14/100], Step [94/111], Loss: 0.9185\n",
      "Epoch [14/100], Step [96/111], Loss: 0.8091\n",
      "Epoch [14/100], Step [98/111], Loss: 1.0760\n",
      "Epoch [14/100], Step [100/111], Loss: 0.7809\n",
      "Epoch [14/100], Step [102/111], Loss: 0.7368\n",
      "Epoch [14/100], Step [104/111], Loss: 1.2103\n",
      "Epoch [14/100], Step [106/111], Loss: 0.7441\n",
      "Epoch [14/100], Step [108/111], Loss: 0.7658\n",
      "Epoch [14/100], Step [110/111], Loss: 0.6350\n",
      "Epoch [15/100], Step [2/111], Loss: 0.7927\n",
      "Epoch [15/100], Step [4/111], Loss: 1.2519\n",
      "Epoch [15/100], Step [6/111], Loss: 0.6300\n",
      "Epoch [15/100], Step [8/111], Loss: 0.9351\n",
      "Epoch [15/100], Step [10/111], Loss: 1.1782\n",
      "Epoch [15/100], Step [12/111], Loss: 5.3120\n",
      "Epoch [15/100], Step [14/111], Loss: 0.7542\n",
      "Epoch [15/100], Step [16/111], Loss: 0.7715\n",
      "Epoch [15/100], Step [18/111], Loss: 1.1395\n",
      "Epoch [15/100], Step [20/111], Loss: 0.7525\n",
      "Epoch [15/100], Step [22/111], Loss: 0.7334\n",
      "Epoch [15/100], Step [24/111], Loss: 0.5742\n",
      "Epoch [15/100], Step [26/111], Loss: 0.9486\n",
      "Epoch [15/100], Step [28/111], Loss: 2.0310\n",
      "Epoch [15/100], Step [30/111], Loss: 1.3398\n",
      "Epoch [15/100], Step [32/111], Loss: 1.0873\n",
      "Epoch [15/100], Step [34/111], Loss: 0.6932\n",
      "Epoch [15/100], Step [36/111], Loss: 0.7614\n",
      "Epoch [15/100], Step [38/111], Loss: 0.6345\n",
      "Epoch [15/100], Step [40/111], Loss: 0.7824\n",
      "Epoch [15/100], Step [42/111], Loss: 0.9944\n",
      "Epoch [15/100], Step [44/111], Loss: 3.6936\n",
      "Epoch [15/100], Step [46/111], Loss: 0.8552\n",
      "Epoch [15/100], Step [48/111], Loss: 1.6940\n",
      "Epoch [15/100], Step [50/111], Loss: 1.0903\n",
      "Epoch [15/100], Step [52/111], Loss: 1.4898\n",
      "Epoch [15/100], Step [54/111], Loss: 1.1185\n",
      "Epoch [15/100], Step [56/111], Loss: 0.7883\n",
      "Epoch [15/100], Step [58/111], Loss: 0.8733\n",
      "Epoch [15/100], Step [60/111], Loss: 1.0872\n",
      "Epoch [15/100], Step [62/111], Loss: 0.8986\n",
      "Epoch [15/100], Step [64/111], Loss: 0.9209\n",
      "Epoch [15/100], Step [66/111], Loss: 0.7543\n",
      "Epoch [15/100], Step [68/111], Loss: 0.6304\n",
      "Epoch [15/100], Step [70/111], Loss: 1.3527\n",
      "Epoch [15/100], Step [72/111], Loss: 0.7954\n",
      "Epoch [15/100], Step [74/111], Loss: 0.8373\n",
      "Epoch [15/100], Step [76/111], Loss: 1.2020\n",
      "Epoch [15/100], Step [78/111], Loss: 0.8421\n",
      "Epoch [15/100], Step [80/111], Loss: 0.8025\n",
      "Epoch [15/100], Step [82/111], Loss: 1.4093\n",
      "Epoch [15/100], Step [84/111], Loss: 0.6448\n",
      "Epoch [15/100], Step [86/111], Loss: 1.1230\n",
      "Epoch [15/100], Step [88/111], Loss: 0.7850\n",
      "Epoch [15/100], Step [90/111], Loss: 0.7333\n",
      "Epoch [15/100], Step [92/111], Loss: 0.6611\n",
      "Epoch [15/100], Step [94/111], Loss: 1.0896\n",
      "Epoch [15/100], Step [96/111], Loss: 0.7872\n",
      "Epoch [15/100], Step [98/111], Loss: 0.9743\n",
      "Epoch [15/100], Step [100/111], Loss: 1.0656\n",
      "Epoch [15/100], Step [102/111], Loss: 0.6023\n",
      "Epoch [15/100], Step [104/111], Loss: 0.6211\n",
      "Epoch [15/100], Step [106/111], Loss: 0.9668\n",
      "Epoch [15/100], Step [108/111], Loss: 0.5612\n",
      "Epoch [15/100], Step [110/111], Loss: 0.7249\n",
      "Epoch [16/100], Step [2/111], Loss: 0.5018\n",
      "Epoch [16/100], Step [4/111], Loss: 0.6489\n",
      "Epoch [16/100], Step [6/111], Loss: 0.6465\n",
      "Epoch [16/100], Step [8/111], Loss: 1.2262\n",
      "Epoch [16/100], Step [10/111], Loss: 0.6931\n",
      "Epoch [16/100], Step [12/111], Loss: 0.6156\n",
      "Epoch [16/100], Step [14/111], Loss: 0.9053\n",
      "Epoch [16/100], Step [16/111], Loss: 0.6110\n",
      "Epoch [16/100], Step [18/111], Loss: 1.0478\n",
      "Epoch [16/100], Step [20/111], Loss: 0.9469\n",
      "Epoch [16/100], Step [22/111], Loss: 0.7704\n",
      "Epoch [16/100], Step [24/111], Loss: 0.8792\n",
      "Epoch [16/100], Step [26/111], Loss: 0.7363\n",
      "Epoch [16/100], Step [28/111], Loss: 0.8107\n",
      "Epoch [16/100], Step [30/111], Loss: 0.7315\n",
      "Epoch [16/100], Step [32/111], Loss: 1.0689\n",
      "Epoch [16/100], Step [34/111], Loss: 0.7772\n",
      "Epoch [16/100], Step [36/111], Loss: 0.9194\n",
      "Epoch [16/100], Step [38/111], Loss: 0.7636\n",
      "Epoch [16/100], Step [40/111], Loss: 1.3029\n",
      "Epoch [16/100], Step [42/111], Loss: 1.1394\n",
      "Epoch [16/100], Step [44/111], Loss: 0.8868\n",
      "Epoch [16/100], Step [46/111], Loss: 0.6207\n",
      "Epoch [16/100], Step [48/111], Loss: 0.9325\n",
      "Epoch [16/100], Step [50/111], Loss: 0.8849\n",
      "Epoch [16/100], Step [52/111], Loss: 0.9845\n",
      "Epoch [16/100], Step [54/111], Loss: 0.6274\n",
      "Epoch [16/100], Step [56/111], Loss: 0.6209\n",
      "Epoch [16/100], Step [58/111], Loss: 0.7067\n",
      "Epoch [16/100], Step [60/111], Loss: 0.7933\n",
      "Epoch [16/100], Step [62/111], Loss: 1.2127\n",
      "Epoch [16/100], Step [64/111], Loss: 0.8542\n",
      "Epoch [16/100], Step [66/111], Loss: 0.6005\n",
      "Epoch [16/100], Step [68/111], Loss: 0.6918\n",
      "Epoch [16/100], Step [70/111], Loss: 0.7135\n",
      "Epoch [16/100], Step [72/111], Loss: 0.8481\n",
      "Epoch [16/100], Step [74/111], Loss: 0.6813\n",
      "Epoch [16/100], Step [76/111], Loss: 0.6812\n",
      "Epoch [16/100], Step [78/111], Loss: 0.7860\n",
      "Epoch [16/100], Step [80/111], Loss: 0.5543\n",
      "Epoch [16/100], Step [82/111], Loss: 0.6102\n",
      "Epoch [16/100], Step [84/111], Loss: 0.8658\n",
      "Epoch [16/100], Step [86/111], Loss: 0.6095\n",
      "Epoch [16/100], Step [88/111], Loss: 1.9126\n",
      "Epoch [16/100], Step [90/111], Loss: 0.6907\n",
      "Epoch [16/100], Step [92/111], Loss: 0.7669\n",
      "Epoch [16/100], Step [94/111], Loss: 0.7306\n",
      "Epoch [16/100], Step [96/111], Loss: 0.8673\n",
      "Epoch [16/100], Step [98/111], Loss: 0.6438\n",
      "Epoch [16/100], Step [100/111], Loss: 8.9545\n",
      "Epoch [16/100], Step [102/111], Loss: 0.6776\n",
      "Epoch [16/100], Step [104/111], Loss: 1.0119\n",
      "Epoch [16/100], Step [106/111], Loss: 1.4034\n",
      "Epoch [16/100], Step [108/111], Loss: 1.2122\n",
      "Epoch [16/100], Step [110/111], Loss: 0.6874\n",
      "Epoch [17/100], Step [2/111], Loss: 1.0557\n",
      "Epoch [17/100], Step [4/111], Loss: 0.6728\n",
      "Epoch [17/100], Step [6/111], Loss: 0.7010\n",
      "Epoch [17/100], Step [8/111], Loss: 0.6899\n",
      "Epoch [17/100], Step [10/111], Loss: 1.7096\n",
      "Epoch [17/100], Step [12/111], Loss: 0.7707\n",
      "Epoch [17/100], Step [14/111], Loss: 0.7803\n",
      "Epoch [17/100], Step [16/111], Loss: 1.6843\n",
      "Epoch [17/100], Step [18/111], Loss: 0.5987\n",
      "Epoch [17/100], Step [20/111], Loss: 2.1992\n",
      "Epoch [17/100], Step [22/111], Loss: 0.7765\n",
      "Epoch [17/100], Step [24/111], Loss: 0.5980\n",
      "Epoch [17/100], Step [26/111], Loss: 0.7061\n",
      "Epoch [17/100], Step [28/111], Loss: 0.6760\n",
      "Epoch [17/100], Step [30/111], Loss: 2.3350\n",
      "Epoch [17/100], Step [32/111], Loss: 0.5970\n",
      "Epoch [17/100], Step [34/111], Loss: 0.9906\n",
      "Epoch [17/100], Step [36/111], Loss: 0.7829\n",
      "Epoch [17/100], Step [38/111], Loss: 0.8938\n",
      "Epoch [17/100], Step [40/111], Loss: 0.6426\n",
      "Epoch [17/100], Step [42/111], Loss: 0.9067\n",
      "Epoch [17/100], Step [44/111], Loss: 0.6621\n",
      "Epoch [17/100], Step [46/111], Loss: 0.5243\n",
      "Epoch [17/100], Step [48/111], Loss: 0.6656\n",
      "Epoch [17/100], Step [50/111], Loss: 0.9652\n",
      "Epoch [17/100], Step [52/111], Loss: 0.5783\n",
      "Epoch [17/100], Step [54/111], Loss: 0.7734\n",
      "Epoch [17/100], Step [56/111], Loss: 0.6986\n",
      "Epoch [17/100], Step [58/111], Loss: 1.0201\n",
      "Epoch [17/100], Step [60/111], Loss: 0.5422\n",
      "Epoch [17/100], Step [62/111], Loss: 4.0046\n",
      "Epoch [17/100], Step [64/111], Loss: 0.9563\n",
      "Epoch [17/100], Step [66/111], Loss: 1.7099\n",
      "Epoch [17/100], Step [68/111], Loss: 0.6904\n",
      "Epoch [17/100], Step [70/111], Loss: 0.7593\n",
      "Epoch [17/100], Step [72/111], Loss: 0.6754\n",
      "Epoch [17/100], Step [74/111], Loss: 0.4375\n",
      "Epoch [17/100], Step [76/111], Loss: 0.8429\n",
      "Epoch [17/100], Step [78/111], Loss: 0.8074\n",
      "Epoch [17/100], Step [80/111], Loss: 0.5624\n",
      "Epoch [17/100], Step [82/111], Loss: 0.5010\n",
      "Epoch [17/100], Step [84/111], Loss: 0.5835\n",
      "Epoch [17/100], Step [86/111], Loss: 0.4850\n",
      "Epoch [17/100], Step [88/111], Loss: 0.4540\n",
      "Epoch [17/100], Step [90/111], Loss: 1.2092\n",
      "Epoch [17/100], Step [92/111], Loss: 0.8476\n",
      "Epoch [17/100], Step [94/111], Loss: 0.7562\n",
      "Epoch [17/100], Step [96/111], Loss: 0.7404\n",
      "Epoch [17/100], Step [98/111], Loss: 1.0653\n",
      "Epoch [17/100], Step [100/111], Loss: 1.4276\n",
      "Epoch [17/100], Step [102/111], Loss: 6.3488\n",
      "Epoch [17/100], Step [104/111], Loss: 0.7054\n",
      "Epoch [17/100], Step [106/111], Loss: 0.9713\n",
      "Epoch [17/100], Step [108/111], Loss: 0.6897\n",
      "Epoch [17/100], Step [110/111], Loss: 0.6057\n",
      "Epoch [18/100], Step [2/111], Loss: 0.4667\n",
      "Epoch [18/100], Step [4/111], Loss: 0.6641\n",
      "Epoch [18/100], Step [6/111], Loss: 1.4279\n",
      "Epoch [18/100], Step [8/111], Loss: 0.7264\n",
      "Epoch [18/100], Step [10/111], Loss: 0.6163\n",
      "Epoch [18/100], Step [12/111], Loss: 0.4828\n",
      "Epoch [18/100], Step [14/111], Loss: 1.1170\n",
      "Epoch [18/100], Step [16/111], Loss: 0.7853\n",
      "Epoch [18/100], Step [18/111], Loss: 0.6846\n",
      "Epoch [18/100], Step [20/111], Loss: 0.8489\n",
      "Epoch [18/100], Step [22/111], Loss: 0.5699\n",
      "Epoch [18/100], Step [24/111], Loss: 0.5604\n",
      "Epoch [18/100], Step [26/111], Loss: 0.6293\n",
      "Epoch [18/100], Step [28/111], Loss: 0.4643\n",
      "Epoch [18/100], Step [30/111], Loss: 0.6149\n",
      "Epoch [18/100], Step [32/111], Loss: 0.9382\n",
      "Epoch [18/100], Step [34/111], Loss: 0.5534\n",
      "Epoch [18/100], Step [36/111], Loss: 1.4815\n",
      "Epoch [18/100], Step [38/111], Loss: 0.6906\n",
      "Epoch [18/100], Step [40/111], Loss: 0.5546\n",
      "Epoch [18/100], Step [42/111], Loss: 0.6671\n",
      "Epoch [18/100], Step [44/111], Loss: 0.5552\n",
      "Epoch [18/100], Step [46/111], Loss: 0.5774\n",
      "Epoch [18/100], Step [48/111], Loss: 0.9772\n",
      "Epoch [18/100], Step [50/111], Loss: 0.4535\n",
      "Epoch [18/100], Step [52/111], Loss: 0.6706\n",
      "Epoch [18/100], Step [54/111], Loss: 0.6270\n",
      "Epoch [18/100], Step [56/111], Loss: 3.5949\n",
      "Epoch [18/100], Step [58/111], Loss: 0.5536\n",
      "Epoch [18/100], Step [60/111], Loss: 0.7303\n",
      "Epoch [18/100], Step [62/111], Loss: 1.1405\n",
      "Epoch [18/100], Step [64/111], Loss: 0.7016\n",
      "Epoch [18/100], Step [66/111], Loss: 3.1504\n",
      "Epoch [18/100], Step [68/111], Loss: 0.7185\n",
      "Epoch [18/100], Step [70/111], Loss: 0.7803\n",
      "Epoch [18/100], Step [72/111], Loss: 1.1769\n",
      "Epoch [18/100], Step [74/111], Loss: 1.2555\n",
      "Epoch [18/100], Step [76/111], Loss: 0.5930\n",
      "Epoch [18/100], Step [78/111], Loss: 1.5394\n",
      "Epoch [18/100], Step [80/111], Loss: 0.7140\n",
      "Epoch [18/100], Step [82/111], Loss: 0.6510\n",
      "Epoch [18/100], Step [84/111], Loss: 0.5372\n",
      "Epoch [18/100], Step [86/111], Loss: 0.6430\n",
      "Epoch [18/100], Step [88/111], Loss: 1.0509\n",
      "Epoch [18/100], Step [90/111], Loss: 0.8155\n",
      "Epoch [18/100], Step [92/111], Loss: 0.6455\n",
      "Epoch [18/100], Step [94/111], Loss: 1.1058\n",
      "Epoch [18/100], Step [96/111], Loss: 0.8606\n",
      "Epoch [18/100], Step [98/111], Loss: 0.5133\n",
      "Epoch [18/100], Step [100/111], Loss: 0.4746\n",
      "Epoch [18/100], Step [102/111], Loss: 1.7564\n",
      "Epoch [18/100], Step [104/111], Loss: 0.6766\n",
      "Epoch [18/100], Step [106/111], Loss: 0.7577\n",
      "Epoch [18/100], Step [108/111], Loss: 0.5919\n",
      "Epoch [18/100], Step [110/111], Loss: 0.6565\n",
      "Epoch [19/100], Step [2/111], Loss: 0.7403\n",
      "Epoch [19/100], Step [4/111], Loss: 0.7009\n",
      "Epoch [19/100], Step [6/111], Loss: 0.6798\n",
      "Epoch [19/100], Step [8/111], Loss: 0.7163\n",
      "Epoch [19/100], Step [10/111], Loss: 0.7841\n",
      "Epoch [19/100], Step [12/111], Loss: 1.5554\n",
      "Epoch [19/100], Step [14/111], Loss: 0.7510\n",
      "Epoch [19/100], Step [16/111], Loss: 0.9849\n",
      "Epoch [19/100], Step [18/111], Loss: 0.7173\n",
      "Epoch [19/100], Step [20/111], Loss: 0.6789\n",
      "Epoch [19/100], Step [22/111], Loss: 0.7159\n",
      "Epoch [19/100], Step [24/111], Loss: 0.8829\n",
      "Epoch [19/100], Step [26/111], Loss: 1.0102\n",
      "Epoch [19/100], Step [28/111], Loss: 1.9856\n",
      "Epoch [19/100], Step [30/111], Loss: 1.6012\n",
      "Epoch [19/100], Step [32/111], Loss: 1.0767\n",
      "Epoch [19/100], Step [34/111], Loss: 0.9226\n",
      "Epoch [19/100], Step [36/111], Loss: 1.3730\n",
      "Epoch [19/100], Step [38/111], Loss: 1.5538\n",
      "Epoch [19/100], Step [40/111], Loss: 1.2035\n",
      "Epoch [19/100], Step [42/111], Loss: 0.7990\n",
      "Epoch [19/100], Step [44/111], Loss: 3.5490\n",
      "Epoch [19/100], Step [46/111], Loss: 1.2303\n",
      "Epoch [19/100], Step [48/111], Loss: 2.2339\n",
      "Epoch [19/100], Step [50/111], Loss: 0.8211\n",
      "Epoch [19/100], Step [52/111], Loss: 1.0356\n",
      "Epoch [19/100], Step [54/111], Loss: 2.0280\n",
      "Epoch [19/100], Step [56/111], Loss: 0.8174\n",
      "Epoch [19/100], Step [58/111], Loss: 0.6581\n",
      "Epoch [19/100], Step [60/111], Loss: 0.7140\n",
      "Epoch [19/100], Step [62/111], Loss: 0.7404\n",
      "Epoch [19/100], Step [64/111], Loss: 0.8478\n",
      "Epoch [19/100], Step [66/111], Loss: 0.7064\n",
      "Epoch [19/100], Step [68/111], Loss: 1.5662\n",
      "Epoch [19/100], Step [70/111], Loss: 0.7162\n",
      "Epoch [19/100], Step [72/111], Loss: 0.7987\n",
      "Epoch [19/100], Step [74/111], Loss: 1.1651\n",
      "Epoch [19/100], Step [76/111], Loss: 5.5263\n",
      "Epoch [19/100], Step [78/111], Loss: 2.1075\n",
      "Epoch [19/100], Step [80/111], Loss: 0.9191\n",
      "Epoch [19/100], Step [82/111], Loss: 0.8566\n",
      "Epoch [19/100], Step [84/111], Loss: 0.6340\n",
      "Epoch [19/100], Step [86/111], Loss: 0.7629\n",
      "Epoch [19/100], Step [88/111], Loss: 0.9200\n",
      "Epoch [19/100], Step [90/111], Loss: 4.0796\n",
      "Epoch [19/100], Step [92/111], Loss: 2.9518\n",
      "Epoch [19/100], Step [94/111], Loss: 0.9886\n",
      "Epoch [19/100], Step [96/111], Loss: 0.9712\n",
      "Epoch [19/100], Step [98/111], Loss: 0.7914\n",
      "Epoch [19/100], Step [100/111], Loss: 0.8670\n",
      "Epoch [19/100], Step [102/111], Loss: 0.9764\n",
      "Epoch [19/100], Step [104/111], Loss: 1.2433\n",
      "Epoch [19/100], Step [106/111], Loss: 0.9311\n",
      "Epoch [19/100], Step [108/111], Loss: 0.8832\n",
      "Epoch [19/100], Step [110/111], Loss: 1.3844\n",
      "Epoch [20/100], Step [2/111], Loss: 0.6779\n",
      "Epoch [20/100], Step [4/111], Loss: 0.8942\n",
      "Epoch [20/100], Step [6/111], Loss: 0.8754\n",
      "Epoch [20/100], Step [8/111], Loss: 0.7634\n",
      "Epoch [20/100], Step [10/111], Loss: 0.6408\n",
      "Epoch [20/100], Step [12/111], Loss: 1.5637\n",
      "Epoch [20/100], Step [14/111], Loss: 0.7129\n",
      "Epoch [20/100], Step [16/111], Loss: 0.8270\n",
      "Epoch [20/100], Step [18/111], Loss: 0.6552\n",
      "Epoch [20/100], Step [20/111], Loss: 2.9237\n",
      "Epoch [20/100], Step [22/111], Loss: 0.7628\n",
      "Epoch [20/100], Step [24/111], Loss: 0.7299\n",
      "Epoch [20/100], Step [26/111], Loss: 0.6267\n",
      "Epoch [20/100], Step [28/111], Loss: 0.9795\n",
      "Epoch [20/100], Step [30/111], Loss: 1.2707\n",
      "Epoch [20/100], Step [32/111], Loss: 0.6880\n",
      "Epoch [20/100], Step [34/111], Loss: 0.6106\n",
      "Epoch [20/100], Step [36/111], Loss: 0.6295\n",
      "Epoch [20/100], Step [38/111], Loss: 0.7738\n",
      "Epoch [20/100], Step [40/111], Loss: 0.7083\n",
      "Epoch [20/100], Step [42/111], Loss: 0.6115\n",
      "Epoch [20/100], Step [44/111], Loss: 0.7147\n",
      "Epoch [20/100], Step [46/111], Loss: 0.7592\n",
      "Epoch [20/100], Step [48/111], Loss: 0.5506\n",
      "Epoch [20/100], Step [50/111], Loss: 1.2415\n",
      "Epoch [20/100], Step [52/111], Loss: 0.6693\n",
      "Epoch [20/100], Step [54/111], Loss: 0.7132\n",
      "Epoch [20/100], Step [56/111], Loss: 0.7311\n",
      "Epoch [20/100], Step [58/111], Loss: 1.1138\n",
      "Epoch [20/100], Step [60/111], Loss: 0.5320\n",
      "Epoch [20/100], Step [62/111], Loss: 0.5748\n",
      "Epoch [20/100], Step [64/111], Loss: 1.0464\n",
      "Epoch [20/100], Step [66/111], Loss: 0.7219\n",
      "Epoch [20/100], Step [68/111], Loss: 0.5954\n",
      "Epoch [20/100], Step [70/111], Loss: 0.6109\n",
      "Epoch [20/100], Step [72/111], Loss: 1.0371\n",
      "Epoch [20/100], Step [74/111], Loss: 0.9202\n",
      "Epoch [20/100], Step [76/111], Loss: 1.0435\n",
      "Epoch [20/100], Step [78/111], Loss: 0.5811\n",
      "Epoch [20/100], Step [80/111], Loss: 0.7395\n",
      "Epoch [20/100], Step [82/111], Loss: 1.0827\n",
      "Epoch [20/100], Step [84/111], Loss: 0.6447\n",
      "Epoch [20/100], Step [86/111], Loss: 0.6149\n",
      "Epoch [20/100], Step [88/111], Loss: 1.7573\n",
      "Epoch [20/100], Step [90/111], Loss: 0.5953\n",
      "Epoch [20/100], Step [92/111], Loss: 3.0358\n",
      "Epoch [20/100], Step [94/111], Loss: 1.0486\n",
      "Epoch [20/100], Step [96/111], Loss: 0.6819\n",
      "Epoch [20/100], Step [98/111], Loss: 0.6843\n",
      "Epoch [20/100], Step [100/111], Loss: 3.8018\n",
      "Epoch [20/100], Step [102/111], Loss: 1.1435\n",
      "Epoch [20/100], Step [104/111], Loss: 0.5984\n",
      "Epoch [20/100], Step [106/111], Loss: 8.3243\n",
      "Epoch [20/100], Step [108/111], Loss: 0.7329\n",
      "Epoch [20/100], Step [110/111], Loss: 1.0326\n",
      "Epoch [21/100], Step [2/111], Loss: 0.9732\n",
      "Epoch [21/100], Step [4/111], Loss: 3.1043\n",
      "Epoch [21/100], Step [6/111], Loss: 0.7824\n",
      "Epoch [21/100], Step [8/111], Loss: 0.9243\n",
      "Epoch [21/100], Step [10/111], Loss: 0.9355\n",
      "Epoch [21/100], Step [12/111], Loss: 0.6309\n",
      "Epoch [21/100], Step [14/111], Loss: 0.9751\n",
      "Epoch [21/100], Step [16/111], Loss: 0.6162\n",
      "Epoch [21/100], Step [18/111], Loss: 3.6028\n",
      "Epoch [21/100], Step [20/111], Loss: 0.8665\n",
      "Epoch [21/100], Step [22/111], Loss: 0.9084\n",
      "Epoch [21/100], Step [24/111], Loss: 1.3072\n",
      "Epoch [21/100], Step [26/111], Loss: 0.5992\n",
      "Epoch [21/100], Step [28/111], Loss: 0.5448\n",
      "Epoch [21/100], Step [30/111], Loss: 7.1132\n",
      "Epoch [21/100], Step [32/111], Loss: 0.6543\n",
      "Epoch [21/100], Step [34/111], Loss: 0.6166\n",
      "Epoch [21/100], Step [36/111], Loss: 0.5257\n",
      "Epoch [21/100], Step [38/111], Loss: 0.5402\n",
      "Epoch [21/100], Step [40/111], Loss: 0.5538\n",
      "Epoch [21/100], Step [42/111], Loss: 2.4713\n",
      "Epoch [21/100], Step [44/111], Loss: 0.7175\n",
      "Epoch [21/100], Step [46/111], Loss: 1.5457\n",
      "Epoch [21/100], Step [48/111], Loss: 0.7460\n",
      "Epoch [21/100], Step [50/111], Loss: 1.0575\n",
      "Epoch [21/100], Step [52/111], Loss: 0.6110\n",
      "Epoch [21/100], Step [54/111], Loss: 0.6838\n",
      "Epoch [21/100], Step [56/111], Loss: 0.5272\n",
      "Epoch [21/100], Step [58/111], Loss: 0.6111\n",
      "Epoch [21/100], Step [60/111], Loss: 0.6793\n",
      "Epoch [21/100], Step [62/111], Loss: 0.6671\n",
      "Epoch [21/100], Step [64/111], Loss: 0.6965\n",
      "Epoch [21/100], Step [66/111], Loss: 0.7080\n",
      "Epoch [21/100], Step [68/111], Loss: 0.7033\n",
      "Epoch [21/100], Step [70/111], Loss: 0.8681\n",
      "Epoch [21/100], Step [72/111], Loss: 0.6305\n",
      "Epoch [21/100], Step [74/111], Loss: 0.7302\n",
      "Epoch [21/100], Step [76/111], Loss: 0.5723\n",
      "Epoch [21/100], Step [78/111], Loss: 0.5549\n",
      "Epoch [21/100], Step [80/111], Loss: 0.7399\n",
      "Epoch [21/100], Step [82/111], Loss: 1.2863\n",
      "Epoch [21/100], Step [84/111], Loss: 0.8465\n",
      "Epoch [21/100], Step [86/111], Loss: 0.6461\n",
      "Epoch [21/100], Step [88/111], Loss: 0.5389\n",
      "Epoch [21/100], Step [90/111], Loss: 0.7567\n",
      "Epoch [21/100], Step [92/111], Loss: 0.9507\n",
      "Epoch [21/100], Step [94/111], Loss: 0.6409\n",
      "Epoch [21/100], Step [96/111], Loss: 0.6500\n",
      "Epoch [21/100], Step [98/111], Loss: 0.6967\n",
      "Epoch [21/100], Step [100/111], Loss: 0.6623\n",
      "Epoch [21/100], Step [102/111], Loss: 0.7359\n",
      "Epoch [21/100], Step [104/111], Loss: 0.8203\n",
      "Epoch [21/100], Step [106/111], Loss: 0.7368\n",
      "Epoch [21/100], Step [108/111], Loss: 0.5106\n",
      "Epoch [21/100], Step [110/111], Loss: 0.7414\n",
      "Epoch [22/100], Step [2/111], Loss: 0.5206\n",
      "Epoch [22/100], Step [4/111], Loss: 0.7229\n",
      "Epoch [22/100], Step [6/111], Loss: 0.4754\n",
      "Epoch [22/100], Step [8/111], Loss: 0.7836\n",
      "Epoch [22/100], Step [10/111], Loss: 0.7080\n",
      "Epoch [22/100], Step [12/111], Loss: 0.8582\n",
      "Epoch [22/100], Step [14/111], Loss: 0.4714\n",
      "Epoch [22/100], Step [16/111], Loss: 1.0045\n",
      "Epoch [22/100], Step [18/111], Loss: 0.4163\n",
      "Epoch [22/100], Step [20/111], Loss: 0.4798\n",
      "Epoch [22/100], Step [22/111], Loss: 0.4357\n",
      "Epoch [22/100], Step [24/111], Loss: 0.4558\n",
      "Epoch [22/100], Step [26/111], Loss: 1.2242\n",
      "Epoch [22/100], Step [28/111], Loss: 0.5998\n",
      "Epoch [22/100], Step [30/111], Loss: 0.5296\n",
      "Epoch [22/100], Step [32/111], Loss: 0.5018\n",
      "Epoch [22/100], Step [34/111], Loss: 0.4161\n",
      "Epoch [22/100], Step [36/111], Loss: 0.7607\n",
      "Epoch [22/100], Step [38/111], Loss: 0.5066\n",
      "Epoch [22/100], Step [40/111], Loss: 0.9028\n",
      "Epoch [22/100], Step [42/111], Loss: 2.1623\n",
      "Epoch [22/100], Step [44/111], Loss: 0.5174\n",
      "Epoch [22/100], Step [46/111], Loss: 0.6973\n",
      "Epoch [22/100], Step [48/111], Loss: 0.6109\n",
      "Epoch [22/100], Step [50/111], Loss: 0.6288\n",
      "Epoch [22/100], Step [52/111], Loss: 0.5932\n",
      "Epoch [22/100], Step [54/111], Loss: 2.5635\n",
      "Epoch [22/100], Step [56/111], Loss: 0.5847\n",
      "Epoch [22/100], Step [58/111], Loss: 0.5564\n",
      "Epoch [22/100], Step [60/111], Loss: 0.7075\n",
      "Epoch [22/100], Step [62/111], Loss: 0.7927\n",
      "Epoch [22/100], Step [64/111], Loss: 0.5980\n",
      "Epoch [22/100], Step [66/111], Loss: 0.4542\n",
      "Epoch [22/100], Step [68/111], Loss: 0.8114\n",
      "Epoch [22/100], Step [70/111], Loss: 0.8453\n",
      "Epoch [22/100], Step [72/111], Loss: 0.4154\n",
      "Epoch [22/100], Step [74/111], Loss: 0.6155\n",
      "Epoch [22/100], Step [76/111], Loss: 0.8786\n",
      "Epoch [22/100], Step [78/111], Loss: 0.7046\n",
      "Epoch [22/100], Step [80/111], Loss: 0.9805\n",
      "Epoch [22/100], Step [82/111], Loss: 0.4894\n",
      "Epoch [22/100], Step [84/111], Loss: 0.4362\n",
      "Epoch [22/100], Step [86/111], Loss: 0.5473\n",
      "Epoch [22/100], Step [88/111], Loss: 0.7547\n",
      "Epoch [22/100], Step [90/111], Loss: 0.5154\n",
      "Epoch [22/100], Step [92/111], Loss: 1.7605\n",
      "Epoch [22/100], Step [94/111], Loss: 0.5763\n",
      "Epoch [22/100], Step [96/111], Loss: 0.5390\n",
      "Epoch [22/100], Step [98/111], Loss: 0.6467\n",
      "Epoch [22/100], Step [100/111], Loss: 0.6836\n",
      "Epoch [22/100], Step [102/111], Loss: 0.5536\n",
      "Epoch [22/100], Step [104/111], Loss: 0.9307\n",
      "Epoch [22/100], Step [106/111], Loss: 0.9879\n",
      "Epoch [22/100], Step [108/111], Loss: 1.1691\n",
      "Epoch [22/100], Step [110/111], Loss: 0.6552\n",
      "Epoch [23/100], Step [2/111], Loss: 0.6012\n",
      "Epoch [23/100], Step [4/111], Loss: 0.5531\n",
      "Epoch [23/100], Step [6/111], Loss: 1.5897\n",
      "Epoch [23/100], Step [8/111], Loss: 0.7065\n",
      "Epoch [23/100], Step [10/111], Loss: 0.5310\n",
      "Epoch [23/100], Step [12/111], Loss: 0.4673\n",
      "Epoch [23/100], Step [14/111], Loss: 0.4709\n",
      "Epoch [23/100], Step [16/111], Loss: 0.4094\n",
      "Epoch [23/100], Step [18/111], Loss: 0.5380\n",
      "Epoch [23/100], Step [20/111], Loss: 0.5653\n",
      "Epoch [23/100], Step [22/111], Loss: 0.6325\n",
      "Epoch [23/100], Step [24/111], Loss: 0.9540\n",
      "Epoch [23/100], Step [26/111], Loss: 0.4792\n",
      "Epoch [23/100], Step [28/111], Loss: 0.4741\n",
      "Epoch [23/100], Step [30/111], Loss: 0.5490\n",
      "Epoch [23/100], Step [32/111], Loss: 0.7979\n",
      "Epoch [23/100], Step [34/111], Loss: 0.4928\n",
      "Epoch [23/100], Step [36/111], Loss: 0.4832\n",
      "Epoch [23/100], Step [38/111], Loss: 0.6210\n",
      "Epoch [23/100], Step [40/111], Loss: 0.5512\n",
      "Epoch [23/100], Step [42/111], Loss: 0.8476\n",
      "Epoch [23/100], Step [44/111], Loss: 0.3646\n",
      "Epoch [23/100], Step [46/111], Loss: 0.5653\n",
      "Epoch [23/100], Step [48/111], Loss: 0.4706\n",
      "Epoch [23/100], Step [50/111], Loss: 0.7595\n",
      "Epoch [23/100], Step [52/111], Loss: 0.4472\n",
      "Epoch [23/100], Step [54/111], Loss: 0.7453\n",
      "Epoch [23/100], Step [56/111], Loss: 0.3923\n",
      "Epoch [23/100], Step [58/111], Loss: 0.5091\n",
      "Epoch [23/100], Step [60/111], Loss: 0.4350\n",
      "Epoch [23/100], Step [62/111], Loss: 0.5121\n",
      "Epoch [23/100], Step [64/111], Loss: 0.5257\n",
      "Epoch [23/100], Step [66/111], Loss: 0.6917\n",
      "Epoch [23/100], Step [68/111], Loss: 0.4907\n",
      "Epoch [23/100], Step [70/111], Loss: 3.7835\n",
      "Epoch [23/100], Step [72/111], Loss: 0.4574\n",
      "Epoch [23/100], Step [74/111], Loss: 0.5362\n",
      "Epoch [23/100], Step [76/111], Loss: 0.7409\n",
      "Epoch [23/100], Step [78/111], Loss: 0.3968\n",
      "Epoch [23/100], Step [80/111], Loss: 0.4849\n",
      "Epoch [23/100], Step [82/111], Loss: 1.4911\n",
      "Epoch [23/100], Step [84/111], Loss: 0.6991\n",
      "Epoch [23/100], Step [86/111], Loss: 0.4800\n",
      "Epoch [23/100], Step [88/111], Loss: 1.0639\n",
      "Epoch [23/100], Step [90/111], Loss: 0.6775\n",
      "Epoch [23/100], Step [92/111], Loss: 1.3881\n",
      "Epoch [23/100], Step [94/111], Loss: 0.5610\n",
      "Epoch [23/100], Step [96/111], Loss: 0.6061\n",
      "Epoch [23/100], Step [98/111], Loss: 0.6217\n",
      "Epoch [23/100], Step [100/111], Loss: 0.7480\n",
      "Epoch [23/100], Step [102/111], Loss: 0.4347\n",
      "Epoch [23/100], Step [104/111], Loss: 0.5441\n",
      "Epoch [23/100], Step [106/111], Loss: 0.3814\n",
      "Epoch [23/100], Step [108/111], Loss: 1.1913\n",
      "Epoch [23/100], Step [110/111], Loss: 0.5829\n",
      "Epoch [24/100], Step [2/111], Loss: 0.4923\n",
      "Epoch [24/100], Step [4/111], Loss: 0.6306\n",
      "Epoch [24/100], Step [6/111], Loss: 0.4754\n",
      "Epoch [24/100], Step [8/111], Loss: 0.5477\n",
      "Epoch [24/100], Step [10/111], Loss: 0.5694\n",
      "Epoch [24/100], Step [12/111], Loss: 0.5544\n",
      "Epoch [24/100], Step [14/111], Loss: 0.7648\n",
      "Epoch [24/100], Step [16/111], Loss: 0.7105\n",
      "Epoch [24/100], Step [18/111], Loss: 0.5730\n",
      "Epoch [24/100], Step [20/111], Loss: 0.4756\n",
      "Epoch [24/100], Step [22/111], Loss: 0.5426\n",
      "Epoch [24/100], Step [24/111], Loss: 0.4585\n",
      "Epoch [24/100], Step [26/111], Loss: 0.5196\n",
      "Epoch [24/100], Step [28/111], Loss: 2.1884\n",
      "Epoch [24/100], Step [30/111], Loss: 0.4465\n",
      "Epoch [24/100], Step [32/111], Loss: 0.6651\n",
      "Epoch [24/100], Step [34/111], Loss: 0.4739\n",
      "Epoch [24/100], Step [36/111], Loss: 0.6550\n",
      "Epoch [24/100], Step [38/111], Loss: 0.7350\n",
      "Epoch [24/100], Step [40/111], Loss: 1.1368\n",
      "Epoch [24/100], Step [42/111], Loss: 0.4598\n",
      "Epoch [24/100], Step [44/111], Loss: 0.6358\n",
      "Epoch [24/100], Step [46/111], Loss: 0.6582\n",
      "Epoch [24/100], Step [48/111], Loss: 0.8687\n",
      "Epoch [24/100], Step [50/111], Loss: 0.7468\n",
      "Epoch [24/100], Step [52/111], Loss: 0.6139\n",
      "Epoch [24/100], Step [54/111], Loss: 0.5414\n",
      "Epoch [24/100], Step [56/111], Loss: 3.6442\n",
      "Epoch [24/100], Step [58/111], Loss: 0.4697\n",
      "Epoch [24/100], Step [60/111], Loss: 0.4750\n",
      "Epoch [24/100], Step [62/111], Loss: 0.6923\n",
      "Epoch [24/100], Step [64/111], Loss: 0.4811\n",
      "Epoch [24/100], Step [66/111], Loss: 0.6009\n",
      "Epoch [24/100], Step [68/111], Loss: 0.5081\n",
      "Epoch [24/100], Step [70/111], Loss: 0.6084\n",
      "Epoch [24/100], Step [72/111], Loss: 0.4835\n",
      "Epoch [24/100], Step [74/111], Loss: 0.5480\n",
      "Epoch [24/100], Step [76/111], Loss: 0.5267\n",
      "Epoch [24/100], Step [78/111], Loss: 0.4017\n",
      "Epoch [24/100], Step [80/111], Loss: 0.4319\n",
      "Epoch [24/100], Step [82/111], Loss: 0.6412\n",
      "Epoch [24/100], Step [84/111], Loss: 0.4271\n",
      "Epoch [24/100], Step [86/111], Loss: 0.5270\n",
      "Epoch [24/100], Step [88/111], Loss: 0.8337\n",
      "Epoch [24/100], Step [90/111], Loss: 0.8694\n",
      "Epoch [24/100], Step [92/111], Loss: 0.5834\n",
      "Epoch [24/100], Step [94/111], Loss: 0.5447\n",
      "Epoch [24/100], Step [96/111], Loss: 0.4417\n",
      "Epoch [24/100], Step [98/111], Loss: 0.5053\n",
      "Epoch [24/100], Step [100/111], Loss: 0.4185\n",
      "Epoch [24/100], Step [102/111], Loss: 0.4513\n",
      "Epoch [24/100], Step [104/111], Loss: 0.5735\n",
      "Epoch [24/100], Step [106/111], Loss: 0.3671\n",
      "Epoch [24/100], Step [108/111], Loss: 0.3485\n",
      "Epoch [24/100], Step [110/111], Loss: 6.3694\n",
      "Epoch [25/100], Step [2/111], Loss: 2.4647\n",
      "Epoch [25/100], Step [4/111], Loss: 1.1711\n",
      "Epoch [25/100], Step [6/111], Loss: 0.5186\n",
      "Epoch [25/100], Step [8/111], Loss: 0.7273\n",
      "Epoch [25/100], Step [10/111], Loss: 0.5459\n",
      "Epoch [25/100], Step [12/111], Loss: 0.5586\n",
      "Epoch [25/100], Step [14/111], Loss: 0.6756\n",
      "Epoch [25/100], Step [16/111], Loss: 0.6275\n",
      "Epoch [25/100], Step [18/111], Loss: 0.5755\n",
      "Epoch [25/100], Step [20/111], Loss: 0.5391\n",
      "Epoch [25/100], Step [22/111], Loss: 0.3734\n",
      "Epoch [25/100], Step [24/111], Loss: 1.8719\n",
      "Epoch [25/100], Step [26/111], Loss: 0.7144\n",
      "Epoch [25/100], Step [28/111], Loss: 0.5769\n",
      "Epoch [25/100], Step [30/111], Loss: 4.5066\n",
      "Epoch [25/100], Step [32/111], Loss: 0.4672\n",
      "Epoch [25/100], Step [34/111], Loss: 0.4934\n",
      "Epoch [25/100], Step [36/111], Loss: 0.7943\n",
      "Epoch [25/100], Step [38/111], Loss: 0.5789\n",
      "Epoch [25/100], Step [40/111], Loss: 0.4485\n",
      "Epoch [25/100], Step [42/111], Loss: 0.7049\n",
      "Epoch [25/100], Step [44/111], Loss: 0.5638\n",
      "Epoch [25/100], Step [46/111], Loss: 0.5515\n",
      "Epoch [25/100], Step [48/111], Loss: 0.6626\n",
      "Epoch [25/100], Step [50/111], Loss: 0.3807\n",
      "Epoch [25/100], Step [52/111], Loss: 0.5753\n",
      "Epoch [25/100], Step [54/111], Loss: 0.6602\n",
      "Epoch [25/100], Step [56/111], Loss: 0.4824\n",
      "Epoch [25/100], Step [58/111], Loss: 0.6283\n",
      "Epoch [25/100], Step [60/111], Loss: 0.8216\n",
      "Epoch [25/100], Step [62/111], Loss: 0.4488\n",
      "Epoch [25/100], Step [64/111], Loss: 0.5778\n",
      "Epoch [25/100], Step [66/111], Loss: 0.8355\n",
      "Epoch [25/100], Step [68/111], Loss: 0.5499\n",
      "Epoch [25/100], Step [70/111], Loss: 0.5363\n",
      "Epoch [25/100], Step [72/111], Loss: 0.7897\n",
      "Epoch [25/100], Step [74/111], Loss: 0.4392\n",
      "Epoch [25/100], Step [76/111], Loss: 0.6015\n",
      "Epoch [25/100], Step [78/111], Loss: 0.8923\n",
      "Epoch [25/100], Step [80/111], Loss: 0.5688\n",
      "Epoch [25/100], Step [82/111], Loss: 3.1317\n",
      "Epoch [25/100], Step [84/111], Loss: 0.6221\n",
      "Epoch [25/100], Step [86/111], Loss: 0.9969\n",
      "Epoch [25/100], Step [88/111], Loss: 3.2228\n",
      "Epoch [25/100], Step [90/111], Loss: 0.6359\n",
      "Epoch [25/100], Step [92/111], Loss: 0.6568\n",
      "Epoch [25/100], Step [94/111], Loss: 0.6857\n",
      "Epoch [25/100], Step [96/111], Loss: 0.7595\n",
      "Epoch [25/100], Step [98/111], Loss: 0.7142\n",
      "Epoch [25/100], Step [100/111], Loss: 1.2674\n",
      "Epoch [25/100], Step [102/111], Loss: 0.4238\n",
      "Epoch [25/100], Step [104/111], Loss: 0.9064\n",
      "Epoch [25/100], Step [106/111], Loss: 0.8441\n",
      "Epoch [25/100], Step [108/111], Loss: 0.5706\n",
      "Epoch [25/100], Step [110/111], Loss: 0.8410\n",
      "Epoch [26/100], Step [2/111], Loss: 5.8536\n",
      "Epoch [26/100], Step [4/111], Loss: 0.6167\n",
      "Epoch [26/100], Step [6/111], Loss: 0.7393\n",
      "Epoch [26/100], Step [8/111], Loss: 0.5820\n",
      "Epoch [26/100], Step [10/111], Loss: 0.8910\n",
      "Epoch [26/100], Step [12/111], Loss: 1.1021\n",
      "Epoch [26/100], Step [14/111], Loss: 0.7276\n",
      "Epoch [26/100], Step [16/111], Loss: 0.7114\n",
      "Epoch [26/100], Step [18/111], Loss: 0.9918\n",
      "Epoch [26/100], Step [20/111], Loss: 1.5083\n",
      "Epoch [26/100], Step [22/111], Loss: 0.8098\n",
      "Epoch [26/100], Step [24/111], Loss: 0.7226\n",
      "Epoch [26/100], Step [26/111], Loss: 0.8867\n",
      "Epoch [26/100], Step [28/111], Loss: 0.7256\n",
      "Epoch [26/100], Step [30/111], Loss: 0.5491\n",
      "Epoch [26/100], Step [32/111], Loss: 0.5638\n",
      "Epoch [26/100], Step [34/111], Loss: 0.5996\n",
      "Epoch [26/100], Step [36/111], Loss: 0.4849\n",
      "Epoch [26/100], Step [38/111], Loss: 0.8668\n",
      "Epoch [26/100], Step [40/111], Loss: 0.6802\n",
      "Epoch [26/100], Step [42/111], Loss: 1.1886\n",
      "Epoch [26/100], Step [44/111], Loss: 0.6282\n",
      "Epoch [26/100], Step [46/111], Loss: 0.6051\n",
      "Epoch [26/100], Step [48/111], Loss: 0.7956\n",
      "Epoch [26/100], Step [50/111], Loss: 0.7392\n",
      "Epoch [26/100], Step [52/111], Loss: 0.5937\n",
      "Epoch [26/100], Step [54/111], Loss: 0.5328\n",
      "Epoch [26/100], Step [56/111], Loss: 0.6666\n",
      "Epoch [26/100], Step [58/111], Loss: 1.0459\n",
      "Epoch [26/100], Step [60/111], Loss: 0.7712\n",
      "Epoch [26/100], Step [62/111], Loss: 0.5442\n",
      "Epoch [26/100], Step [64/111], Loss: 0.4374\n",
      "Epoch [26/100], Step [66/111], Loss: 0.6097\n",
      "Epoch [26/100], Step [68/111], Loss: 0.8926\n",
      "Epoch [26/100], Step [70/111], Loss: 0.6648\n",
      "Epoch [26/100], Step [72/111], Loss: 0.5829\n",
      "Epoch [26/100], Step [74/111], Loss: 0.5903\n",
      "Epoch [26/100], Step [76/111], Loss: 0.4430\n",
      "Epoch [26/100], Step [78/111], Loss: 0.6009\n",
      "Epoch [26/100], Step [80/111], Loss: 0.6006\n",
      "Epoch [26/100], Step [82/111], Loss: 0.6947\n",
      "Epoch [26/100], Step [84/111], Loss: 0.5452\n",
      "Epoch [26/100], Step [86/111], Loss: 0.4738\n",
      "Epoch [26/100], Step [88/111], Loss: 0.4987\n",
      "Epoch [26/100], Step [90/111], Loss: 5.1570\n",
      "Epoch [26/100], Step [92/111], Loss: 0.6105\n",
      "Epoch [26/100], Step [94/111], Loss: 0.7235\n",
      "Epoch [26/100], Step [96/111], Loss: 0.4731\n",
      "Epoch [26/100], Step [98/111], Loss: 0.8112\n",
      "Epoch [26/100], Step [100/111], Loss: 0.8991\n",
      "Epoch [26/100], Step [102/111], Loss: 0.5720\n",
      "Epoch [26/100], Step [104/111], Loss: 0.6089\n",
      "Epoch [26/100], Step [106/111], Loss: 0.8192\n",
      "Epoch [26/100], Step [108/111], Loss: 0.6598\n",
      "Epoch [26/100], Step [110/111], Loss: 0.5879\n",
      "Epoch [27/100], Step [2/111], Loss: 0.6201\n",
      "Epoch [27/100], Step [4/111], Loss: 0.5063\n",
      "Epoch [27/100], Step [6/111], Loss: 0.9037\n",
      "Epoch [27/100], Step [8/111], Loss: 0.5875\n",
      "Epoch [27/100], Step [10/111], Loss: 0.5954\n",
      "Epoch [27/100], Step [12/111], Loss: 0.4952\n",
      "Epoch [27/100], Step [14/111], Loss: 0.8180\n",
      "Epoch [27/100], Step [16/111], Loss: 0.5944\n",
      "Epoch [27/100], Step [18/111], Loss: 0.5169\n",
      "Epoch [27/100], Step [20/111], Loss: 0.4973\n",
      "Epoch [27/100], Step [22/111], Loss: 0.4366\n",
      "Epoch [27/100], Step [24/111], Loss: 0.6874\n",
      "Epoch [27/100], Step [26/111], Loss: 0.7265\n",
      "Epoch [27/100], Step [28/111], Loss: 0.9469\n",
      "Epoch [27/100], Step [30/111], Loss: 0.7881\n",
      "Epoch [27/100], Step [32/111], Loss: 0.9813\n",
      "Epoch [27/100], Step [34/111], Loss: 0.6815\n",
      "Epoch [27/100], Step [36/111], Loss: 0.6313\n",
      "Epoch [27/100], Step [38/111], Loss: 0.8401\n",
      "Epoch [27/100], Step [40/111], Loss: 0.7893\n",
      "Epoch [27/100], Step [42/111], Loss: 1.5208\n",
      "Epoch [27/100], Step [44/111], Loss: 0.6122\n",
      "Epoch [27/100], Step [46/111], Loss: 0.5018\n",
      "Epoch [27/100], Step [48/111], Loss: 0.5002\n",
      "Epoch [27/100], Step [50/111], Loss: 0.4985\n",
      "Epoch [27/100], Step [52/111], Loss: 0.5876\n",
      "Epoch [27/100], Step [54/111], Loss: 0.8658\n",
      "Epoch [27/100], Step [56/111], Loss: 0.8740\n",
      "Epoch [27/100], Step [58/111], Loss: 0.5811\n",
      "Epoch [27/100], Step [60/111], Loss: 0.5765\n",
      "Epoch [27/100], Step [62/111], Loss: 3.1476\n",
      "Epoch [27/100], Step [64/111], Loss: 2.9457\n",
      "Epoch [27/100], Step [66/111], Loss: 0.5869\n",
      "Epoch [27/100], Step [68/111], Loss: 0.6570\n",
      "Epoch [27/100], Step [70/111], Loss: 0.5553\n",
      "Epoch [27/100], Step [72/111], Loss: 0.6892\n",
      "Epoch [27/100], Step [74/111], Loss: 0.6838\n",
      "Epoch [27/100], Step [76/111], Loss: 0.6914\n",
      "Epoch [27/100], Step [78/111], Loss: 0.5690\n",
      "Epoch [27/100], Step [80/111], Loss: 0.5809\n",
      "Epoch [27/100], Step [82/111], Loss: 4.9629\n",
      "Epoch [27/100], Step [84/111], Loss: 0.5061\n",
      "Epoch [27/100], Step [86/111], Loss: 0.5276\n",
      "Epoch [27/100], Step [88/111], Loss: 0.5391\n",
      "Epoch [27/100], Step [90/111], Loss: 0.4922\n",
      "Epoch [27/100], Step [92/111], Loss: 0.5889\n",
      "Epoch [27/100], Step [94/111], Loss: 0.7184\n",
      "Epoch [27/100], Step [96/111], Loss: 0.5185\n",
      "Epoch [27/100], Step [98/111], Loss: 0.6393\n",
      "Epoch [27/100], Step [100/111], Loss: 0.4964\n",
      "Epoch [27/100], Step [102/111], Loss: 0.5646\n",
      "Epoch [27/100], Step [104/111], Loss: 3.0506\n",
      "Epoch [27/100], Step [106/111], Loss: 0.4404\n",
      "Epoch [27/100], Step [108/111], Loss: 0.4228\n",
      "Epoch [27/100], Step [110/111], Loss: 0.4425\n",
      "Epoch [28/100], Step [2/111], Loss: 0.4551\n",
      "Epoch [28/100], Step [4/111], Loss: 0.6201\n",
      "Epoch [28/100], Step [6/111], Loss: 0.5333\n",
      "Epoch [28/100], Step [8/111], Loss: 0.7575\n",
      "Epoch [28/100], Step [10/111], Loss: 0.6086\n",
      "Epoch [28/100], Step [12/111], Loss: 0.3859\n",
      "Epoch [28/100], Step [14/111], Loss: 0.6877\n",
      "Epoch [28/100], Step [16/111], Loss: 0.4420\n",
      "Epoch [28/100], Step [18/111], Loss: 0.3132\n",
      "Epoch [28/100], Step [20/111], Loss: 0.4429\n",
      "Epoch [28/100], Step [22/111], Loss: 1.1467\n",
      "Epoch [28/100], Step [24/111], Loss: 0.4666\n",
      "Epoch [28/100], Step [26/111], Loss: 0.5325\n",
      "Epoch [28/100], Step [28/111], Loss: 0.9804\n",
      "Epoch [28/100], Step [30/111], Loss: 0.6122\n",
      "Epoch [28/100], Step [32/111], Loss: 0.5441\n",
      "Epoch [28/100], Step [34/111], Loss: 0.8397\n",
      "Epoch [28/100], Step [36/111], Loss: 0.5949\n",
      "Epoch [28/100], Step [38/111], Loss: 0.7962\n",
      "Epoch [28/100], Step [40/111], Loss: 0.7382\n",
      "Epoch [28/100], Step [42/111], Loss: 0.5371\n",
      "Epoch [28/100], Step [44/111], Loss: 3.8306\n",
      "Epoch [28/100], Step [46/111], Loss: 0.6589\n",
      "Epoch [28/100], Step [48/111], Loss: 0.6848\n",
      "Epoch [28/100], Step [50/111], Loss: 0.6318\n",
      "Epoch [28/100], Step [52/111], Loss: 0.5771\n",
      "Epoch [28/100], Step [54/111], Loss: 0.5844\n",
      "Epoch [28/100], Step [56/111], Loss: 0.4549\n",
      "Epoch [28/100], Step [58/111], Loss: 0.5368\n",
      "Epoch [28/100], Step [60/111], Loss: 0.6907\n",
      "Epoch [28/100], Step [62/111], Loss: 0.4749\n",
      "Epoch [28/100], Step [64/111], Loss: 0.4644\n",
      "Epoch [28/100], Step [66/111], Loss: 0.7229\n",
      "Epoch [28/100], Step [68/111], Loss: 0.5197\n",
      "Epoch [28/100], Step [70/111], Loss: 0.4864\n",
      "Epoch [28/100], Step [72/111], Loss: 0.6128\n",
      "Epoch [28/100], Step [74/111], Loss: 0.3795\n",
      "Epoch [28/100], Step [76/111], Loss: 0.5018\n",
      "Epoch [28/100], Step [78/111], Loss: 0.4750\n",
      "Epoch [28/100], Step [80/111], Loss: 0.5225\n",
      "Epoch [28/100], Step [82/111], Loss: 0.3069\n",
      "Epoch [28/100], Step [84/111], Loss: 0.7251\n",
      "Epoch [28/100], Step [86/111], Loss: 0.4751\n",
      "Epoch [28/100], Step [88/111], Loss: 0.7219\n",
      "Epoch [28/100], Step [90/111], Loss: 0.4300\n",
      "Epoch [28/100], Step [92/111], Loss: 0.4967\n",
      "Epoch [28/100], Step [94/111], Loss: 0.5255\n",
      "Epoch [28/100], Step [96/111], Loss: 0.4484\n",
      "Epoch [28/100], Step [98/111], Loss: 0.3911\n",
      "Epoch [28/100], Step [100/111], Loss: 0.3855\n",
      "Epoch [28/100], Step [102/111], Loss: 0.5221\n",
      "Epoch [28/100], Step [104/111], Loss: 0.5550\n",
      "Epoch [28/100], Step [106/111], Loss: 0.7948\n",
      "Epoch [28/100], Step [108/111], Loss: 0.6723\n",
      "Epoch [28/100], Step [110/111], Loss: 0.6247\n",
      "Epoch [29/100], Step [2/111], Loss: 0.3699\n",
      "Epoch [29/100], Step [4/111], Loss: 0.4802\n",
      "Epoch [29/100], Step [6/111], Loss: 0.3889\n",
      "Epoch [29/100], Step [8/111], Loss: 0.5628\n",
      "Epoch [29/100], Step [10/111], Loss: 0.5832\n",
      "Epoch [29/100], Step [12/111], Loss: 0.6862\n",
      "Epoch [29/100], Step [14/111], Loss: 0.7088\n",
      "Epoch [29/100], Step [16/111], Loss: 0.3838\n",
      "Epoch [29/100], Step [18/111], Loss: 0.5270\n",
      "Epoch [29/100], Step [20/111], Loss: 0.4582\n",
      "Epoch [29/100], Step [22/111], Loss: 0.5452\n",
      "Epoch [29/100], Step [24/111], Loss: 0.5408\n",
      "Epoch [29/100], Step [26/111], Loss: 0.5019\n",
      "Epoch [29/100], Step [28/111], Loss: 0.6022\n",
      "Epoch [29/100], Step [30/111], Loss: 0.7026\n",
      "Epoch [29/100], Step [32/111], Loss: 0.7255\n",
      "Epoch [29/100], Step [34/111], Loss: 0.5571\n",
      "Epoch [29/100], Step [36/111], Loss: 0.5048\n",
      "Epoch [29/100], Step [38/111], Loss: 0.4197\n",
      "Epoch [29/100], Step [40/111], Loss: 0.3938\n",
      "Epoch [29/100], Step [42/111], Loss: 0.5014\n",
      "Epoch [29/100], Step [44/111], Loss: 4.6055\n",
      "Epoch [29/100], Step [46/111], Loss: 0.5441\n",
      "Epoch [29/100], Step [48/111], Loss: 0.5215\n",
      "Epoch [29/100], Step [50/111], Loss: 0.4711\n",
      "Epoch [29/100], Step [52/111], Loss: 0.4663\n",
      "Epoch [29/100], Step [54/111], Loss: 0.4104\n",
      "Epoch [29/100], Step [56/111], Loss: 0.4602\n",
      "Epoch [29/100], Step [58/111], Loss: 0.4694\n",
      "Epoch [29/100], Step [60/111], Loss: 0.5061\n",
      "Epoch [29/100], Step [62/111], Loss: 0.5692\n",
      "Epoch [29/100], Step [64/111], Loss: 0.6501\n",
      "Epoch [29/100], Step [66/111], Loss: 0.8849\n",
      "Epoch [29/100], Step [68/111], Loss: 0.9927\n",
      "Epoch [29/100], Step [70/111], Loss: 0.8173\n",
      "Epoch [29/100], Step [72/111], Loss: 0.5642\n",
      "Epoch [29/100], Step [74/111], Loss: 0.5246\n",
      "Epoch [29/100], Step [76/111], Loss: 0.6230\n",
      "Epoch [29/100], Step [78/111], Loss: 1.3187\n",
      "Epoch [29/100], Step [80/111], Loss: 0.6705\n",
      "Epoch [29/100], Step [82/111], Loss: 0.4622\n",
      "Epoch [29/100], Step [84/111], Loss: 0.8402\n",
      "Epoch [29/100], Step [86/111], Loss: 0.6968\n",
      "Epoch [29/100], Step [88/111], Loss: 0.4966\n",
      "Epoch [29/100], Step [90/111], Loss: 0.6333\n",
      "Epoch [29/100], Step [92/111], Loss: 0.4782\n",
      "Epoch [29/100], Step [94/111], Loss: 0.4875\n",
      "Epoch [29/100], Step [96/111], Loss: 0.6133\n",
      "Epoch [29/100], Step [98/111], Loss: 0.5743\n",
      "Epoch [29/100], Step [100/111], Loss: 0.4261\n",
      "Epoch [29/100], Step [102/111], Loss: 0.8701\n",
      "Epoch [29/100], Step [104/111], Loss: 0.7668\n",
      "Epoch [29/100], Step [106/111], Loss: 1.5589\n",
      "Epoch [29/100], Step [108/111], Loss: 0.4174\n",
      "Epoch [29/100], Step [110/111], Loss: 0.7932\n",
      "Epoch [30/100], Step [2/111], Loss: 0.4422\n",
      "Epoch [30/100], Step [4/111], Loss: 0.5260\n",
      "Epoch [30/100], Step [6/111], Loss: 0.8156\n",
      "Epoch [30/100], Step [8/111], Loss: 0.5411\n",
      "Epoch [30/100], Step [10/111], Loss: 0.3936\n",
      "Epoch [30/100], Step [12/111], Loss: 0.4255\n",
      "Epoch [30/100], Step [14/111], Loss: 0.4476\n",
      "Epoch [30/100], Step [16/111], Loss: 0.4653\n",
      "Epoch [30/100], Step [18/111], Loss: 0.3584\n",
      "Epoch [30/100], Step [20/111], Loss: 0.2880\n",
      "Epoch [30/100], Step [22/111], Loss: 0.4223\n",
      "Epoch [30/100], Step [24/111], Loss: 0.3734\n",
      "Epoch [30/100], Step [26/111], Loss: 0.5390\n",
      "Epoch [30/100], Step [28/111], Loss: 0.4111\n",
      "Epoch [30/100], Step [30/111], Loss: 2.8128\n",
      "Epoch [30/100], Step [32/111], Loss: 0.4917\n",
      "Epoch [30/100], Step [34/111], Loss: 1.7816\n",
      "Epoch [30/100], Step [36/111], Loss: 0.9315\n",
      "Epoch [30/100], Step [38/111], Loss: 0.7916\n",
      "Epoch [30/100], Step [40/111], Loss: 0.6670\n",
      "Epoch [30/100], Step [42/111], Loss: 0.8359\n",
      "Epoch [30/100], Step [44/111], Loss: 3.0274\n",
      "Epoch [30/100], Step [46/111], Loss: 0.8228\n",
      "Epoch [30/100], Step [48/111], Loss: 0.7457\n",
      "Epoch [30/100], Step [50/111], Loss: 0.8523\n",
      "Epoch [30/100], Step [52/111], Loss: 0.8050\n",
      "Epoch [30/100], Step [54/111], Loss: 0.9672\n",
      "Epoch [30/100], Step [56/111], Loss: 1.0154\n",
      "Epoch [30/100], Step [58/111], Loss: 0.5959\n",
      "Epoch [30/100], Step [60/111], Loss: 1.0976\n",
      "Epoch [30/100], Step [62/111], Loss: 0.7688\n",
      "Epoch [30/100], Step [64/111], Loss: 0.6024\n",
      "Epoch [30/100], Step [66/111], Loss: 0.6521\n",
      "Epoch [30/100], Step [68/111], Loss: 5.1347\n",
      "Epoch [30/100], Step [70/111], Loss: 0.7120\n",
      "Epoch [30/100], Step [72/111], Loss: 0.8866\n",
      "Epoch [30/100], Step [74/111], Loss: 0.6251\n",
      "Epoch [30/100], Step [76/111], Loss: 0.7645\n",
      "Epoch [30/100], Step [78/111], Loss: 3.9874\n",
      "Epoch [30/100], Step [80/111], Loss: 0.6465\n",
      "Epoch [30/100], Step [82/111], Loss: 0.8116\n",
      "Epoch [30/100], Step [84/111], Loss: 0.8775\n",
      "Epoch [30/100], Step [86/111], Loss: 0.5662\n",
      "Epoch [30/100], Step [88/111], Loss: 0.6232\n",
      "Epoch [30/100], Step [90/111], Loss: 0.7683\n",
      "Epoch [30/100], Step [92/111], Loss: 0.5769\n",
      "Epoch [30/100], Step [94/111], Loss: 0.6967\n",
      "Epoch [30/100], Step [96/111], Loss: 1.1436\n",
      "Epoch [30/100], Step [98/111], Loss: 0.6556\n",
      "Epoch [30/100], Step [100/111], Loss: 0.4487\n",
      "Epoch [30/100], Step [102/111], Loss: 0.6185\n",
      "Epoch [30/100], Step [104/111], Loss: 0.6278\n",
      "Epoch [30/100], Step [106/111], Loss: 0.7431\n",
      "Epoch [30/100], Step [108/111], Loss: 1.2471\n",
      "Epoch [30/100], Step [110/111], Loss: 0.4732\n",
      "Epoch [31/100], Step [2/111], Loss: 0.6845\n",
      "Epoch [31/100], Step [4/111], Loss: 1.0624\n",
      "Epoch [31/100], Step [6/111], Loss: 0.6313\n",
      "Epoch [31/100], Step [8/111], Loss: 0.5761\n",
      "Epoch [31/100], Step [10/111], Loss: 0.4882\n",
      "Epoch [31/100], Step [12/111], Loss: 0.7840\n",
      "Epoch [31/100], Step [14/111], Loss: 0.5601\n",
      "Epoch [31/100], Step [16/111], Loss: 0.6599\n",
      "Epoch [31/100], Step [18/111], Loss: 0.6951\n",
      "Epoch [31/100], Step [20/111], Loss: 0.7872\n",
      "Epoch [31/100], Step [22/111], Loss: 0.5005\n",
      "Epoch [31/100], Step [24/111], Loss: 0.8981\n",
      "Epoch [31/100], Step [26/111], Loss: 0.6352\n",
      "Epoch [31/100], Step [28/111], Loss: 0.6212\n",
      "Epoch [31/100], Step [30/111], Loss: 0.8260\n",
      "Epoch [31/100], Step [32/111], Loss: 0.7248\n",
      "Epoch [31/100], Step [34/111], Loss: 0.6717\n",
      "Epoch [31/100], Step [36/111], Loss: 0.6397\n",
      "Epoch [31/100], Step [38/111], Loss: 0.4138\n",
      "Epoch [31/100], Step [40/111], Loss: 0.5126\n",
      "Epoch [31/100], Step [42/111], Loss: 0.4166\n",
      "Epoch [31/100], Step [44/111], Loss: 0.6139\n",
      "Epoch [31/100], Step [46/111], Loss: 0.4975\n",
      "Epoch [31/100], Step [48/111], Loss: 0.5005\n",
      "Epoch [31/100], Step [50/111], Loss: 0.4627\n",
      "Epoch [31/100], Step [52/111], Loss: 0.4916\n",
      "Epoch [31/100], Step [54/111], Loss: 0.6322\n",
      "Epoch [31/100], Step [56/111], Loss: 0.4459\n",
      "Epoch [31/100], Step [58/111], Loss: 0.6039\n",
      "Epoch [31/100], Step [60/111], Loss: 0.3883\n",
      "Epoch [31/100], Step [62/111], Loss: 0.3946\n",
      "Epoch [31/100], Step [64/111], Loss: 0.7210\n",
      "Epoch [31/100], Step [66/111], Loss: 0.7357\n",
      "Epoch [31/100], Step [68/111], Loss: 0.9217\n",
      "Epoch [31/100], Step [70/111], Loss: 0.5205\n",
      "Epoch [31/100], Step [72/111], Loss: 1.1017\n",
      "Epoch [31/100], Step [74/111], Loss: 0.6271\n",
      "Epoch [31/100], Step [76/111], Loss: 0.6580\n",
      "Epoch [31/100], Step [78/111], Loss: 0.4219\n",
      "Epoch [31/100], Step [80/111], Loss: 0.6531\n",
      "Epoch [31/100], Step [82/111], Loss: 0.5192\n",
      "Epoch [31/100], Step [84/111], Loss: 0.5051\n",
      "Epoch [31/100], Step [86/111], Loss: 0.6811\n",
      "Epoch [31/100], Step [88/111], Loss: 0.6492\n",
      "Epoch [31/100], Step [90/111], Loss: 0.5068\n",
      "Epoch [31/100], Step [92/111], Loss: 0.6038\n",
      "Epoch [31/100], Step [94/111], Loss: 0.5768\n",
      "Epoch [31/100], Step [96/111], Loss: 0.5034\n",
      "Epoch [31/100], Step [98/111], Loss: 0.4708\n",
      "Epoch [31/100], Step [100/111], Loss: 0.6877\n",
      "Epoch [31/100], Step [102/111], Loss: 0.5950\n",
      "Epoch [31/100], Step [104/111], Loss: 0.6187\n",
      "Epoch [31/100], Step [106/111], Loss: 0.6125\n",
      "Epoch [31/100], Step [108/111], Loss: 0.5010\n",
      "Epoch [31/100], Step [110/111], Loss: 0.4681\n",
      "Epoch [32/100], Step [2/111], Loss: 1.5217\n",
      "Epoch [32/100], Step [4/111], Loss: 1.5601\n",
      "Epoch [32/100], Step [6/111], Loss: 0.6216\n",
      "Epoch [32/100], Step [8/111], Loss: 0.7877\n",
      "Epoch [32/100], Step [10/111], Loss: 0.7039\n",
      "Epoch [32/100], Step [12/111], Loss: 0.7481\n",
      "Epoch [32/100], Step [14/111], Loss: 0.8050\n",
      "Epoch [32/100], Step [16/111], Loss: 0.6427\n",
      "Epoch [32/100], Step [18/111], Loss: 0.4226\n",
      "Epoch [32/100], Step [20/111], Loss: 0.6524\n",
      "Epoch [32/100], Step [22/111], Loss: 0.6726\n",
      "Epoch [32/100], Step [24/111], Loss: 0.6912\n",
      "Epoch [32/100], Step [26/111], Loss: 0.7128\n",
      "Epoch [32/100], Step [28/111], Loss: 0.9850\n",
      "Epoch [32/100], Step [30/111], Loss: 0.5270\n",
      "Epoch [32/100], Step [32/111], Loss: 0.5791\n",
      "Epoch [32/100], Step [34/111], Loss: 0.7589\n",
      "Epoch [32/100], Step [36/111], Loss: 0.6398\n",
      "Epoch [32/100], Step [38/111], Loss: 0.4839\n",
      "Epoch [32/100], Step [40/111], Loss: 0.5264\n",
      "Epoch [32/100], Step [42/111], Loss: 0.4712\n",
      "Epoch [32/100], Step [44/111], Loss: 0.8062\n",
      "Epoch [32/100], Step [46/111], Loss: 0.5901\n",
      "Epoch [32/100], Step [48/111], Loss: 0.6501\n",
      "Epoch [32/100], Step [50/111], Loss: 0.4393\n",
      "Epoch [32/100], Step [52/111], Loss: 0.4001\n",
      "Epoch [32/100], Step [54/111], Loss: 0.4368\n",
      "Epoch [32/100], Step [56/111], Loss: 0.5161\n",
      "Epoch [32/100], Step [58/111], Loss: 0.4444\n",
      "Epoch [32/100], Step [60/111], Loss: 0.7189\n",
      "Epoch [32/100], Step [62/111], Loss: 0.4615\n",
      "Epoch [32/100], Step [64/111], Loss: 0.6289\n",
      "Epoch [32/100], Step [66/111], Loss: 0.5626\n",
      "Epoch [32/100], Step [68/111], Loss: 0.4581\n",
      "Epoch [32/100], Step [70/111], Loss: 0.8521\n",
      "Epoch [32/100], Step [72/111], Loss: 1.1175\n",
      "Epoch [32/100], Step [74/111], Loss: 0.3987\n",
      "Epoch [32/100], Step [76/111], Loss: 0.6130\n",
      "Epoch [32/100], Step [78/111], Loss: 0.5060\n",
      "Epoch [32/100], Step [80/111], Loss: 3.1783\n",
      "Epoch [32/100], Step [82/111], Loss: 0.5129\n",
      "Epoch [32/100], Step [84/111], Loss: 0.6386\n",
      "Epoch [32/100], Step [86/111], Loss: 0.5139\n",
      "Epoch [32/100], Step [88/111], Loss: 0.6451\n",
      "Epoch [32/100], Step [90/111], Loss: 0.5310\n",
      "Epoch [32/100], Step [92/111], Loss: 0.5528\n",
      "Epoch [32/100], Step [94/111], Loss: 0.7040\n",
      "Epoch [32/100], Step [96/111], Loss: 0.7390\n",
      "Epoch [32/100], Step [98/111], Loss: 0.4781\n",
      "Epoch [32/100], Step [100/111], Loss: 0.5302\n",
      "Epoch [32/100], Step [102/111], Loss: 0.4758\n",
      "Epoch [32/100], Step [104/111], Loss: 0.4898\n",
      "Epoch [32/100], Step [106/111], Loss: 0.9517\n",
      "Epoch [32/100], Step [108/111], Loss: 3.5834\n",
      "Epoch [32/100], Step [110/111], Loss: 0.6153\n",
      "Epoch [33/100], Step [2/111], Loss: 0.5815\n",
      "Epoch [33/100], Step [4/111], Loss: 0.4599\n",
      "Epoch [33/100], Step [6/111], Loss: 0.4821\n",
      "Epoch [33/100], Step [8/111], Loss: 0.9559\n",
      "Epoch [33/100], Step [10/111], Loss: 0.4981\n",
      "Epoch [33/100], Step [12/111], Loss: 0.5374\n",
      "Epoch [33/100], Step [14/111], Loss: 0.5250\n",
      "Epoch [33/100], Step [16/111], Loss: 0.4675\n",
      "Epoch [33/100], Step [18/111], Loss: 0.3671\n",
      "Epoch [33/100], Step [20/111], Loss: 0.7092\n",
      "Epoch [33/100], Step [22/111], Loss: 0.4708\n",
      "Epoch [33/100], Step [24/111], Loss: 0.3472\n",
      "Epoch [33/100], Step [26/111], Loss: 1.3399\n",
      "Epoch [33/100], Step [28/111], Loss: 0.3900\n",
      "Epoch [33/100], Step [30/111], Loss: 0.4766\n",
      "Epoch [33/100], Step [32/111], Loss: 0.8031\n",
      "Epoch [33/100], Step [34/111], Loss: 0.4892\n",
      "Epoch [33/100], Step [36/111], Loss: 0.4715\n",
      "Epoch [33/100], Step [38/111], Loss: 0.4083\n",
      "Epoch [33/100], Step [40/111], Loss: 0.6086\n",
      "Epoch [33/100], Step [42/111], Loss: 0.3336\n",
      "Epoch [33/100], Step [44/111], Loss: 0.4805\n",
      "Epoch [33/100], Step [46/111], Loss: 0.3920\n",
      "Epoch [33/100], Step [48/111], Loss: 2.4110\n",
      "Epoch [33/100], Step [50/111], Loss: 0.3454\n",
      "Epoch [33/100], Step [52/111], Loss: 0.7089\n",
      "Epoch [33/100], Step [54/111], Loss: 0.4606\n",
      "Epoch [33/100], Step [56/111], Loss: 0.4392\n",
      "Epoch [33/100], Step [58/111], Loss: 0.5847\n",
      "Epoch [33/100], Step [60/111], Loss: 0.3107\n",
      "Epoch [33/100], Step [62/111], Loss: 0.4240\n",
      "Epoch [33/100], Step [64/111], Loss: 0.5137\n",
      "Epoch [33/100], Step [66/111], Loss: 0.3309\n",
      "Epoch [33/100], Step [68/111], Loss: 0.5134\n",
      "Epoch [33/100], Step [70/111], Loss: 0.8303\n",
      "Epoch [33/100], Step [72/111], Loss: 0.4703\n",
      "Epoch [33/100], Step [74/111], Loss: 0.4435\n",
      "Epoch [33/100], Step [76/111], Loss: 0.4927\n",
      "Epoch [33/100], Step [78/111], Loss: 0.5269\n",
      "Epoch [33/100], Step [80/111], Loss: 0.4041\n",
      "Epoch [33/100], Step [82/111], Loss: 0.5146\n",
      "Epoch [33/100], Step [84/111], Loss: 0.4727\n",
      "Epoch [33/100], Step [86/111], Loss: 0.5205\n",
      "Epoch [33/100], Step [88/111], Loss: 0.5484\n",
      "Epoch [33/100], Step [90/111], Loss: 0.4379\n",
      "Epoch [33/100], Step [92/111], Loss: 0.6294\n",
      "Epoch [33/100], Step [94/111], Loss: 0.4119\n",
      "Epoch [33/100], Step [96/111], Loss: 0.5544\n",
      "Epoch [33/100], Step [98/111], Loss: 0.4422\n",
      "Epoch [33/100], Step [100/111], Loss: 0.6007\n",
      "Epoch [33/100], Step [102/111], Loss: 0.4355\n",
      "Epoch [33/100], Step [104/111], Loss: 0.4872\n",
      "Epoch [33/100], Step [106/111], Loss: 0.3476\n",
      "Epoch [33/100], Step [108/111], Loss: 4.3301\n",
      "Epoch [33/100], Step [110/111], Loss: 4.9224\n",
      "Epoch [34/100], Step [2/111], Loss: 0.3471\n",
      "Epoch [34/100], Step [4/111], Loss: 0.4469\n",
      "Epoch [34/100], Step [6/111], Loss: 0.5050\n",
      "Epoch [34/100], Step [8/111], Loss: 0.4189\n",
      "Epoch [34/100], Step [10/111], Loss: 2.2355\n",
      "Epoch [34/100], Step [12/111], Loss: 0.3954\n",
      "Epoch [34/100], Step [14/111], Loss: 0.5166\n",
      "Epoch [34/100], Step [16/111], Loss: 0.4513\n",
      "Epoch [34/100], Step [18/111], Loss: 0.5782\n",
      "Epoch [34/100], Step [20/111], Loss: 0.4029\n",
      "Epoch [34/100], Step [22/111], Loss: 0.4639\n",
      "Epoch [34/100], Step [24/111], Loss: 0.3774\n",
      "Epoch [34/100], Step [26/111], Loss: 0.3832\n",
      "Epoch [34/100], Step [28/111], Loss: 1.4581\n",
      "Epoch [34/100], Step [30/111], Loss: 0.9069\n",
      "Epoch [34/100], Step [32/111], Loss: 0.4216\n",
      "Epoch [34/100], Step [34/111], Loss: 0.7715\n",
      "Epoch [34/100], Step [36/111], Loss: 0.6529\n",
      "Epoch [34/100], Step [38/111], Loss: 0.5314\n",
      "Epoch [34/100], Step [40/111], Loss: 0.5839\n",
      "Epoch [34/100], Step [42/111], Loss: 0.5013\n",
      "Epoch [34/100], Step [44/111], Loss: 0.6434\n",
      "Epoch [34/100], Step [46/111], Loss: 0.4322\n",
      "Epoch [34/100], Step [48/111], Loss: 0.3296\n",
      "Epoch [34/100], Step [50/111], Loss: 0.3627\n",
      "Epoch [34/100], Step [52/111], Loss: 0.3915\n",
      "Epoch [34/100], Step [54/111], Loss: 0.4682\n",
      "Epoch [34/100], Step [56/111], Loss: 0.4006\n",
      "Epoch [34/100], Step [58/111], Loss: 0.4068\n",
      "Epoch [34/100], Step [60/111], Loss: 0.4145\n",
      "Epoch [34/100], Step [62/111], Loss: 0.5272\n",
      "Epoch [34/100], Step [64/111], Loss: 0.6097\n",
      "Epoch [34/100], Step [66/111], Loss: 0.4652\n",
      "Epoch [34/100], Step [68/111], Loss: 0.4023\n",
      "Epoch [34/100], Step [70/111], Loss: 0.4026\n",
      "Epoch [34/100], Step [72/111], Loss: 0.4711\n",
      "Epoch [34/100], Step [74/111], Loss: 0.6698\n",
      "Epoch [34/100], Step [76/111], Loss: 0.3156\n",
      "Epoch [34/100], Step [78/111], Loss: 0.4119\n",
      "Epoch [34/100], Step [80/111], Loss: 0.4536\n",
      "Epoch [34/100], Step [82/111], Loss: 0.4717\n",
      "Epoch [34/100], Step [84/111], Loss: 0.3668\n",
      "Epoch [34/100], Step [86/111], Loss: 2.8703\n",
      "Epoch [34/100], Step [88/111], Loss: 0.9571\n",
      "Epoch [34/100], Step [90/111], Loss: 0.3035\n",
      "Epoch [34/100], Step [92/111], Loss: 0.3780\n",
      "Epoch [34/100], Step [94/111], Loss: 0.3125\n",
      "Epoch [34/100], Step [96/111], Loss: 0.4243\n",
      "Epoch [34/100], Step [98/111], Loss: 0.3930\n",
      "Epoch [34/100], Step [100/111], Loss: 0.5844\n",
      "Epoch [34/100], Step [102/111], Loss: 0.4508\n",
      "Epoch [34/100], Step [104/111], Loss: 0.3333\n",
      "Epoch [34/100], Step [106/111], Loss: 0.3568\n",
      "Epoch [34/100], Step [108/111], Loss: 0.5046\n",
      "Epoch [34/100], Step [110/111], Loss: 0.3374\n",
      "Epoch [35/100], Step [2/111], Loss: 0.2685\n",
      "Epoch [35/100], Step [4/111], Loss: 0.2875\n",
      "Epoch [35/100], Step [6/111], Loss: 0.3314\n",
      "Epoch [35/100], Step [8/111], Loss: 0.3574\n",
      "Epoch [35/100], Step [10/111], Loss: 0.5514\n",
      "Epoch [35/100], Step [12/111], Loss: 0.3420\n",
      "Epoch [35/100], Step [14/111], Loss: 0.3068\n",
      "Epoch [35/100], Step [16/111], Loss: 0.3122\n",
      "Epoch [35/100], Step [18/111], Loss: 0.6919\n",
      "Epoch [35/100], Step [20/111], Loss: 0.3458\n",
      "Epoch [35/100], Step [22/111], Loss: 0.3929\n",
      "Epoch [35/100], Step [24/111], Loss: 0.3084\n",
      "Epoch [35/100], Step [26/111], Loss: 0.3373\n",
      "Epoch [35/100], Step [28/111], Loss: 0.3920\n",
      "Epoch [35/100], Step [30/111], Loss: 0.5312\n",
      "Epoch [35/100], Step [32/111], Loss: 0.5153\n",
      "Epoch [35/100], Step [34/111], Loss: 0.2966\n",
      "Epoch [35/100], Step [36/111], Loss: 0.4971\n",
      "Epoch [35/100], Step [38/111], Loss: 0.2915\n",
      "Epoch [35/100], Step [40/111], Loss: 0.3895\n",
      "Epoch [35/100], Step [42/111], Loss: 0.3523\n",
      "Epoch [35/100], Step [44/111], Loss: 0.4864\n",
      "Epoch [35/100], Step [46/111], Loss: 0.8156\n",
      "Epoch [35/100], Step [48/111], Loss: 0.3694\n",
      "Epoch [35/100], Step [50/111], Loss: 0.3723\n",
      "Epoch [35/100], Step [52/111], Loss: 0.3305\n",
      "Epoch [35/100], Step [54/111], Loss: 0.3290\n",
      "Epoch [35/100], Step [56/111], Loss: 0.6079\n",
      "Epoch [35/100], Step [58/111], Loss: 0.4491\n",
      "Epoch [35/100], Step [60/111], Loss: 0.2944\n",
      "Epoch [35/100], Step [62/111], Loss: 0.3687\n",
      "Epoch [35/100], Step [64/111], Loss: 2.0417\n",
      "Epoch [35/100], Step [66/111], Loss: 0.4707\n",
      "Epoch [35/100], Step [68/111], Loss: 0.4180\n",
      "Epoch [35/100], Step [70/111], Loss: 0.3394\n",
      "Epoch [35/100], Step [72/111], Loss: 0.4402\n",
      "Epoch [35/100], Step [74/111], Loss: 0.2696\n",
      "Epoch [35/100], Step [76/111], Loss: 3.4961\n",
      "Epoch [35/100], Step [78/111], Loss: 0.6457\n",
      "Epoch [35/100], Step [80/111], Loss: 0.6029\n",
      "Epoch [35/100], Step [82/111], Loss: 0.4566\n",
      "Epoch [35/100], Step [84/111], Loss: 0.4622\n",
      "Epoch [35/100], Step [86/111], Loss: 0.3690\n",
      "Epoch [35/100], Step [88/111], Loss: 0.6146\n",
      "Epoch [35/100], Step [90/111], Loss: 0.4037\n",
      "Epoch [35/100], Step [92/111], Loss: 0.4635\n",
      "Epoch [35/100], Step [94/111], Loss: 0.5975\n",
      "Epoch [35/100], Step [96/111], Loss: 0.3516\n",
      "Epoch [35/100], Step [98/111], Loss: 0.3842\n",
      "Epoch [35/100], Step [100/111], Loss: 0.4020\n",
      "Epoch [35/100], Step [102/111], Loss: 0.4719\n",
      "Epoch [35/100], Step [104/111], Loss: 0.4090\n",
      "Epoch [35/100], Step [106/111], Loss: 0.6260\n",
      "Epoch [35/100], Step [108/111], Loss: 0.3072\n",
      "Epoch [35/100], Step [110/111], Loss: 0.3961\n",
      "Epoch [36/100], Step [2/111], Loss: 0.4364\n",
      "Epoch [36/100], Step [4/111], Loss: 0.3880\n",
      "Epoch [36/100], Step [6/111], Loss: 0.3383\n",
      "Epoch [36/100], Step [8/111], Loss: 0.3265\n",
      "Epoch [36/100], Step [10/111], Loss: 0.3299\n",
      "Epoch [36/100], Step [12/111], Loss: 0.5868\n",
      "Epoch [36/100], Step [14/111], Loss: 0.2864\n",
      "Epoch [36/100], Step [16/111], Loss: 0.3604\n",
      "Epoch [36/100], Step [18/111], Loss: 0.2346\n",
      "Epoch [36/100], Step [20/111], Loss: 0.4288\n",
      "Epoch [36/100], Step [22/111], Loss: 0.3740\n",
      "Epoch [36/100], Step [24/111], Loss: 0.2551\n",
      "Epoch [36/100], Step [26/111], Loss: 0.3081\n",
      "Epoch [36/100], Step [28/111], Loss: 0.3772\n",
      "Epoch [36/100], Step [30/111], Loss: 0.2963\n",
      "Epoch [36/100], Step [32/111], Loss: 0.5024\n",
      "Epoch [36/100], Step [34/111], Loss: 0.5370\n",
      "Epoch [36/100], Step [36/111], Loss: 0.2649\n",
      "Epoch [36/100], Step [38/111], Loss: 0.4609\n",
      "Epoch [36/100], Step [40/111], Loss: 0.3110\n",
      "Epoch [36/100], Step [42/111], Loss: 2.5551\n",
      "Epoch [36/100], Step [44/111], Loss: 0.4584\n",
      "Epoch [36/100], Step [46/111], Loss: 0.5039\n",
      "Epoch [36/100], Step [48/111], Loss: 0.4510\n",
      "Epoch [36/100], Step [50/111], Loss: 0.5412\n",
      "Epoch [36/100], Step [52/111], Loss: 0.3454\n",
      "Epoch [36/100], Step [54/111], Loss: 0.3928\n",
      "Epoch [36/100], Step [56/111], Loss: 0.3538\n",
      "Epoch [36/100], Step [58/111], Loss: 0.3422\n",
      "Epoch [36/100], Step [60/111], Loss: 0.4098\n",
      "Epoch [36/100], Step [62/111], Loss: 0.2929\n",
      "Epoch [36/100], Step [64/111], Loss: 0.4132\n",
      "Epoch [36/100], Step [66/111], Loss: 0.2814\n",
      "Epoch [36/100], Step [68/111], Loss: 0.3002\n",
      "Epoch [36/100], Step [70/111], Loss: 0.3822\n",
      "Epoch [36/100], Step [72/111], Loss: 0.3162\n",
      "Epoch [36/100], Step [74/111], Loss: 0.3643\n",
      "Epoch [36/100], Step [76/111], Loss: 0.3812\n",
      "Epoch [36/100], Step [78/111], Loss: 0.2895\n",
      "Epoch [36/100], Step [80/111], Loss: 0.4658\n",
      "Epoch [36/100], Step [82/111], Loss: 0.3595\n",
      "Epoch [36/100], Step [84/111], Loss: 0.4203\n",
      "Epoch [36/100], Step [86/111], Loss: 1.3304\n",
      "Epoch [36/100], Step [88/111], Loss: 0.4191\n",
      "Epoch [36/100], Step [90/111], Loss: 0.4409\n",
      "Epoch [36/100], Step [92/111], Loss: 0.6371\n",
      "Epoch [36/100], Step [94/111], Loss: 0.3434\n",
      "Epoch [36/100], Step [96/111], Loss: 0.3047\n",
      "Epoch [36/100], Step [98/111], Loss: 0.3390\n",
      "Epoch [36/100], Step [100/111], Loss: 0.6072\n",
      "Epoch [36/100], Step [102/111], Loss: 0.4539\n",
      "Epoch [36/100], Step [104/111], Loss: 0.3309\n",
      "Epoch [36/100], Step [106/111], Loss: 0.3248\n",
      "Epoch [36/100], Step [108/111], Loss: 0.5160\n",
      "Epoch [36/100], Step [110/111], Loss: 0.3445\n",
      "Epoch [37/100], Step [2/111], Loss: 1.1378\n",
      "Epoch [37/100], Step [4/111], Loss: 0.3638\n",
      "Epoch [37/100], Step [6/111], Loss: 0.3757\n",
      "Epoch [37/100], Step [8/111], Loss: 0.3232\n",
      "Epoch [37/100], Step [10/111], Loss: 0.3460\n",
      "Epoch [37/100], Step [12/111], Loss: 0.6444\n",
      "Epoch [37/100], Step [14/111], Loss: 0.3271\n",
      "Epoch [37/100], Step [16/111], Loss: 0.3371\n",
      "Epoch [37/100], Step [18/111], Loss: 0.2845\n",
      "Epoch [37/100], Step [20/111], Loss: 0.5353\n",
      "Epoch [37/100], Step [22/111], Loss: 0.2863\n",
      "Epoch [37/100], Step [24/111], Loss: 0.4329\n",
      "Epoch [37/100], Step [26/111], Loss: 0.4439\n",
      "Epoch [37/100], Step [28/111], Loss: 0.3041\n",
      "Epoch [37/100], Step [30/111], Loss: 0.5167\n",
      "Epoch [37/100], Step [32/111], Loss: 0.3525\n",
      "Epoch [37/100], Step [34/111], Loss: 0.4747\n",
      "Epoch [37/100], Step [36/111], Loss: 0.3948\n",
      "Epoch [37/100], Step [38/111], Loss: 0.2946\n",
      "Epoch [37/100], Step [40/111], Loss: 0.3699\n",
      "Epoch [37/100], Step [42/111], Loss: 0.3045\n",
      "Epoch [37/100], Step [44/111], Loss: 0.4160\n",
      "Epoch [37/100], Step [46/111], Loss: 0.3276\n",
      "Epoch [37/100], Step [48/111], Loss: 0.4388\n",
      "Epoch [37/100], Step [50/111], Loss: 0.2719\n",
      "Epoch [37/100], Step [52/111], Loss: 0.3253\n",
      "Epoch [37/100], Step [54/111], Loss: 0.4757\n",
      "Epoch [37/100], Step [56/111], Loss: 0.3972\n",
      "Epoch [37/100], Step [58/111], Loss: 0.2666\n",
      "Epoch [37/100], Step [60/111], Loss: 0.3978\n",
      "Epoch [37/100], Step [62/111], Loss: 0.3765\n",
      "Epoch [37/100], Step [64/111], Loss: 0.3336\n",
      "Epoch [37/100], Step [66/111], Loss: 0.4893\n",
      "Epoch [37/100], Step [68/111], Loss: 0.4367\n",
      "Epoch [37/100], Step [70/111], Loss: 0.3507\n",
      "Epoch [37/100], Step [72/111], Loss: 0.3493\n",
      "Epoch [37/100], Step [74/111], Loss: 0.3869\n",
      "Epoch [37/100], Step [76/111], Loss: 0.3479\n",
      "Epoch [37/100], Step [78/111], Loss: 0.3208\n",
      "Epoch [37/100], Step [80/111], Loss: 0.6636\n",
      "Epoch [37/100], Step [82/111], Loss: 0.5874\n",
      "Epoch [37/100], Step [84/111], Loss: 0.3352\n",
      "Epoch [37/100], Step [86/111], Loss: 0.3286\n",
      "Epoch [37/100], Step [88/111], Loss: 0.4545\n",
      "Epoch [37/100], Step [90/111], Loss: 0.3227\n",
      "Epoch [37/100], Step [92/111], Loss: 0.3050\n",
      "Epoch [37/100], Step [94/111], Loss: 0.6302\n",
      "Epoch [37/100], Step [96/111], Loss: 0.2707\n",
      "Epoch [37/100], Step [98/111], Loss: 0.3814\n",
      "Epoch [37/100], Step [100/111], Loss: 0.2557\n",
      "Epoch [37/100], Step [102/111], Loss: 0.4428\n",
      "Epoch [37/100], Step [104/111], Loss: 0.3308\n",
      "Epoch [37/100], Step [106/111], Loss: 0.4368\n",
      "Epoch [37/100], Step [108/111], Loss: 0.4294\n",
      "Epoch [37/100], Step [110/111], Loss: 0.3203\n",
      "Epoch [38/100], Step [2/111], Loss: 0.3313\n",
      "Epoch [38/100], Step [4/111], Loss: 0.4433\n",
      "Epoch [38/100], Step [6/111], Loss: 0.3078\n",
      "Epoch [38/100], Step [8/111], Loss: 0.3339\n",
      "Epoch [38/100], Step [10/111], Loss: 0.2461\n",
      "Epoch [38/100], Step [12/111], Loss: 1.7884\n",
      "Epoch [38/100], Step [14/111], Loss: 0.3233\n",
      "Epoch [38/100], Step [16/111], Loss: 0.2212\n",
      "Epoch [38/100], Step [18/111], Loss: 0.4162\n",
      "Epoch [38/100], Step [20/111], Loss: 0.3693\n",
      "Epoch [38/100], Step [22/111], Loss: 0.3768\n",
      "Epoch [38/100], Step [24/111], Loss: 0.3724\n",
      "Epoch [38/100], Step [26/111], Loss: 0.8588\n",
      "Epoch [38/100], Step [28/111], Loss: 0.4327\n",
      "Epoch [38/100], Step [30/111], Loss: 0.4370\n",
      "Epoch [38/100], Step [32/111], Loss: 0.3359\n",
      "Epoch [38/100], Step [34/111], Loss: 0.5208\n",
      "Epoch [38/100], Step [36/111], Loss: 0.3710\n",
      "Epoch [38/100], Step [38/111], Loss: 0.3087\n",
      "Epoch [38/100], Step [40/111], Loss: 0.4888\n",
      "Epoch [38/100], Step [42/111], Loss: 0.2223\n",
      "Epoch [38/100], Step [44/111], Loss: 0.3182\n",
      "Epoch [38/100], Step [46/111], Loss: 0.3643\n",
      "Epoch [38/100], Step [48/111], Loss: 0.3371\n",
      "Epoch [38/100], Step [50/111], Loss: 0.3606\n",
      "Epoch [38/100], Step [52/111], Loss: 0.6085\n",
      "Epoch [38/100], Step [54/111], Loss: 0.3887\n",
      "Epoch [38/100], Step [56/111], Loss: 0.4266\n",
      "Epoch [38/100], Step [58/111], Loss: 0.3748\n",
      "Epoch [38/100], Step [60/111], Loss: 0.4071\n",
      "Epoch [38/100], Step [62/111], Loss: 3.4091\n",
      "Epoch [38/100], Step [64/111], Loss: 0.5407\n",
      "Epoch [38/100], Step [66/111], Loss: 0.4546\n",
      "Epoch [38/100], Step [68/111], Loss: 0.3427\n",
      "Epoch [38/100], Step [70/111], Loss: 0.3078\n",
      "Epoch [38/100], Step [72/111], Loss: 0.3839\n",
      "Epoch [38/100], Step [74/111], Loss: 0.3563\n",
      "Epoch [38/100], Step [76/111], Loss: 0.6210\n",
      "Epoch [38/100], Step [78/111], Loss: 0.2333\n",
      "Epoch [38/100], Step [80/111], Loss: 0.3737\n",
      "Epoch [38/100], Step [82/111], Loss: 0.2976\n",
      "Epoch [38/100], Step [84/111], Loss: 0.2952\n",
      "Epoch [38/100], Step [86/111], Loss: 0.3757\n",
      "Epoch [38/100], Step [88/111], Loss: 0.3220\n",
      "Epoch [38/100], Step [90/111], Loss: 0.2239\n",
      "Epoch [38/100], Step [92/111], Loss: 0.3624\n",
      "Epoch [38/100], Step [94/111], Loss: 3.8612\n",
      "Epoch [38/100], Step [96/111], Loss: 0.3450\n",
      "Epoch [38/100], Step [98/111], Loss: 0.3644\n",
      "Epoch [38/100], Step [100/111], Loss: 0.3096\n",
      "Epoch [38/100], Step [102/111], Loss: 0.2486\n",
      "Epoch [38/100], Step [104/111], Loss: 0.3218\n",
      "Epoch [38/100], Step [106/111], Loss: 0.3149\n",
      "Epoch [38/100], Step [108/111], Loss: 0.2530\n",
      "Epoch [38/100], Step [110/111], Loss: 0.4448\n",
      "Epoch [39/100], Step [2/111], Loss: 0.3338\n",
      "Epoch [39/100], Step [4/111], Loss: 0.3471\n",
      "Epoch [39/100], Step [6/111], Loss: 0.2571\n",
      "Epoch [39/100], Step [8/111], Loss: 0.2985\n",
      "Epoch [39/100], Step [10/111], Loss: 0.2475\n",
      "Epoch [39/100], Step [12/111], Loss: 0.3512\n",
      "Epoch [39/100], Step [14/111], Loss: 0.3774\n",
      "Epoch [39/100], Step [16/111], Loss: 0.2682\n",
      "Epoch [39/100], Step [18/111], Loss: 0.2220\n",
      "Epoch [39/100], Step [20/111], Loss: 0.2949\n",
      "Epoch [39/100], Step [22/111], Loss: 0.4250\n",
      "Epoch [39/100], Step [24/111], Loss: 0.2937\n",
      "Epoch [39/100], Step [26/111], Loss: 0.2526\n",
      "Epoch [39/100], Step [28/111], Loss: 3.8379\n",
      "Epoch [39/100], Step [30/111], Loss: 0.3488\n",
      "Epoch [39/100], Step [32/111], Loss: 0.3428\n",
      "Epoch [39/100], Step [34/111], Loss: 0.3168\n",
      "Epoch [39/100], Step [36/111], Loss: 0.3463\n",
      "Epoch [39/100], Step [38/111], Loss: 0.2662\n",
      "Epoch [39/100], Step [40/111], Loss: 0.4777\n",
      "Epoch [39/100], Step [42/111], Loss: 0.3239\n",
      "Epoch [39/100], Step [44/111], Loss: 0.3065\n",
      "Epoch [39/100], Step [46/111], Loss: 0.3488\n",
      "Epoch [39/100], Step [48/111], Loss: 0.2622\n",
      "Epoch [39/100], Step [50/111], Loss: 0.2681\n",
      "Epoch [39/100], Step [52/111], Loss: 0.2798\n",
      "Epoch [39/100], Step [54/111], Loss: 0.3143\n",
      "Epoch [39/100], Step [56/111], Loss: 0.3105\n",
      "Epoch [39/100], Step [58/111], Loss: 0.2849\n",
      "Epoch [39/100], Step [60/111], Loss: 0.2866\n",
      "Epoch [39/100], Step [62/111], Loss: 0.3045\n",
      "Epoch [39/100], Step [64/111], Loss: 0.2380\n",
      "Epoch [39/100], Step [66/111], Loss: 0.4403\n",
      "Epoch [39/100], Step [68/111], Loss: 0.2996\n",
      "Epoch [39/100], Step [70/111], Loss: 0.2561\n",
      "Epoch [39/100], Step [72/111], Loss: 0.3876\n",
      "Epoch [39/100], Step [74/111], Loss: 0.2562\n",
      "Epoch [39/100], Step [76/111], Loss: 0.2304\n",
      "Epoch [39/100], Step [78/111], Loss: 0.4084\n",
      "Epoch [39/100], Step [80/111], Loss: 0.5397\n",
      "Epoch [39/100], Step [82/111], Loss: 0.3749\n",
      "Epoch [39/100], Step [84/111], Loss: 0.3525\n",
      "Epoch [39/100], Step [86/111], Loss: 0.3590\n",
      "Epoch [39/100], Step [88/111], Loss: 0.4773\n",
      "Epoch [39/100], Step [90/111], Loss: 0.3678\n",
      "Epoch [39/100], Step [92/111], Loss: 0.4363\n",
      "Epoch [39/100], Step [94/111], Loss: 0.5256\n",
      "Epoch [39/100], Step [96/111], Loss: 0.2648\n",
      "Epoch [39/100], Step [98/111], Loss: 0.4190\n",
      "Epoch [39/100], Step [100/111], Loss: 0.3812\n",
      "Epoch [39/100], Step [102/111], Loss: 0.4758\n",
      "Epoch [39/100], Step [104/111], Loss: 0.4709\n",
      "Epoch [39/100], Step [106/111], Loss: 0.2903\n",
      "Epoch [39/100], Step [108/111], Loss: 0.4002\n",
      "Epoch [39/100], Step [110/111], Loss: 0.2710\n",
      "Epoch [40/100], Step [2/111], Loss: 0.6085\n",
      "Epoch [40/100], Step [4/111], Loss: 0.2855\n",
      "Epoch [40/100], Step [6/111], Loss: 2.5408\n",
      "Epoch [40/100], Step [8/111], Loss: 0.3290\n",
      "Epoch [40/100], Step [10/111], Loss: 3.9736\n",
      "Epoch [40/100], Step [12/111], Loss: 0.3874\n",
      "Epoch [40/100], Step [14/111], Loss: 0.4344\n",
      "Epoch [40/100], Step [16/111], Loss: 0.5660\n",
      "Epoch [40/100], Step [18/111], Loss: 1.0703\n",
      "Epoch [40/100], Step [20/111], Loss: 0.4055\n",
      "Epoch [40/100], Step [22/111], Loss: 0.2766\n",
      "Epoch [40/100], Step [24/111], Loss: 0.4476\n",
      "Epoch [40/100], Step [26/111], Loss: 0.4249\n",
      "Epoch [40/100], Step [28/111], Loss: 0.2365\n",
      "Epoch [40/100], Step [30/111], Loss: 0.4179\n",
      "Epoch [40/100], Step [32/111], Loss: 1.2603\n",
      "Epoch [40/100], Step [34/111], Loss: 0.2941\n",
      "Epoch [40/100], Step [36/111], Loss: 0.4379\n",
      "Epoch [40/100], Step [38/111], Loss: 0.4125\n",
      "Epoch [40/100], Step [40/111], Loss: 0.4018\n",
      "Epoch [40/100], Step [42/111], Loss: 0.4045\n",
      "Epoch [40/100], Step [44/111], Loss: 0.3941\n",
      "Epoch [40/100], Step [46/111], Loss: 0.3708\n",
      "Epoch [40/100], Step [48/111], Loss: 0.3168\n",
      "Epoch [40/100], Step [50/111], Loss: 0.3474\n",
      "Epoch [40/100], Step [52/111], Loss: 0.3066\n",
      "Epoch [40/100], Step [54/111], Loss: 0.3074\n",
      "Epoch [40/100], Step [56/111], Loss: 0.2957\n",
      "Epoch [40/100], Step [58/111], Loss: 0.3187\n",
      "Epoch [40/100], Step [60/111], Loss: 0.3324\n",
      "Epoch [40/100], Step [62/111], Loss: 0.2880\n",
      "Epoch [40/100], Step [64/111], Loss: 0.2685\n",
      "Epoch [40/100], Step [66/111], Loss: 0.4226\n",
      "Epoch [40/100], Step [68/111], Loss: 0.4400\n",
      "Epoch [40/100], Step [70/111], Loss: 0.4046\n",
      "Epoch [40/100], Step [72/111], Loss: 0.3066\n",
      "Epoch [40/100], Step [74/111], Loss: 0.3706\n",
      "Epoch [40/100], Step [76/111], Loss: 0.4099\n",
      "Epoch [40/100], Step [78/111], Loss: 2.9424\n",
      "Epoch [40/100], Step [80/111], Loss: 0.3435\n",
      "Epoch [40/100], Step [82/111], Loss: 0.3165\n",
      "Epoch [40/100], Step [84/111], Loss: 0.4225\n",
      "Epoch [40/100], Step [86/111], Loss: 0.2918\n",
      "Epoch [40/100], Step [88/111], Loss: 0.3006\n",
      "Epoch [40/100], Step [90/111], Loss: 3.2124\n",
      "Epoch [40/100], Step [92/111], Loss: 0.3162\n",
      "Epoch [40/100], Step [94/111], Loss: 0.1928\n",
      "Epoch [40/100], Step [96/111], Loss: 0.3663\n",
      "Epoch [40/100], Step [98/111], Loss: 0.3106\n",
      "Epoch [40/100], Step [100/111], Loss: 0.6540\n",
      "Epoch [40/100], Step [102/111], Loss: 0.3484\n",
      "Epoch [40/100], Step [104/111], Loss: 0.3417\n",
      "Epoch [40/100], Step [106/111], Loss: 0.5894\n",
      "Epoch [40/100], Step [108/111], Loss: 0.3723\n",
      "Epoch [40/100], Step [110/111], Loss: 0.3989\n",
      "Epoch [41/100], Step [2/111], Loss: 0.5401\n",
      "Epoch [41/100], Step [4/111], Loss: 0.2467\n",
      "Epoch [41/100], Step [6/111], Loss: 0.5425\n",
      "Epoch [41/100], Step [8/111], Loss: 1.7600\n",
      "Epoch [41/100], Step [10/111], Loss: 0.3778\n",
      "Epoch [41/100], Step [12/111], Loss: 0.5578\n",
      "Epoch [41/100], Step [14/111], Loss: 0.4603\n",
      "Epoch [41/100], Step [16/111], Loss: 0.4178\n",
      "Epoch [41/100], Step [18/111], Loss: 0.7035\n",
      "Epoch [41/100], Step [20/111], Loss: 0.3297\n",
      "Epoch [41/100], Step [22/111], Loss: 0.3995\n",
      "Epoch [41/100], Step [24/111], Loss: 0.3244\n",
      "Epoch [41/100], Step [26/111], Loss: 0.3220\n",
      "Epoch [41/100], Step [28/111], Loss: 0.3548\n",
      "Epoch [41/100], Step [30/111], Loss: 0.2958\n",
      "Epoch [41/100], Step [32/111], Loss: 0.3433\n",
      "Epoch [41/100], Step [34/111], Loss: 0.3475\n",
      "Epoch [41/100], Step [36/111], Loss: 0.6301\n",
      "Epoch [41/100], Step [38/111], Loss: 0.5442\n",
      "Epoch [41/100], Step [40/111], Loss: 0.3489\n",
      "Epoch [41/100], Step [42/111], Loss: 0.4530\n",
      "Epoch [41/100], Step [44/111], Loss: 0.2817\n",
      "Epoch [41/100], Step [46/111], Loss: 0.2683\n",
      "Epoch [41/100], Step [48/111], Loss: 0.4193\n",
      "Epoch [41/100], Step [50/111], Loss: 0.3403\n",
      "Epoch [41/100], Step [52/111], Loss: 0.2419\n",
      "Epoch [41/100], Step [54/111], Loss: 0.3035\n",
      "Epoch [41/100], Step [56/111], Loss: 0.3165\n",
      "Epoch [41/100], Step [58/111], Loss: 0.2548\n",
      "Epoch [41/100], Step [60/111], Loss: 0.2254\n",
      "Epoch [41/100], Step [62/111], Loss: 0.7329\n",
      "Epoch [41/100], Step [64/111], Loss: 0.2803\n",
      "Epoch [41/100], Step [66/111], Loss: 0.3431\n",
      "Epoch [41/100], Step [68/111], Loss: 0.4901\n",
      "Epoch [41/100], Step [70/111], Loss: 0.2930\n",
      "Epoch [41/100], Step [72/111], Loss: 0.4476\n",
      "Epoch [41/100], Step [74/111], Loss: 0.3811\n",
      "Epoch [41/100], Step [76/111], Loss: 0.3614\n",
      "Epoch [41/100], Step [78/111], Loss: 0.2860\n",
      "Epoch [41/100], Step [80/111], Loss: 0.2487\n",
      "Epoch [41/100], Step [82/111], Loss: 0.4258\n",
      "Epoch [41/100], Step [84/111], Loss: 0.3932\n",
      "Epoch [41/100], Step [86/111], Loss: 0.7877\n",
      "Epoch [41/100], Step [88/111], Loss: 0.2648\n",
      "Epoch [41/100], Step [90/111], Loss: 0.4473\n",
      "Epoch [41/100], Step [92/111], Loss: 0.3818\n",
      "Epoch [41/100], Step [94/111], Loss: 0.3776\n",
      "Epoch [41/100], Step [96/111], Loss: 0.3950\n",
      "Epoch [41/100], Step [98/111], Loss: 0.3224\n",
      "Epoch [41/100], Step [100/111], Loss: 0.3978\n",
      "Epoch [41/100], Step [102/111], Loss: 0.4591\n",
      "Epoch [41/100], Step [104/111], Loss: 0.3815\n",
      "Epoch [41/100], Step [106/111], Loss: 0.2367\n",
      "Epoch [41/100], Step [108/111], Loss: 0.4031\n",
      "Epoch [41/100], Step [110/111], Loss: 0.4476\n",
      "Epoch [42/100], Step [2/111], Loss: 0.5517\n",
      "Epoch [42/100], Step [4/111], Loss: 0.4144\n",
      "Epoch [42/100], Step [6/111], Loss: 0.3656\n",
      "Epoch [42/100], Step [8/111], Loss: 0.4591\n",
      "Epoch [42/100], Step [10/111], Loss: 0.5269\n",
      "Epoch [42/100], Step [12/111], Loss: 0.3943\n",
      "Epoch [42/100], Step [14/111], Loss: 0.4142\n",
      "Epoch [42/100], Step [16/111], Loss: 0.2636\n",
      "Epoch [42/100], Step [18/111], Loss: 0.2780\n",
      "Epoch [42/100], Step [20/111], Loss: 0.3745\n",
      "Epoch [42/100], Step [22/111], Loss: 0.3261\n",
      "Epoch [42/100], Step [24/111], Loss: 0.5730\n",
      "Epoch [42/100], Step [26/111], Loss: 0.3972\n",
      "Epoch [42/100], Step [28/111], Loss: 0.2666\n",
      "Epoch [42/100], Step [30/111], Loss: 0.3931\n",
      "Epoch [42/100], Step [32/111], Loss: 0.2782\n",
      "Epoch [42/100], Step [34/111], Loss: 0.2593\n",
      "Epoch [42/100], Step [36/111], Loss: 0.2540\n",
      "Epoch [42/100], Step [38/111], Loss: 0.2864\n",
      "Epoch [42/100], Step [40/111], Loss: 0.2236\n",
      "Epoch [42/100], Step [42/111], Loss: 0.2987\n",
      "Epoch [42/100], Step [44/111], Loss: 0.2788\n",
      "Epoch [42/100], Step [46/111], Loss: 0.2508\n",
      "Epoch [42/100], Step [48/111], Loss: 0.2664\n",
      "Epoch [42/100], Step [50/111], Loss: 0.2632\n",
      "Epoch [42/100], Step [52/111], Loss: 0.5089\n",
      "Epoch [42/100], Step [54/111], Loss: 0.2799\n",
      "Epoch [42/100], Step [56/111], Loss: 0.2554\n",
      "Epoch [42/100], Step [58/111], Loss: 0.3008\n",
      "Epoch [42/100], Step [60/111], Loss: 0.2703\n",
      "Epoch [42/100], Step [62/111], Loss: 0.3187\n",
      "Epoch [42/100], Step [64/111], Loss: 0.2175\n",
      "Epoch [42/100], Step [66/111], Loss: 1.2864\n",
      "Epoch [42/100], Step [68/111], Loss: 0.2720\n",
      "Epoch [42/100], Step [70/111], Loss: 0.4205\n",
      "Epoch [42/100], Step [72/111], Loss: 0.3251\n",
      "Epoch [42/100], Step [74/111], Loss: 0.2598\n",
      "Epoch [42/100], Step [76/111], Loss: 0.3366\n",
      "Epoch [42/100], Step [78/111], Loss: 0.5403\n",
      "Epoch [42/100], Step [80/111], Loss: 0.2916\n",
      "Epoch [42/100], Step [82/111], Loss: 0.3349\n",
      "Epoch [42/100], Step [84/111], Loss: 0.2340\n",
      "Epoch [42/100], Step [86/111], Loss: 0.4854\n",
      "Epoch [42/100], Step [88/111], Loss: 0.5213\n",
      "Epoch [42/100], Step [90/111], Loss: 0.3315\n",
      "Epoch [42/100], Step [92/111], Loss: 0.3184\n",
      "Epoch [42/100], Step [94/111], Loss: 0.3471\n",
      "Epoch [42/100], Step [96/111], Loss: 0.5042\n",
      "Epoch [42/100], Step [98/111], Loss: 0.3272\n",
      "Epoch [42/100], Step [100/111], Loss: 0.4690\n",
      "Epoch [42/100], Step [102/111], Loss: 0.4156\n",
      "Epoch [42/100], Step [104/111], Loss: 0.3034\n",
      "Epoch [42/100], Step [106/111], Loss: 0.4598\n",
      "Epoch [42/100], Step [108/111], Loss: 3.7944\n",
      "Epoch [42/100], Step [110/111], Loss: 0.3950\n",
      "Epoch [43/100], Step [2/111], Loss: 0.3367\n",
      "Epoch [43/100], Step [4/111], Loss: 0.4015\n",
      "Epoch [43/100], Step [6/111], Loss: 0.4502\n",
      "Epoch [43/100], Step [8/111], Loss: 0.3299\n",
      "Epoch [43/100], Step [10/111], Loss: 0.3522\n",
      "Epoch [43/100], Step [12/111], Loss: 0.2747\n",
      "Epoch [43/100], Step [14/111], Loss: 0.3008\n",
      "Epoch [43/100], Step [16/111], Loss: 0.4765\n",
      "Epoch [43/100], Step [18/111], Loss: 0.3590\n",
      "Epoch [43/100], Step [20/111], Loss: 4.0794\n",
      "Epoch [43/100], Step [22/111], Loss: 0.3767\n",
      "Epoch [43/100], Step [24/111], Loss: 0.3361\n",
      "Epoch [43/100], Step [26/111], Loss: 0.2929\n",
      "Epoch [43/100], Step [28/111], Loss: 0.6130\n",
      "Epoch [43/100], Step [30/111], Loss: 0.3935\n",
      "Epoch [43/100], Step [32/111], Loss: 0.3300\n",
      "Epoch [43/100], Step [34/111], Loss: 0.2700\n",
      "Epoch [43/100], Step [36/111], Loss: 3.2515\n",
      "Epoch [43/100], Step [38/111], Loss: 0.3409\n",
      "Epoch [43/100], Step [40/111], Loss: 1.3287\n",
      "Epoch [43/100], Step [42/111], Loss: 0.3956\n",
      "Epoch [43/100], Step [44/111], Loss: 0.3998\n",
      "Epoch [43/100], Step [46/111], Loss: 0.4545\n",
      "Epoch [43/100], Step [48/111], Loss: 0.3447\n",
      "Epoch [43/100], Step [50/111], Loss: 0.2784\n",
      "Epoch [43/100], Step [52/111], Loss: 0.3194\n",
      "Epoch [43/100], Step [54/111], Loss: 0.3372\n",
      "Epoch [43/100], Step [56/111], Loss: 0.3277\n",
      "Epoch [43/100], Step [58/111], Loss: 0.2864\n",
      "Epoch [43/100], Step [60/111], Loss: 0.2686\n",
      "Epoch [43/100], Step [62/111], Loss: 0.2824\n",
      "Epoch [43/100], Step [64/111], Loss: 0.2766\n",
      "Epoch [43/100], Step [66/111], Loss: 0.5894\n",
      "Epoch [43/100], Step [68/111], Loss: 0.2924\n",
      "Epoch [43/100], Step [70/111], Loss: 0.1849\n",
      "Epoch [43/100], Step [72/111], Loss: 0.3534\n",
      "Epoch [43/100], Step [74/111], Loss: 0.3061\n",
      "Epoch [43/100], Step [76/111], Loss: 0.3152\n",
      "Epoch [43/100], Step [78/111], Loss: 0.6742\n",
      "Epoch [43/100], Step [80/111], Loss: 2.5808\n",
      "Epoch [43/100], Step [82/111], Loss: 0.3242\n",
      "Epoch [43/100], Step [84/111], Loss: 0.4687\n",
      "Epoch [43/100], Step [86/111], Loss: 0.3171\n",
      "Epoch [43/100], Step [88/111], Loss: 0.4070\n",
      "Epoch [43/100], Step [90/111], Loss: 0.3566\n",
      "Epoch [43/100], Step [92/111], Loss: 0.3065\n",
      "Epoch [43/100], Step [94/111], Loss: 0.2750\n",
      "Epoch [43/100], Step [96/111], Loss: 0.4275\n",
      "Epoch [43/100], Step [98/111], Loss: 0.3550\n",
      "Epoch [43/100], Step [100/111], Loss: 0.2629\n",
      "Epoch [43/100], Step [102/111], Loss: 0.4577\n",
      "Epoch [43/100], Step [104/111], Loss: 0.2656\n",
      "Epoch [43/100], Step [106/111], Loss: 0.2845\n",
      "Epoch [43/100], Step [108/111], Loss: 0.3684\n",
      "Epoch [43/100], Step [110/111], Loss: 0.4304\n",
      "Epoch [44/100], Step [2/111], Loss: 0.5684\n",
      "Epoch [44/100], Step [4/111], Loss: 0.9590\n",
      "Epoch [44/100], Step [6/111], Loss: 0.8860\n",
      "Epoch [44/100], Step [8/111], Loss: 0.6818\n",
      "Epoch [44/100], Step [10/111], Loss: 0.9279\n",
      "Epoch [44/100], Step [12/111], Loss: 0.8003\n",
      "Epoch [44/100], Step [14/111], Loss: 0.7337\n",
      "Epoch [44/100], Step [16/111], Loss: 2.0614\n",
      "Epoch [44/100], Step [18/111], Loss: 0.9868\n",
      "Epoch [44/100], Step [20/111], Loss: 0.9563\n",
      "Epoch [44/100], Step [22/111], Loss: 0.7401\n",
      "Epoch [44/100], Step [24/111], Loss: 0.5285\n",
      "Epoch [44/100], Step [26/111], Loss: 0.6602\n",
      "Epoch [44/100], Step [28/111], Loss: 0.6208\n",
      "Epoch [44/100], Step [30/111], Loss: 0.4213\n",
      "Epoch [44/100], Step [32/111], Loss: 0.5147\n",
      "Epoch [44/100], Step [34/111], Loss: 1.3569\n",
      "Epoch [44/100], Step [36/111], Loss: 0.6940\n",
      "Epoch [44/100], Step [38/111], Loss: 0.6063\n",
      "Epoch [44/100], Step [40/111], Loss: 0.9461\n",
      "Epoch [44/100], Step [42/111], Loss: 1.2061\n",
      "Epoch [44/100], Step [44/111], Loss: 0.7086\n",
      "Epoch [44/100], Step [46/111], Loss: 0.5360\n",
      "Epoch [44/100], Step [48/111], Loss: 0.5614\n",
      "Epoch [44/100], Step [50/111], Loss: 1.6364\n",
      "Epoch [44/100], Step [52/111], Loss: 1.8506\n",
      "Epoch [44/100], Step [54/111], Loss: 0.4144\n",
      "Epoch [44/100], Step [56/111], Loss: 0.4584\n",
      "Epoch [44/100], Step [58/111], Loss: 0.5038\n",
      "Epoch [44/100], Step [60/111], Loss: 0.4339\n",
      "Epoch [44/100], Step [62/111], Loss: 0.7515\n",
      "Epoch [44/100], Step [64/111], Loss: 0.7168\n",
      "Epoch [44/100], Step [66/111], Loss: 0.7980\n",
      "Epoch [44/100], Step [68/111], Loss: 0.6220\n",
      "Epoch [44/100], Step [70/111], Loss: 0.7503\n",
      "Epoch [44/100], Step [72/111], Loss: 2.2682\n",
      "Epoch [44/100], Step [74/111], Loss: 0.9412\n",
      "Epoch [44/100], Step [76/111], Loss: 0.7068\n",
      "Epoch [44/100], Step [78/111], Loss: 0.5572\n",
      "Epoch [44/100], Step [80/111], Loss: 0.6071\n",
      "Epoch [44/100], Step [82/111], Loss: 0.6407\n",
      "Epoch [44/100], Step [84/111], Loss: 0.5853\n",
      "Epoch [44/100], Step [86/111], Loss: 0.9029\n",
      "Epoch [44/100], Step [88/111], Loss: 0.7011\n",
      "Epoch [44/100], Step [90/111], Loss: 0.4751\n",
      "Epoch [44/100], Step [92/111], Loss: 0.5342\n",
      "Epoch [44/100], Step [94/111], Loss: 0.4516\n",
      "Epoch [44/100], Step [96/111], Loss: 0.5512\n",
      "Epoch [44/100], Step [98/111], Loss: 0.6128\n",
      "Epoch [44/100], Step [100/111], Loss: 0.4660\n",
      "Epoch [44/100], Step [102/111], Loss: 0.4230\n",
      "Epoch [44/100], Step [104/111], Loss: 0.5443\n",
      "Epoch [44/100], Step [106/111], Loss: 4.4882\n",
      "Epoch [44/100], Step [108/111], Loss: 0.5365\n",
      "Epoch [44/100], Step [110/111], Loss: 0.4859\n",
      "Epoch [45/100], Step [2/111], Loss: 0.6793\n",
      "Epoch [45/100], Step [4/111], Loss: 0.6536\n",
      "Epoch [45/100], Step [6/111], Loss: 0.3328\n",
      "Epoch [45/100], Step [8/111], Loss: 0.6958\n",
      "Epoch [45/100], Step [10/111], Loss: 0.7211\n",
      "Epoch [45/100], Step [12/111], Loss: 0.7302\n",
      "Epoch [45/100], Step [14/111], Loss: 0.5517\n",
      "Epoch [45/100], Step [16/111], Loss: 0.5382\n",
      "Epoch [45/100], Step [18/111], Loss: 0.7194\n",
      "Epoch [45/100], Step [20/111], Loss: 0.5118\n",
      "Epoch [45/100], Step [22/111], Loss: 0.5948\n",
      "Epoch [45/100], Step [24/111], Loss: 2.1195\n",
      "Epoch [45/100], Step [26/111], Loss: 0.4457\n",
      "Epoch [45/100], Step [28/111], Loss: 0.9594\n",
      "Epoch [45/100], Step [30/111], Loss: 0.5645\n",
      "Epoch [45/100], Step [32/111], Loss: 0.6495\n",
      "Epoch [45/100], Step [34/111], Loss: 0.8549\n",
      "Epoch [45/100], Step [36/111], Loss: 0.4765\n",
      "Epoch [45/100], Step [38/111], Loss: 0.6672\n",
      "Epoch [45/100], Step [40/111], Loss: 0.6275\n",
      "Epoch [45/100], Step [42/111], Loss: 0.5607\n",
      "Epoch [45/100], Step [44/111], Loss: 0.4040\n",
      "Epoch [45/100], Step [46/111], Loss: 0.7033\n",
      "Epoch [45/100], Step [48/111], Loss: 0.7642\n",
      "Epoch [45/100], Step [50/111], Loss: 0.6941\n",
      "Epoch [45/100], Step [52/111], Loss: 0.4886\n",
      "Epoch [45/100], Step [54/111], Loss: 0.6538\n",
      "Epoch [45/100], Step [56/111], Loss: 0.6428\n",
      "Epoch [45/100], Step [58/111], Loss: 0.5612\n",
      "Epoch [45/100], Step [60/111], Loss: 0.5710\n",
      "Epoch [45/100], Step [62/111], Loss: 0.7234\n",
      "Epoch [45/100], Step [64/111], Loss: 0.6691\n",
      "Epoch [45/100], Step [66/111], Loss: 0.8201\n",
      "Epoch [45/100], Step [68/111], Loss: 6.2872\n",
      "Epoch [45/100], Step [70/111], Loss: 1.0654\n",
      "Epoch [45/100], Step [72/111], Loss: 0.7100\n",
      "Epoch [45/100], Step [74/111], Loss: 3.2567\n",
      "Epoch [45/100], Step [76/111], Loss: 0.9472\n",
      "Epoch [45/100], Step [78/111], Loss: 0.8618\n",
      "Epoch [45/100], Step [80/111], Loss: 0.8796\n",
      "Epoch [45/100], Step [82/111], Loss: 0.6732\n",
      "Epoch [45/100], Step [84/111], Loss: 1.0180\n",
      "Epoch [45/100], Step [86/111], Loss: 0.7703\n",
      "Epoch [45/100], Step [88/111], Loss: 0.8167\n",
      "Epoch [45/100], Step [90/111], Loss: 1.2231\n",
      "Epoch [45/100], Step [92/111], Loss: 0.8152\n",
      "Epoch [45/100], Step [94/111], Loss: 0.4827\n",
      "Epoch [45/100], Step [96/111], Loss: 0.6608\n",
      "Epoch [45/100], Step [98/111], Loss: 0.7246\n",
      "Epoch [45/100], Step [100/111], Loss: 0.8670\n",
      "Epoch [45/100], Step [102/111], Loss: 0.7432\n",
      "Epoch [45/100], Step [104/111], Loss: 0.7110\n",
      "Epoch [45/100], Step [106/111], Loss: 0.5709\n",
      "Epoch [45/100], Step [108/111], Loss: 0.5157\n",
      "Epoch [45/100], Step [110/111], Loss: 0.7509\n",
      "Epoch [46/100], Step [2/111], Loss: 0.7199\n",
      "Epoch [46/100], Step [4/111], Loss: 0.8478\n",
      "Epoch [46/100], Step [6/111], Loss: 0.7466\n",
      "Epoch [46/100], Step [8/111], Loss: 0.8841\n",
      "Epoch [46/100], Step [10/111], Loss: 0.6183\n",
      "Epoch [46/100], Step [12/111], Loss: 0.5460\n",
      "Epoch [46/100], Step [14/111], Loss: 0.6833\n",
      "Epoch [46/100], Step [16/111], Loss: 0.9005\n",
      "Epoch [46/100], Step [18/111], Loss: 0.5306\n",
      "Epoch [46/100], Step [20/111], Loss: 0.5002\n",
      "Epoch [46/100], Step [22/111], Loss: 0.5390\n",
      "Epoch [46/100], Step [24/111], Loss: 0.4611\n",
      "Epoch [46/100], Step [26/111], Loss: 0.6301\n",
      "Epoch [46/100], Step [28/111], Loss: 0.4395\n",
      "Epoch [46/100], Step [30/111], Loss: 0.5068\n",
      "Epoch [46/100], Step [32/111], Loss: 0.8645\n",
      "Epoch [46/100], Step [34/111], Loss: 0.7721\n",
      "Epoch [46/100], Step [36/111], Loss: 0.5355\n",
      "Epoch [46/100], Step [38/111], Loss: 1.2419\n",
      "Epoch [46/100], Step [40/111], Loss: 0.5601\n",
      "Epoch [46/100], Step [42/111], Loss: 0.3952\n",
      "Epoch [46/100], Step [44/111], Loss: 0.7786\n",
      "Epoch [46/100], Step [46/111], Loss: 1.3959\n",
      "Epoch [46/100], Step [48/111], Loss: 0.8306\n",
      "Epoch [46/100], Step [50/111], Loss: 0.6597\n",
      "Epoch [46/100], Step [52/111], Loss: 1.0984\n",
      "Epoch [46/100], Step [54/111], Loss: 9.7644\n",
      "Epoch [46/100], Step [56/111], Loss: 0.7764\n",
      "Epoch [46/100], Step [58/111], Loss: 0.6777\n",
      "Epoch [46/100], Step [60/111], Loss: 0.7444\n",
      "Epoch [46/100], Step [62/111], Loss: 0.5126\n",
      "Epoch [46/100], Step [64/111], Loss: 1.2715\n",
      "Epoch [46/100], Step [66/111], Loss: 0.6265\n",
      "Epoch [46/100], Step [68/111], Loss: 0.9512\n",
      "Epoch [46/100], Step [70/111], Loss: 0.5962\n",
      "Epoch [46/100], Step [72/111], Loss: 0.6747\n",
      "Epoch [46/100], Step [74/111], Loss: 0.5145\n",
      "Epoch [46/100], Step [76/111], Loss: 0.5046\n",
      "Epoch [46/100], Step [78/111], Loss: 0.5426\n",
      "Epoch [46/100], Step [80/111], Loss: 0.5977\n",
      "Epoch [46/100], Step [82/111], Loss: 0.4747\n",
      "Epoch [46/100], Step [84/111], Loss: 0.5744\n",
      "Epoch [46/100], Step [86/111], Loss: 1.1534\n",
      "Epoch [46/100], Step [88/111], Loss: 0.5405\n",
      "Epoch [46/100], Step [90/111], Loss: 0.5099\n",
      "Epoch [46/100], Step [92/111], Loss: 0.5594\n",
      "Epoch [46/100], Step [94/111], Loss: 0.5131\n",
      "Epoch [46/100], Step [96/111], Loss: 0.4660\n",
      "Epoch [46/100], Step [98/111], Loss: 0.7983\n",
      "Epoch [46/100], Step [100/111], Loss: 0.7240\n",
      "Epoch [46/100], Step [102/111], Loss: 0.6917\n",
      "Epoch [46/100], Step [104/111], Loss: 0.4742\n",
      "Epoch [46/100], Step [106/111], Loss: 0.4638\n",
      "Epoch [46/100], Step [108/111], Loss: 0.9521\n",
      "Epoch [46/100], Step [110/111], Loss: 0.5364\n",
      "Epoch [47/100], Step [2/111], Loss: 0.3776\n",
      "Epoch [47/100], Step [4/111], Loss: 0.4899\n",
      "Epoch [47/100], Step [6/111], Loss: 0.5341\n",
      "Epoch [47/100], Step [8/111], Loss: 0.4290\n",
      "Epoch [47/100], Step [10/111], Loss: 0.6117\n",
      "Epoch [47/100], Step [12/111], Loss: 0.4335\n",
      "Epoch [47/100], Step [14/111], Loss: 1.6803\n",
      "Epoch [47/100], Step [16/111], Loss: 0.7364\n",
      "Epoch [47/100], Step [18/111], Loss: 0.4903\n",
      "Epoch [47/100], Step [20/111], Loss: 0.5311\n",
      "Epoch [47/100], Step [22/111], Loss: 0.3333\n",
      "Epoch [47/100], Step [24/111], Loss: 0.6207\n",
      "Epoch [47/100], Step [26/111], Loss: 0.3111\n",
      "Epoch [47/100], Step [28/111], Loss: 0.4613\n",
      "Epoch [47/100], Step [30/111], Loss: 0.4071\n",
      "Epoch [47/100], Step [32/111], Loss: 0.4064\n",
      "Epoch [47/100], Step [34/111], Loss: 0.4992\n",
      "Epoch [47/100], Step [36/111], Loss: 0.4964\n",
      "Epoch [47/100], Step [38/111], Loss: 0.3145\n",
      "Epoch [47/100], Step [40/111], Loss: 0.2778\n",
      "Epoch [47/100], Step [42/111], Loss: 0.3895\n",
      "Epoch [47/100], Step [44/111], Loss: 0.3497\n",
      "Epoch [47/100], Step [46/111], Loss: 0.6942\n",
      "Epoch [47/100], Step [48/111], Loss: 0.5865\n",
      "Epoch [47/100], Step [50/111], Loss: 0.4848\n",
      "Epoch [47/100], Step [52/111], Loss: 0.4385\n",
      "Epoch [47/100], Step [54/111], Loss: 0.3622\n",
      "Epoch [47/100], Step [56/111], Loss: 0.4750\n",
      "Epoch [47/100], Step [58/111], Loss: 0.5397\n",
      "Epoch [47/100], Step [60/111], Loss: 0.4133\n",
      "Epoch [47/100], Step [62/111], Loss: 0.4264\n",
      "Epoch [47/100], Step [64/111], Loss: 0.4714\n",
      "Epoch [47/100], Step [66/111], Loss: 0.4233\n",
      "Epoch [47/100], Step [68/111], Loss: 0.6666\n",
      "Epoch [47/100], Step [70/111], Loss: 0.7209\n",
      "Epoch [47/100], Step [72/111], Loss: 0.4008\n",
      "Epoch [47/100], Step [74/111], Loss: 0.4260\n",
      "Epoch [47/100], Step [76/111], Loss: 0.6976\n",
      "Epoch [47/100], Step [78/111], Loss: 0.5025\n",
      "Epoch [47/100], Step [80/111], Loss: 0.5268\n",
      "Epoch [47/100], Step [82/111], Loss: 0.3917\n",
      "Epoch [47/100], Step [84/111], Loss: 0.3967\n",
      "Epoch [47/100], Step [86/111], Loss: 0.3404\n",
      "Epoch [47/100], Step [88/111], Loss: 0.3836\n",
      "Epoch [47/100], Step [90/111], Loss: 0.6904\n",
      "Epoch [47/100], Step [92/111], Loss: 0.4430\n",
      "Epoch [47/100], Step [94/111], Loss: 0.4617\n",
      "Epoch [47/100], Step [96/111], Loss: 0.5097\n",
      "Epoch [47/100], Step [98/111], Loss: 0.5498\n",
      "Epoch [47/100], Step [100/111], Loss: 0.3819\n",
      "Epoch [47/100], Step [102/111], Loss: 0.6559\n",
      "Epoch [47/100], Step [104/111], Loss: 0.3096\n",
      "Epoch [47/100], Step [106/111], Loss: 0.7669\n",
      "Epoch [47/100], Step [108/111], Loss: 0.6027\n",
      "Epoch [47/100], Step [110/111], Loss: 0.5698\n",
      "Epoch [48/100], Step [2/111], Loss: 0.5871\n",
      "Epoch [48/100], Step [4/111], Loss: 0.4655\n",
      "Epoch [48/100], Step [6/111], Loss: 1.3339\n",
      "Epoch [48/100], Step [8/111], Loss: 0.9019\n",
      "Epoch [48/100], Step [10/111], Loss: 0.8991\n",
      "Epoch [48/100], Step [12/111], Loss: 1.7832\n",
      "Epoch [48/100], Step [14/111], Loss: 0.5943\n",
      "Epoch [48/100], Step [16/111], Loss: 0.4950\n",
      "Epoch [48/100], Step [18/111], Loss: 0.4848\n",
      "Epoch [48/100], Step [20/111], Loss: 0.6892\n",
      "Epoch [48/100], Step [22/111], Loss: 1.1628\n",
      "Epoch [48/100], Step [24/111], Loss: 0.7197\n",
      "Epoch [48/100], Step [26/111], Loss: 0.4930\n",
      "Epoch [48/100], Step [28/111], Loss: 0.5528\n",
      "Epoch [48/100], Step [30/111], Loss: 0.4735\n",
      "Epoch [48/100], Step [32/111], Loss: 0.5730\n",
      "Epoch [48/100], Step [34/111], Loss: 0.4959\n",
      "Epoch [48/100], Step [36/111], Loss: 3.5514\n",
      "Epoch [48/100], Step [38/111], Loss: 0.7900\n",
      "Epoch [48/100], Step [40/111], Loss: 0.6245\n",
      "Epoch [48/100], Step [42/111], Loss: 0.5572\n",
      "Epoch [48/100], Step [44/111], Loss: 0.9151\n",
      "Epoch [48/100], Step [46/111], Loss: 0.8203\n",
      "Epoch [48/100], Step [48/111], Loss: 0.8618\n",
      "Epoch [48/100], Step [50/111], Loss: 0.5781\n",
      "Epoch [48/100], Step [52/111], Loss: 0.5431\n",
      "Epoch [48/100], Step [54/111], Loss: 0.5301\n",
      "Epoch [48/100], Step [56/111], Loss: 0.5069\n",
      "Epoch [48/100], Step [58/111], Loss: 0.4907\n",
      "Epoch [48/100], Step [60/111], Loss: 0.6095\n",
      "Epoch [48/100], Step [62/111], Loss: 0.4479\n",
      "Epoch [48/100], Step [64/111], Loss: 0.4011\n",
      "Epoch [48/100], Step [66/111], Loss: 0.4962\n",
      "Epoch [48/100], Step [68/111], Loss: 0.4805\n",
      "Epoch [48/100], Step [70/111], Loss: 0.4633\n",
      "Epoch [48/100], Step [72/111], Loss: 0.5980\n",
      "Epoch [48/100], Step [74/111], Loss: 0.4278\n",
      "Epoch [48/100], Step [76/111], Loss: 0.4645\n",
      "Epoch [48/100], Step [78/111], Loss: 0.6211\n",
      "Epoch [48/100], Step [80/111], Loss: 0.4164\n",
      "Epoch [48/100], Step [82/111], Loss: 0.4014\n",
      "Epoch [48/100], Step [84/111], Loss: 0.3961\n",
      "Epoch [48/100], Step [86/111], Loss: 0.4591\n",
      "Epoch [48/100], Step [88/111], Loss: 0.5673\n",
      "Epoch [48/100], Step [90/111], Loss: 0.4710\n",
      "Epoch [48/100], Step [92/111], Loss: 3.1943\n",
      "Epoch [48/100], Step [94/111], Loss: 0.6686\n",
      "Epoch [48/100], Step [96/111], Loss: 0.4678\n",
      "Epoch [48/100], Step [98/111], Loss: 0.4695\n",
      "Epoch [48/100], Step [100/111], Loss: 0.6046\n",
      "Epoch [48/100], Step [102/111], Loss: 0.5501\n",
      "Epoch [48/100], Step [104/111], Loss: 0.5505\n",
      "Epoch [48/100], Step [106/111], Loss: 0.4722\n",
      "Epoch [48/100], Step [108/111], Loss: 0.5290\n",
      "Epoch [48/100], Step [110/111], Loss: 0.4249\n",
      "Epoch [49/100], Step [2/111], Loss: 0.3672\n",
      "Epoch [49/100], Step [4/111], Loss: 0.6092\n",
      "Epoch [49/100], Step [6/111], Loss: 6.1960\n",
      "Epoch [49/100], Step [8/111], Loss: 0.6610\n",
      "Epoch [49/100], Step [10/111], Loss: 0.9140\n",
      "Epoch [49/100], Step [12/111], Loss: 0.6288\n",
      "Epoch [49/100], Step [14/111], Loss: 0.5448\n",
      "Epoch [49/100], Step [16/111], Loss: 0.5207\n",
      "Epoch [49/100], Step [18/111], Loss: 0.8587\n",
      "Epoch [49/100], Step [20/111], Loss: 0.7337\n",
      "Epoch [49/100], Step [22/111], Loss: 0.5904\n",
      "Epoch [49/100], Step [24/111], Loss: 0.8089\n",
      "Epoch [49/100], Step [26/111], Loss: 1.0502\n",
      "Epoch [49/100], Step [28/111], Loss: 0.7288\n",
      "Epoch [49/100], Step [30/111], Loss: 0.6077\n",
      "Epoch [49/100], Step [32/111], Loss: 0.4713\n",
      "Epoch [49/100], Step [34/111], Loss: 0.6136\n",
      "Epoch [49/100], Step [36/111], Loss: 0.6977\n",
      "Epoch [49/100], Step [38/111], Loss: 0.7243\n",
      "Epoch [49/100], Step [40/111], Loss: 0.4971\n",
      "Epoch [49/100], Step [42/111], Loss: 0.5043\n",
      "Epoch [49/100], Step [44/111], Loss: 0.5591\n",
      "Epoch [49/100], Step [46/111], Loss: 0.5011\n",
      "Epoch [49/100], Step [48/111], Loss: 0.4787\n",
      "Epoch [49/100], Step [50/111], Loss: 0.6622\n",
      "Epoch [49/100], Step [52/111], Loss: 0.6711\n",
      "Epoch [49/100], Step [54/111], Loss: 0.4957\n",
      "Epoch [49/100], Step [56/111], Loss: 0.4770\n",
      "Epoch [49/100], Step [58/111], Loss: 0.6327\n",
      "Epoch [49/100], Step [60/111], Loss: 0.4631\n",
      "Epoch [49/100], Step [62/111], Loss: 0.4320\n",
      "Epoch [49/100], Step [64/111], Loss: 0.4877\n",
      "Epoch [49/100], Step [66/111], Loss: 0.4275\n",
      "Epoch [49/100], Step [68/111], Loss: 0.5753\n",
      "Epoch [49/100], Step [70/111], Loss: 0.4357\n",
      "Epoch [49/100], Step [72/111], Loss: 0.3974\n",
      "Epoch [49/100], Step [74/111], Loss: 0.4495\n",
      "Epoch [49/100], Step [76/111], Loss: 0.6398\n",
      "Epoch [49/100], Step [78/111], Loss: 0.6009\n",
      "Epoch [49/100], Step [80/111], Loss: 0.6979\n",
      "Epoch [49/100], Step [82/111], Loss: 0.3779\n",
      "Epoch [49/100], Step [84/111], Loss: 0.6465\n",
      "Epoch [49/100], Step [86/111], Loss: 0.4008\n",
      "Epoch [49/100], Step [88/111], Loss: 0.6019\n",
      "Epoch [49/100], Step [90/111], Loss: 0.4663\n",
      "Epoch [49/100], Step [92/111], Loss: 0.4149\n",
      "Epoch [49/100], Step [94/111], Loss: 0.5749\n",
      "Epoch [49/100], Step [96/111], Loss: 0.5064\n",
      "Epoch [49/100], Step [98/111], Loss: 0.4084\n",
      "Epoch [49/100], Step [100/111], Loss: 0.4371\n",
      "Epoch [49/100], Step [102/111], Loss: 0.6084\n",
      "Epoch [49/100], Step [104/111], Loss: 0.5138\n",
      "Epoch [49/100], Step [106/111], Loss: 0.5316\n",
      "Epoch [49/100], Step [108/111], Loss: 2.6632\n",
      "Epoch [49/100], Step [110/111], Loss: 0.5813\n",
      "Epoch [50/100], Step [2/111], Loss: 0.5541\n",
      "Epoch [50/100], Step [4/111], Loss: 0.6406\n",
      "Epoch [50/100], Step [6/111], Loss: 0.4168\n",
      "Epoch [50/100], Step [8/111], Loss: 1.1444\n",
      "Epoch [50/100], Step [10/111], Loss: 0.5002\n",
      "Epoch [50/100], Step [12/111], Loss: 0.3683\n",
      "Epoch [50/100], Step [14/111], Loss: 0.3865\n",
      "Epoch [50/100], Step [16/111], Loss: 0.3521\n",
      "Epoch [50/100], Step [18/111], Loss: 0.3812\n",
      "Epoch [50/100], Step [20/111], Loss: 0.3922\n",
      "Epoch [50/100], Step [22/111], Loss: 0.3532\n",
      "Epoch [50/100], Step [24/111], Loss: 0.3742\n",
      "Epoch [50/100], Step [26/111], Loss: 0.6049\n",
      "Epoch [50/100], Step [28/111], Loss: 0.3622\n",
      "Epoch [50/100], Step [30/111], Loss: 0.3833\n",
      "Epoch [50/100], Step [32/111], Loss: 0.8261\n",
      "Epoch [50/100], Step [34/111], Loss: 0.4120\n",
      "Epoch [50/100], Step [36/111], Loss: 0.4136\n",
      "Epoch [50/100], Step [38/111], Loss: 0.3741\n",
      "Epoch [50/100], Step [40/111], Loss: 0.3307\n",
      "Epoch [50/100], Step [42/111], Loss: 0.5737\n",
      "Epoch [50/100], Step [44/111], Loss: 0.3139\n",
      "Epoch [50/100], Step [46/111], Loss: 0.5727\n",
      "Epoch [50/100], Step [48/111], Loss: 0.6612\n",
      "Epoch [50/100], Step [50/111], Loss: 0.4613\n",
      "Epoch [50/100], Step [52/111], Loss: 0.4441\n",
      "Epoch [50/100], Step [54/111], Loss: 0.4071\n",
      "Epoch [50/100], Step [56/111], Loss: 0.3652\n",
      "Epoch [50/100], Step [58/111], Loss: 0.4127\n",
      "Epoch [50/100], Step [60/111], Loss: 0.3367\n",
      "Epoch [50/100], Step [62/111], Loss: 0.3841\n",
      "Epoch [50/100], Step [64/111], Loss: 0.3708\n",
      "Epoch [50/100], Step [66/111], Loss: 0.3875\n",
      "Epoch [50/100], Step [68/111], Loss: 6.9772\n",
      "Epoch [50/100], Step [70/111], Loss: 0.3531\n",
      "Epoch [50/100], Step [72/111], Loss: 0.5471\n",
      "Epoch [50/100], Step [74/111], Loss: 0.3511\n",
      "Epoch [50/100], Step [76/111], Loss: 0.3911\n",
      "Epoch [50/100], Step [78/111], Loss: 0.5588\n",
      "Epoch [50/100], Step [80/111], Loss: 0.4956\n",
      "Epoch [50/100], Step [82/111], Loss: 0.5534\n",
      "Epoch [50/100], Step [84/111], Loss: 0.3978\n",
      "Epoch [50/100], Step [86/111], Loss: 0.5351\n",
      "Epoch [50/100], Step [88/111], Loss: 0.3451\n",
      "Epoch [50/100], Step [90/111], Loss: 0.4921\n",
      "Epoch [50/100], Step [92/111], Loss: 0.3404\n",
      "Epoch [50/100], Step [94/111], Loss: 0.3440\n",
      "Epoch [50/100], Step [96/111], Loss: 0.4285\n",
      "Epoch [50/100], Step [98/111], Loss: 0.4520\n",
      "Epoch [50/100], Step [100/111], Loss: 0.3224\n",
      "Epoch [50/100], Step [102/111], Loss: 0.6230\n",
      "Epoch [50/100], Step [104/111], Loss: 0.4661\n",
      "Epoch [50/100], Step [106/111], Loss: 0.3115\n",
      "Epoch [50/100], Step [108/111], Loss: 0.3399\n",
      "Epoch [50/100], Step [110/111], Loss: 0.4252\n",
      "Epoch [51/100], Step [2/111], Loss: 0.3707\n",
      "Epoch [51/100], Step [4/111], Loss: 0.2972\n",
      "Epoch [51/100], Step [6/111], Loss: 0.3916\n",
      "Epoch [51/100], Step [8/111], Loss: 0.3669\n",
      "Epoch [51/100], Step [10/111], Loss: 0.3230\n",
      "Epoch [51/100], Step [12/111], Loss: 0.5184\n",
      "Epoch [51/100], Step [14/111], Loss: 0.2979\n",
      "Epoch [51/100], Step [16/111], Loss: 0.3213\n",
      "Epoch [51/100], Step [18/111], Loss: 0.4402\n",
      "Epoch [51/100], Step [20/111], Loss: 0.3157\n",
      "Epoch [51/100], Step [22/111], Loss: 0.2325\n",
      "Epoch [51/100], Step [24/111], Loss: 0.3374\n",
      "Epoch [51/100], Step [26/111], Loss: 0.3413\n",
      "Epoch [51/100], Step [28/111], Loss: 0.3927\n",
      "Epoch [51/100], Step [30/111], Loss: 0.3192\n",
      "Epoch [51/100], Step [32/111], Loss: 0.3727\n",
      "Epoch [51/100], Step [34/111], Loss: 0.4415\n",
      "Epoch [51/100], Step [36/111], Loss: 0.6191\n",
      "Epoch [51/100], Step [38/111], Loss: 0.4113\n",
      "Epoch [51/100], Step [40/111], Loss: 0.7446\n",
      "Epoch [51/100], Step [42/111], Loss: 0.3303\n",
      "Epoch [51/100], Step [44/111], Loss: 0.8334\n",
      "Epoch [51/100], Step [46/111], Loss: 0.3624\n",
      "Epoch [51/100], Step [48/111], Loss: 0.5483\n",
      "Epoch [51/100], Step [50/111], Loss: 0.3308\n",
      "Epoch [51/100], Step [52/111], Loss: 0.3772\n",
      "Epoch [51/100], Step [54/111], Loss: 0.3888\n",
      "Epoch [51/100], Step [56/111], Loss: 0.2767\n",
      "Epoch [51/100], Step [58/111], Loss: 0.5107\n",
      "Epoch [51/100], Step [60/111], Loss: 0.2765\n",
      "Epoch [51/100], Step [62/111], Loss: 0.2760\n",
      "Epoch [51/100], Step [64/111], Loss: 0.2682\n",
      "Epoch [51/100], Step [66/111], Loss: 0.2982\n",
      "Epoch [51/100], Step [68/111], Loss: 0.2374\n",
      "Epoch [51/100], Step [70/111], Loss: 0.2575\n",
      "Epoch [51/100], Step [72/111], Loss: 0.3023\n",
      "Epoch [51/100], Step [74/111], Loss: 0.3798\n",
      "Epoch [51/100], Step [76/111], Loss: 0.2716\n",
      "Epoch [51/100], Step [78/111], Loss: 0.2816\n",
      "Epoch [51/100], Step [80/111], Loss: 3.1445\n",
      "Epoch [51/100], Step [82/111], Loss: 0.2414\n",
      "Epoch [51/100], Step [84/111], Loss: 0.2443\n",
      "Epoch [51/100], Step [86/111], Loss: 0.2856\n",
      "Epoch [51/100], Step [88/111], Loss: 0.2636\n",
      "Epoch [51/100], Step [90/111], Loss: 0.3518\n",
      "Epoch [51/100], Step [92/111], Loss: 0.3377\n",
      "Epoch [51/100], Step [94/111], Loss: 0.2361\n",
      "Epoch [51/100], Step [96/111], Loss: 0.2316\n",
      "Epoch [51/100], Step [98/111], Loss: 0.4710\n",
      "Epoch [51/100], Step [100/111], Loss: 0.4165\n",
      "Epoch [51/100], Step [102/111], Loss: 0.2993\n",
      "Epoch [51/100], Step [104/111], Loss: 0.2882\n",
      "Epoch [51/100], Step [106/111], Loss: 0.3593\n",
      "Epoch [51/100], Step [108/111], Loss: 0.3353\n",
      "Epoch [51/100], Step [110/111], Loss: 0.2133\n",
      "Epoch [52/100], Step [2/111], Loss: 0.3143\n",
      "Epoch [52/100], Step [4/111], Loss: 0.2753\n",
      "Epoch [52/100], Step [6/111], Loss: 0.3050\n",
      "Epoch [52/100], Step [8/111], Loss: 0.4591\n",
      "Epoch [52/100], Step [10/111], Loss: 0.3533\n",
      "Epoch [52/100], Step [12/111], Loss: 3.4030\n",
      "Epoch [52/100], Step [14/111], Loss: 0.3227\n",
      "Epoch [52/100], Step [16/111], Loss: 0.2692\n",
      "Epoch [52/100], Step [18/111], Loss: 0.2406\n",
      "Epoch [52/100], Step [20/111], Loss: 0.3213\n",
      "Epoch [52/100], Step [22/111], Loss: 0.3006\n",
      "Epoch [52/100], Step [24/111], Loss: 0.3679\n",
      "Epoch [52/100], Step [26/111], Loss: 1.0560\n",
      "Epoch [52/100], Step [28/111], Loss: 0.3424\n",
      "Epoch [52/100], Step [30/111], Loss: 0.3828\n",
      "Epoch [52/100], Step [32/111], Loss: 0.2279\n",
      "Epoch [52/100], Step [34/111], Loss: 0.3916\n",
      "Epoch [52/100], Step [36/111], Loss: 0.2531\n",
      "Epoch [52/100], Step [38/111], Loss: 0.2605\n",
      "Epoch [52/100], Step [40/111], Loss: 0.3502\n",
      "Epoch [52/100], Step [42/111], Loss: 5.7741\n",
      "Epoch [52/100], Step [44/111], Loss: 0.6821\n",
      "Epoch [52/100], Step [46/111], Loss: 0.3102\n",
      "Epoch [52/100], Step [48/111], Loss: 0.3587\n",
      "Epoch [52/100], Step [50/111], Loss: 0.3203\n",
      "Epoch [52/100], Step [52/111], Loss: 0.3104\n",
      "Epoch [52/100], Step [54/111], Loss: 2.9719\n",
      "Epoch [52/100], Step [56/111], Loss: 0.2774\n",
      "Epoch [52/100], Step [58/111], Loss: 0.4205\n",
      "Epoch [52/100], Step [60/111], Loss: 0.2170\n",
      "Epoch [52/100], Step [62/111], Loss: 0.3704\n",
      "Epoch [52/100], Step [64/111], Loss: 0.3479\n",
      "Epoch [52/100], Step [66/111], Loss: 0.6311\n",
      "Epoch [52/100], Step [68/111], Loss: 0.3159\n",
      "Epoch [52/100], Step [70/111], Loss: 0.2489\n",
      "Epoch [52/100], Step [72/111], Loss: 0.2437\n",
      "Epoch [52/100], Step [74/111], Loss: 0.2852\n",
      "Epoch [52/100], Step [76/111], Loss: 0.2677\n",
      "Epoch [52/100], Step [78/111], Loss: 0.2343\n",
      "Epoch [52/100], Step [80/111], Loss: 0.2296\n",
      "Epoch [52/100], Step [82/111], Loss: 0.2480\n",
      "Epoch [52/100], Step [84/111], Loss: 0.2388\n",
      "Epoch [52/100], Step [86/111], Loss: 0.2750\n",
      "Epoch [52/100], Step [88/111], Loss: 0.2777\n",
      "Epoch [52/100], Step [90/111], Loss: 0.3176\n",
      "Epoch [52/100], Step [92/111], Loss: 0.3036\n",
      "Epoch [52/100], Step [94/111], Loss: 0.2782\n",
      "Epoch [52/100], Step [96/111], Loss: 0.3002\n",
      "Epoch [52/100], Step [98/111], Loss: 0.2177\n",
      "Epoch [52/100], Step [100/111], Loss: 0.2872\n",
      "Epoch [52/100], Step [102/111], Loss: 0.2866\n",
      "Epoch [52/100], Step [104/111], Loss: 0.2865\n",
      "Epoch [52/100], Step [106/111], Loss: 0.3172\n",
      "Epoch [52/100], Step [108/111], Loss: 0.3249\n",
      "Epoch [52/100], Step [110/111], Loss: 0.2964\n",
      "Epoch [53/100], Step [2/111], Loss: 0.2283\n",
      "Epoch [53/100], Step [4/111], Loss: 0.3021\n",
      "Epoch [53/100], Step [6/111], Loss: 0.2162\n",
      "Epoch [53/100], Step [8/111], Loss: 0.2399\n",
      "Epoch [53/100], Step [10/111], Loss: 0.3284\n",
      "Epoch [53/100], Step [12/111], Loss: 0.3013\n",
      "Epoch [53/100], Step [14/111], Loss: 0.2932\n",
      "Epoch [53/100], Step [16/111], Loss: 1.9478\n",
      "Epoch [53/100], Step [18/111], Loss: 0.2156\n",
      "Epoch [53/100], Step [20/111], Loss: 0.2636\n",
      "Epoch [53/100], Step [22/111], Loss: 0.2306\n",
      "Epoch [53/100], Step [24/111], Loss: 0.3010\n",
      "Epoch [53/100], Step [26/111], Loss: 0.3263\n",
      "Epoch [53/100], Step [28/111], Loss: 0.2159\n",
      "Epoch [53/100], Step [30/111], Loss: 0.2524\n",
      "Epoch [53/100], Step [32/111], Loss: 0.2873\n",
      "Epoch [53/100], Step [34/111], Loss: 0.2364\n",
      "Epoch [53/100], Step [36/111], Loss: 0.2362\n",
      "Epoch [53/100], Step [38/111], Loss: 0.2509\n",
      "Epoch [53/100], Step [40/111], Loss: 0.2861\n",
      "Epoch [53/100], Step [42/111], Loss: 0.5073\n",
      "Epoch [53/100], Step [44/111], Loss: 0.2088\n",
      "Epoch [53/100], Step [46/111], Loss: 0.4463\n",
      "Epoch [53/100], Step [48/111], Loss: 0.2749\n",
      "Epoch [53/100], Step [50/111], Loss: 0.1777\n",
      "Epoch [53/100], Step [52/111], Loss: 0.2877\n",
      "Epoch [53/100], Step [54/111], Loss: 0.2996\n",
      "Epoch [53/100], Step [56/111], Loss: 0.2125\n",
      "Epoch [53/100], Step [58/111], Loss: 0.3072\n",
      "Epoch [53/100], Step [60/111], Loss: 0.2748\n",
      "Epoch [53/100], Step [62/111], Loss: 0.2227\n",
      "Epoch [53/100], Step [64/111], Loss: 0.3326\n",
      "Epoch [53/100], Step [66/111], Loss: 0.2060\n",
      "Epoch [53/100], Step [68/111], Loss: 0.2489\n",
      "Epoch [53/100], Step [70/111], Loss: 0.2691\n",
      "Epoch [53/100], Step [72/111], Loss: 0.2228\n",
      "Epoch [53/100], Step [74/111], Loss: 0.2819\n",
      "Epoch [53/100], Step [76/111], Loss: 0.8009\n",
      "Epoch [53/100], Step [78/111], Loss: 0.2221\n",
      "Epoch [53/100], Step [80/111], Loss: 0.2042\n",
      "Epoch [53/100], Step [82/111], Loss: 0.2543\n",
      "Epoch [53/100], Step [84/111], Loss: 0.2269\n",
      "Epoch [53/100], Step [86/111], Loss: 0.4286\n",
      "Epoch [53/100], Step [88/111], Loss: 6.3246\n",
      "Epoch [53/100], Step [90/111], Loss: 0.3438\n",
      "Epoch [53/100], Step [92/111], Loss: 0.3450\n",
      "Epoch [53/100], Step [94/111], Loss: 0.3200\n",
      "Epoch [53/100], Step [96/111], Loss: 0.2715\n",
      "Epoch [53/100], Step [98/111], Loss: 0.2979\n",
      "Epoch [53/100], Step [100/111], Loss: 0.4107\n",
      "Epoch [53/100], Step [102/111], Loss: 0.3238\n",
      "Epoch [53/100], Step [104/111], Loss: 0.3646\n",
      "Epoch [53/100], Step [106/111], Loss: 0.3019\n",
      "Epoch [53/100], Step [108/111], Loss: 0.2138\n",
      "Epoch [53/100], Step [110/111], Loss: 0.2648\n",
      "Epoch [54/100], Step [2/111], Loss: 0.3432\n",
      "Epoch [54/100], Step [4/111], Loss: 0.2923\n",
      "Epoch [54/100], Step [6/111], Loss: 0.2758\n",
      "Epoch [54/100], Step [8/111], Loss: 0.3713\n",
      "Epoch [54/100], Step [10/111], Loss: 0.2896\n",
      "Epoch [54/100], Step [12/111], Loss: 0.4150\n",
      "Epoch [54/100], Step [14/111], Loss: 0.2616\n",
      "Epoch [54/100], Step [16/111], Loss: 0.2669\n",
      "Epoch [54/100], Step [18/111], Loss: 0.2589\n",
      "Epoch [54/100], Step [20/111], Loss: 0.1822\n",
      "Epoch [54/100], Step [22/111], Loss: 0.3662\n",
      "Epoch [54/100], Step [24/111], Loss: 0.1772\n",
      "Epoch [54/100], Step [26/111], Loss: 0.2332\n",
      "Epoch [54/100], Step [28/111], Loss: 0.2516\n",
      "Epoch [54/100], Step [30/111], Loss: 0.3318\n",
      "Epoch [54/100], Step [32/111], Loss: 0.4189\n",
      "Epoch [54/100], Step [34/111], Loss: 0.2061\n",
      "Epoch [54/100], Step [36/111], Loss: 0.3377\n",
      "Epoch [54/100], Step [38/111], Loss: 0.2142\n",
      "Epoch [54/100], Step [40/111], Loss: 0.3120\n",
      "Epoch [54/100], Step [42/111], Loss: 0.2932\n",
      "Epoch [54/100], Step [44/111], Loss: 0.2053\n",
      "Epoch [54/100], Step [46/111], Loss: 0.4912\n",
      "Epoch [54/100], Step [48/111], Loss: 0.2253\n",
      "Epoch [54/100], Step [50/111], Loss: 0.2895\n",
      "Epoch [54/100], Step [52/111], Loss: 0.2625\n",
      "Epoch [54/100], Step [54/111], Loss: 0.3294\n",
      "Epoch [54/100], Step [56/111], Loss: 0.3462\n",
      "Epoch [54/100], Step [58/111], Loss: 0.2976\n",
      "Epoch [54/100], Step [60/111], Loss: 0.3330\n",
      "Epoch [54/100], Step [62/111], Loss: 0.2630\n",
      "Epoch [54/100], Step [64/111], Loss: 0.3084\n",
      "Epoch [54/100], Step [66/111], Loss: 0.3002\n",
      "Epoch [54/100], Step [68/111], Loss: 0.6483\n",
      "Epoch [54/100], Step [70/111], Loss: 0.3249\n",
      "Epoch [54/100], Step [72/111], Loss: 0.4462\n",
      "Epoch [54/100], Step [74/111], Loss: 0.4280\n",
      "Epoch [54/100], Step [76/111], Loss: 0.3322\n",
      "Epoch [54/100], Step [78/111], Loss: 0.3800\n",
      "Epoch [54/100], Step [80/111], Loss: 0.3881\n",
      "Epoch [54/100], Step [82/111], Loss: 0.2827\n",
      "Epoch [54/100], Step [84/111], Loss: 3.0649\n",
      "Epoch [54/100], Step [86/111], Loss: 0.5019\n",
      "Epoch [54/100], Step [88/111], Loss: 0.2727\n",
      "Epoch [54/100], Step [90/111], Loss: 0.4318\n",
      "Epoch [54/100], Step [92/111], Loss: 0.2920\n",
      "Epoch [54/100], Step [94/111], Loss: 0.2799\n",
      "Epoch [54/100], Step [96/111], Loss: 0.2878\n",
      "Epoch [54/100], Step [98/111], Loss: 0.2859\n",
      "Epoch [54/100], Step [100/111], Loss: 0.2948\n",
      "Epoch [54/100], Step [102/111], Loss: 0.2190\n",
      "Epoch [54/100], Step [104/111], Loss: 0.2307\n",
      "Epoch [54/100], Step [106/111], Loss: 0.4968\n",
      "Epoch [54/100], Step [108/111], Loss: 0.3049\n",
      "Epoch [54/100], Step [110/111], Loss: 0.2686\n",
      "Epoch [55/100], Step [2/111], Loss: 0.4009\n",
      "Epoch [55/100], Step [4/111], Loss: 0.7689\n",
      "Epoch [55/100], Step [6/111], Loss: 0.2552\n",
      "Epoch [55/100], Step [8/111], Loss: 0.4332\n",
      "Epoch [55/100], Step [10/111], Loss: 0.2832\n",
      "Epoch [55/100], Step [12/111], Loss: 0.3650\n",
      "Epoch [55/100], Step [14/111], Loss: 0.3258\n",
      "Epoch [55/100], Step [16/111], Loss: 0.2111\n",
      "Epoch [55/100], Step [18/111], Loss: 0.2365\n",
      "Epoch [55/100], Step [20/111], Loss: 0.3286\n",
      "Epoch [55/100], Step [22/111], Loss: 2.2299\n",
      "Epoch [55/100], Step [24/111], Loss: 0.3008\n",
      "Epoch [55/100], Step [26/111], Loss: 0.2230\n",
      "Epoch [55/100], Step [28/111], Loss: 0.3381\n",
      "Epoch [55/100], Step [30/111], Loss: 0.2597\n",
      "Epoch [55/100], Step [32/111], Loss: 0.2743\n",
      "Epoch [55/100], Step [34/111], Loss: 0.3167\n",
      "Epoch [55/100], Step [36/111], Loss: 0.2307\n",
      "Epoch [55/100], Step [38/111], Loss: 0.2037\n",
      "Epoch [55/100], Step [40/111], Loss: 0.2585\n",
      "Epoch [55/100], Step [42/111], Loss: 0.3710\n",
      "Epoch [55/100], Step [44/111], Loss: 0.2335\n",
      "Epoch [55/100], Step [46/111], Loss: 0.2619\n",
      "Epoch [55/100], Step [48/111], Loss: 0.2984\n",
      "Epoch [55/100], Step [50/111], Loss: 0.2412\n",
      "Epoch [55/100], Step [52/111], Loss: 0.2747\n",
      "Epoch [55/100], Step [54/111], Loss: 0.2543\n",
      "Epoch [55/100], Step [56/111], Loss: 0.6304\n",
      "Epoch [55/100], Step [58/111], Loss: 0.2553\n",
      "Epoch [55/100], Step [60/111], Loss: 0.2725\n",
      "Epoch [55/100], Step [62/111], Loss: 0.2490\n",
      "Epoch [55/100], Step [64/111], Loss: 0.2680\n",
      "Epoch [55/100], Step [66/111], Loss: 0.3653\n",
      "Epoch [55/100], Step [68/111], Loss: 0.3179\n",
      "Epoch [55/100], Step [70/111], Loss: 0.3226\n",
      "Epoch [55/100], Step [72/111], Loss: 2.8636\n",
      "Epoch [55/100], Step [74/111], Loss: 0.2099\n",
      "Epoch [55/100], Step [76/111], Loss: 5.5659\n",
      "Epoch [55/100], Step [78/111], Loss: 0.3107\n",
      "Epoch [55/100], Step [80/111], Loss: 0.2614\n",
      "Epoch [55/100], Step [82/111], Loss: 0.2168\n",
      "Epoch [55/100], Step [84/111], Loss: 0.3260\n",
      "Epoch [55/100], Step [86/111], Loss: 0.2666\n",
      "Epoch [55/100], Step [88/111], Loss: 0.3590\n",
      "Epoch [55/100], Step [90/111], Loss: 0.3244\n",
      "Epoch [55/100], Step [92/111], Loss: 0.2739\n",
      "Epoch [55/100], Step [94/111], Loss: 0.2199\n",
      "Epoch [55/100], Step [96/111], Loss: 0.2334\n",
      "Epoch [55/100], Step [98/111], Loss: 0.2779\n",
      "Epoch [55/100], Step [100/111], Loss: 0.2289\n",
      "Epoch [55/100], Step [102/111], Loss: 0.2376\n",
      "Epoch [55/100], Step [104/111], Loss: 0.3813\n",
      "Epoch [55/100], Step [106/111], Loss: 0.2712\n",
      "Epoch [55/100], Step [108/111], Loss: 0.2535\n",
      "Epoch [55/100], Step [110/111], Loss: 0.3269\n",
      "Epoch [56/100], Step [2/111], Loss: 0.3736\n",
      "Epoch [56/100], Step [4/111], Loss: 0.4045\n",
      "Epoch [56/100], Step [6/111], Loss: 0.2574\n",
      "Epoch [56/100], Step [8/111], Loss: 0.3323\n",
      "Epoch [56/100], Step [10/111], Loss: 0.3560\n",
      "Epoch [56/100], Step [12/111], Loss: 1.9810\n",
      "Epoch [56/100], Step [14/111], Loss: 0.3771\n",
      "Epoch [56/100], Step [16/111], Loss: 0.2669\n",
      "Epoch [56/100], Step [18/111], Loss: 0.2155\n",
      "Epoch [56/100], Step [20/111], Loss: 0.4556\n",
      "Epoch [56/100], Step [22/111], Loss: 0.3038\n",
      "Epoch [56/100], Step [24/111], Loss: 0.2923\n",
      "Epoch [56/100], Step [26/111], Loss: 0.3298\n",
      "Epoch [56/100], Step [28/111], Loss: 0.1941\n",
      "Epoch [56/100], Step [30/111], Loss: 0.2646\n",
      "Epoch [56/100], Step [32/111], Loss: 0.2892\n",
      "Epoch [56/100], Step [34/111], Loss: 0.2324\n",
      "Epoch [56/100], Step [36/111], Loss: 0.1947\n",
      "Epoch [56/100], Step [38/111], Loss: 0.2446\n",
      "Epoch [56/100], Step [40/111], Loss: 0.2076\n",
      "Epoch [56/100], Step [42/111], Loss: 0.2603\n",
      "Epoch [56/100], Step [44/111], Loss: 0.2470\n",
      "Epoch [56/100], Step [46/111], Loss: 0.3640\n",
      "Epoch [56/100], Step [48/111], Loss: 0.3244\n",
      "Epoch [56/100], Step [50/111], Loss: 0.2310\n",
      "Epoch [56/100], Step [52/111], Loss: 0.4651\n",
      "Epoch [56/100], Step [54/111], Loss: 0.2023\n",
      "Epoch [56/100], Step [56/111], Loss: 3.6940\n",
      "Epoch [56/100], Step [58/111], Loss: 0.3548\n",
      "Epoch [56/100], Step [60/111], Loss: 0.3258\n",
      "Epoch [56/100], Step [62/111], Loss: 0.2465\n",
      "Epoch [56/100], Step [64/111], Loss: 0.2749\n",
      "Epoch [56/100], Step [66/111], Loss: 0.3176\n",
      "Epoch [56/100], Step [68/111], Loss: 0.2298\n",
      "Epoch [56/100], Step [70/111], Loss: 0.2143\n",
      "Epoch [56/100], Step [72/111], Loss: 0.2545\n",
      "Epoch [56/100], Step [74/111], Loss: 0.2406\n",
      "Epoch [56/100], Step [76/111], Loss: 0.2070\n",
      "Epoch [56/100], Step [78/111], Loss: 6.2670\n",
      "Epoch [56/100], Step [80/111], Loss: 0.3892\n",
      "Epoch [56/100], Step [82/111], Loss: 0.3261\n",
      "Epoch [56/100], Step [84/111], Loss: 0.2734\n",
      "Epoch [56/100], Step [86/111], Loss: 0.2269\n",
      "Epoch [56/100], Step [88/111], Loss: 0.2626\n",
      "Epoch [56/100], Step [90/111], Loss: 0.3583\n",
      "Epoch [56/100], Step [92/111], Loss: 0.1644\n",
      "Epoch [56/100], Step [94/111], Loss: 0.2833\n",
      "Epoch [56/100], Step [96/111], Loss: 0.2665\n",
      "Epoch [56/100], Step [98/111], Loss: 0.2478\n",
      "Epoch [56/100], Step [100/111], Loss: 0.4749\n",
      "Epoch [56/100], Step [102/111], Loss: 0.3102\n",
      "Epoch [56/100], Step [104/111], Loss: 0.3095\n",
      "Epoch [56/100], Step [106/111], Loss: 0.2818\n",
      "Epoch [56/100], Step [108/111], Loss: 0.2592\n",
      "Epoch [56/100], Step [110/111], Loss: 0.2830\n",
      "Epoch [57/100], Step [2/111], Loss: 0.2014\n",
      "Epoch [57/100], Step [4/111], Loss: 0.2197\n",
      "Epoch [57/100], Step [6/111], Loss: 0.2153\n",
      "Epoch [57/100], Step [8/111], Loss: 0.2657\n",
      "Epoch [57/100], Step [10/111], Loss: 0.2705\n",
      "Epoch [57/100], Step [12/111], Loss: 2.0001\n",
      "Epoch [57/100], Step [14/111], Loss: 0.2836\n",
      "Epoch [57/100], Step [16/111], Loss: 0.2424\n",
      "Epoch [57/100], Step [18/111], Loss: 0.2549\n",
      "Epoch [57/100], Step [20/111], Loss: 0.2647\n",
      "Epoch [57/100], Step [22/111], Loss: 0.2469\n",
      "Epoch [57/100], Step [24/111], Loss: 0.2455\n",
      "Epoch [57/100], Step [26/111], Loss: 0.1886\n",
      "Epoch [57/100], Step [28/111], Loss: 0.3291\n",
      "Epoch [57/100], Step [30/111], Loss: 0.2716\n",
      "Epoch [57/100], Step [32/111], Loss: 0.1622\n",
      "Epoch [57/100], Step [34/111], Loss: 0.3659\n",
      "Epoch [57/100], Step [36/111], Loss: 0.2328\n",
      "Epoch [57/100], Step [38/111], Loss: 0.2488\n",
      "Epoch [57/100], Step [40/111], Loss: 0.2545\n",
      "Epoch [57/100], Step [42/111], Loss: 0.3006\n",
      "Epoch [57/100], Step [44/111], Loss: 0.3082\n",
      "Epoch [57/100], Step [46/111], Loss: 0.2389\n",
      "Epoch [57/100], Step [48/111], Loss: 0.3014\n",
      "Epoch [57/100], Step [50/111], Loss: 0.3567\n",
      "Epoch [57/100], Step [52/111], Loss: 0.2212\n",
      "Epoch [57/100], Step [54/111], Loss: 0.2044\n",
      "Epoch [57/100], Step [56/111], Loss: 0.1973\n",
      "Epoch [57/100], Step [58/111], Loss: 2.2738\n",
      "Epoch [57/100], Step [60/111], Loss: 0.2620\n",
      "Epoch [57/100], Step [62/111], Loss: 0.2653\n",
      "Epoch [57/100], Step [64/111], Loss: 0.3150\n",
      "Epoch [57/100], Step [66/111], Loss: 0.1912\n",
      "Epoch [57/100], Step [68/111], Loss: 0.2705\n",
      "Epoch [57/100], Step [70/111], Loss: 0.2589\n",
      "Epoch [57/100], Step [72/111], Loss: 0.3190\n",
      "Epoch [57/100], Step [74/111], Loss: 0.3684\n",
      "Epoch [57/100], Step [76/111], Loss: 0.2059\n",
      "Epoch [57/100], Step [78/111], Loss: 0.2547\n",
      "Epoch [57/100], Step [80/111], Loss: 0.2661\n",
      "Epoch [57/100], Step [82/111], Loss: 0.5124\n",
      "Epoch [57/100], Step [84/111], Loss: 0.2726\n",
      "Epoch [57/100], Step [86/111], Loss: 0.2286\n",
      "Epoch [57/100], Step [88/111], Loss: 0.2626\n",
      "Epoch [57/100], Step [90/111], Loss: 0.2765\n",
      "Epoch [57/100], Step [92/111], Loss: 0.2385\n",
      "Epoch [57/100], Step [94/111], Loss: 0.2721\n",
      "Epoch [57/100], Step [96/111], Loss: 0.2685\n",
      "Epoch [57/100], Step [98/111], Loss: 0.1942\n",
      "Epoch [57/100], Step [100/111], Loss: 0.2031\n",
      "Epoch [57/100], Step [102/111], Loss: 0.3124\n",
      "Epoch [57/100], Step [104/111], Loss: 0.2550\n",
      "Epoch [57/100], Step [106/111], Loss: 0.3735\n",
      "Epoch [57/100], Step [108/111], Loss: 0.2704\n",
      "Epoch [57/100], Step [110/111], Loss: 0.2955\n",
      "Epoch [58/100], Step [2/111], Loss: 0.2116\n",
      "Epoch [58/100], Step [4/111], Loss: 0.3540\n",
      "Epoch [58/100], Step [6/111], Loss: 0.2410\n",
      "Epoch [58/100], Step [8/111], Loss: 2.2206\n",
      "Epoch [58/100], Step [10/111], Loss: 0.5672\n",
      "Epoch [58/100], Step [12/111], Loss: 0.2716\n",
      "Epoch [58/100], Step [14/111], Loss: 3.7077\n",
      "Epoch [58/100], Step [16/111], Loss: 0.2811\n",
      "Epoch [58/100], Step [18/111], Loss: 0.2152\n",
      "Epoch [58/100], Step [20/111], Loss: 0.3498\n",
      "Epoch [58/100], Step [22/111], Loss: 0.1836\n",
      "Epoch [58/100], Step [24/111], Loss: 0.4055\n",
      "Epoch [58/100], Step [26/111], Loss: 0.2073\n",
      "Epoch [58/100], Step [28/111], Loss: 0.2742\n",
      "Epoch [58/100], Step [30/111], Loss: 0.2867\n",
      "Epoch [58/100], Step [32/111], Loss: 0.3554\n",
      "Epoch [58/100], Step [34/111], Loss: 0.3079\n",
      "Epoch [58/100], Step [36/111], Loss: 0.2732\n",
      "Epoch [58/100], Step [38/111], Loss: 0.3031\n",
      "Epoch [58/100], Step [40/111], Loss: 0.2106\n",
      "Epoch [58/100], Step [42/111], Loss: 0.3623\n",
      "Epoch [58/100], Step [44/111], Loss: 0.3251\n",
      "Epoch [58/100], Step [46/111], Loss: 0.5306\n",
      "Epoch [58/100], Step [48/111], Loss: 0.1669\n",
      "Epoch [58/100], Step [50/111], Loss: 0.2142\n",
      "Epoch [58/100], Step [52/111], Loss: 0.4026\n",
      "Epoch [58/100], Step [54/111], Loss: 0.2144\n",
      "Epoch [58/100], Step [56/111], Loss: 0.3947\n",
      "Epoch [58/100], Step [58/111], Loss: 0.2100\n",
      "Epoch [58/100], Step [60/111], Loss: 0.2527\n",
      "Epoch [58/100], Step [62/111], Loss: 0.2322\n",
      "Epoch [58/100], Step [64/111], Loss: 0.2692\n",
      "Epoch [58/100], Step [66/111], Loss: 0.2741\n",
      "Epoch [58/100], Step [68/111], Loss: 0.1728\n",
      "Epoch [58/100], Step [70/111], Loss: 0.2821\n",
      "Epoch [58/100], Step [72/111], Loss: 0.2034\n",
      "Epoch [58/100], Step [74/111], Loss: 0.2090\n",
      "Epoch [58/100], Step [76/111], Loss: 0.1872\n",
      "Epoch [58/100], Step [78/111], Loss: 0.3666\n",
      "Epoch [58/100], Step [80/111], Loss: 0.2097\n",
      "Epoch [58/100], Step [82/111], Loss: 0.1696\n",
      "Epoch [58/100], Step [84/111], Loss: 0.2185\n",
      "Epoch [58/100], Step [86/111], Loss: 0.1868\n",
      "Epoch [58/100], Step [88/111], Loss: 0.2103\n",
      "Epoch [58/100], Step [90/111], Loss: 0.2436\n",
      "Epoch [58/100], Step [92/111], Loss: 0.3472\n",
      "Epoch [58/100], Step [94/111], Loss: 0.2365\n",
      "Epoch [58/100], Step [96/111], Loss: 0.2524\n",
      "Epoch [58/100], Step [98/111], Loss: 0.2698\n",
      "Epoch [58/100], Step [100/111], Loss: 0.2442\n",
      "Epoch [58/100], Step [102/111], Loss: 0.1785\n",
      "Epoch [58/100], Step [104/111], Loss: 0.2403\n",
      "Epoch [58/100], Step [106/111], Loss: 0.2889\n",
      "Epoch [58/100], Step [108/111], Loss: 0.2142\n",
      "Epoch [58/100], Step [110/111], Loss: 0.3669\n",
      "Epoch [59/100], Step [2/111], Loss: 0.4339\n",
      "Epoch [59/100], Step [4/111], Loss: 0.2709\n",
      "Epoch [59/100], Step [6/111], Loss: 0.3707\n",
      "Epoch [59/100], Step [8/111], Loss: 0.2174\n",
      "Epoch [59/100], Step [10/111], Loss: 0.2365\n",
      "Epoch [59/100], Step [12/111], Loss: 0.2429\n",
      "Epoch [59/100], Step [14/111], Loss: 0.2544\n",
      "Epoch [59/100], Step [16/111], Loss: 0.2998\n",
      "Epoch [59/100], Step [18/111], Loss: 0.1883\n",
      "Epoch [59/100], Step [20/111], Loss: 0.3063\n",
      "Epoch [59/100], Step [22/111], Loss: 0.2509\n",
      "Epoch [59/100], Step [24/111], Loss: 0.4591\n",
      "Epoch [59/100], Step [26/111], Loss: 0.2432\n",
      "Epoch [59/100], Step [28/111], Loss: 0.2536\n",
      "Epoch [59/100], Step [30/111], Loss: 0.2061\n",
      "Epoch [59/100], Step [32/111], Loss: 0.2640\n",
      "Epoch [59/100], Step [34/111], Loss: 0.2422\n",
      "Epoch [59/100], Step [36/111], Loss: 0.2963\n",
      "Epoch [59/100], Step [38/111], Loss: 0.3874\n",
      "Epoch [59/100], Step [40/111], Loss: 0.2451\n",
      "Epoch [59/100], Step [42/111], Loss: 0.2371\n",
      "Epoch [59/100], Step [44/111], Loss: 0.2450\n",
      "Epoch [59/100], Step [46/111], Loss: 0.2761\n",
      "Epoch [59/100], Step [48/111], Loss: 0.2106\n",
      "Epoch [59/100], Step [50/111], Loss: 0.1906\n",
      "Epoch [59/100], Step [52/111], Loss: 0.2045\n",
      "Epoch [59/100], Step [54/111], Loss: 0.3403\n",
      "Epoch [59/100], Step [56/111], Loss: 0.2057\n",
      "Epoch [59/100], Step [58/111], Loss: 0.2035\n",
      "Epoch [59/100], Step [60/111], Loss: 0.1665\n",
      "Epoch [59/100], Step [62/111], Loss: 0.3413\n",
      "Epoch [59/100], Step [64/111], Loss: 0.2577\n",
      "Epoch [59/100], Step [66/111], Loss: 0.2344\n",
      "Epoch [59/100], Step [68/111], Loss: 0.2045\n",
      "Epoch [59/100], Step [70/111], Loss: 0.1939\n",
      "Epoch [59/100], Step [72/111], Loss: 0.2276\n",
      "Epoch [59/100], Step [74/111], Loss: 0.1664\n",
      "Epoch [59/100], Step [76/111], Loss: 0.1799\n",
      "Epoch [59/100], Step [78/111], Loss: 0.2391\n",
      "Epoch [59/100], Step [80/111], Loss: 0.2510\n",
      "Epoch [59/100], Step [82/111], Loss: 4.0507\n",
      "Epoch [59/100], Step [84/111], Loss: 1.8339\n",
      "Epoch [59/100], Step [86/111], Loss: 0.2806\n",
      "Epoch [59/100], Step [88/111], Loss: 0.2027\n",
      "Epoch [59/100], Step [90/111], Loss: 0.2154\n",
      "Epoch [59/100], Step [92/111], Loss: 0.2543\n",
      "Epoch [59/100], Step [94/111], Loss: 0.2239\n",
      "Epoch [59/100], Step [96/111], Loss: 3.4023\n",
      "Epoch [59/100], Step [98/111], Loss: 0.2538\n",
      "Epoch [59/100], Step [100/111], Loss: 3.1742\n",
      "Epoch [59/100], Step [102/111], Loss: 0.2843\n",
      "Epoch [59/100], Step [104/111], Loss: 0.3177\n",
      "Epoch [59/100], Step [106/111], Loss: 0.3063\n",
      "Epoch [59/100], Step [108/111], Loss: 0.2682\n",
      "Epoch [59/100], Step [110/111], Loss: 0.3088\n",
      "Epoch [60/100], Step [2/111], Loss: 0.3037\n",
      "Epoch [60/100], Step [4/111], Loss: 0.2139\n",
      "Epoch [60/100], Step [6/111], Loss: 0.6496\n",
      "Epoch [60/100], Step [8/111], Loss: 0.2236\n",
      "Epoch [60/100], Step [10/111], Loss: 0.2220\n",
      "Epoch [60/100], Step [12/111], Loss: 0.3513\n",
      "Epoch [60/100], Step [14/111], Loss: 0.3440\n",
      "Epoch [60/100], Step [16/111], Loss: 0.2901\n",
      "Epoch [60/100], Step [18/111], Loss: 0.1956\n",
      "Epoch [60/100], Step [20/111], Loss: 0.3589\n",
      "Epoch [60/100], Step [22/111], Loss: 0.1822\n",
      "Epoch [60/100], Step [24/111], Loss: 0.2096\n",
      "Epoch [60/100], Step [26/111], Loss: 0.1870\n",
      "Epoch [60/100], Step [28/111], Loss: 0.1845\n",
      "Epoch [60/100], Step [30/111], Loss: 0.1834\n",
      "Epoch [60/100], Step [32/111], Loss: 0.2139\n",
      "Epoch [60/100], Step [34/111], Loss: 0.2839\n",
      "Epoch [60/100], Step [36/111], Loss: 0.2971\n",
      "Epoch [60/100], Step [38/111], Loss: 0.1866\n",
      "Epoch [60/100], Step [40/111], Loss: 0.3558\n",
      "Epoch [60/100], Step [42/111], Loss: 0.1788\n",
      "Epoch [60/100], Step [44/111], Loss: 0.1726\n",
      "Epoch [60/100], Step [46/111], Loss: 0.3454\n",
      "Epoch [60/100], Step [48/111], Loss: 0.4166\n",
      "Epoch [60/100], Step [50/111], Loss: 0.2375\n",
      "Epoch [60/100], Step [52/111], Loss: 0.2369\n",
      "Epoch [60/100], Step [54/111], Loss: 0.2702\n",
      "Epoch [60/100], Step [56/111], Loss: 0.2706\n",
      "Epoch [60/100], Step [58/111], Loss: 0.2691\n",
      "Epoch [60/100], Step [60/111], Loss: 0.3077\n",
      "Epoch [60/100], Step [62/111], Loss: 0.2598\n",
      "Epoch [60/100], Step [64/111], Loss: 0.3709\n",
      "Epoch [60/100], Step [66/111], Loss: 0.3112\n",
      "Epoch [60/100], Step [68/111], Loss: 0.1699\n",
      "Epoch [60/100], Step [70/111], Loss: 0.2067\n",
      "Epoch [60/100], Step [72/111], Loss: 0.1611\n",
      "Epoch [60/100], Step [74/111], Loss: 0.2182\n",
      "Epoch [60/100], Step [76/111], Loss: 0.2589\n",
      "Epoch [60/100], Step [78/111], Loss: 0.3426\n",
      "Epoch [60/100], Step [80/111], Loss: 0.3455\n",
      "Epoch [60/100], Step [82/111], Loss: 3.3771\n",
      "Epoch [60/100], Step [84/111], Loss: 0.2585\n",
      "Epoch [60/100], Step [86/111], Loss: 0.2248\n",
      "Epoch [60/100], Step [88/111], Loss: 0.2463\n",
      "Epoch [60/100], Step [90/111], Loss: 2.9470\n",
      "Epoch [60/100], Step [92/111], Loss: 0.2058\n",
      "Epoch [60/100], Step [94/111], Loss: 0.6266\n",
      "Epoch [60/100], Step [96/111], Loss: 0.2134\n",
      "Epoch [60/100], Step [98/111], Loss: 0.2608\n",
      "Epoch [60/100], Step [100/111], Loss: 0.2096\n",
      "Epoch [60/100], Step [102/111], Loss: 0.1941\n",
      "Epoch [60/100], Step [104/111], Loss: 0.2643\n",
      "Epoch [60/100], Step [106/111], Loss: 0.2027\n",
      "Epoch [60/100], Step [108/111], Loss: 0.2553\n",
      "Epoch [60/100], Step [110/111], Loss: 0.2219\n",
      "Epoch [61/100], Step [2/111], Loss: 0.2160\n",
      "Epoch [61/100], Step [4/111], Loss: 0.2281\n",
      "Epoch [61/100], Step [6/111], Loss: 0.2476\n",
      "Epoch [61/100], Step [8/111], Loss: 0.2711\n",
      "Epoch [61/100], Step [10/111], Loss: 0.3513\n",
      "Epoch [61/100], Step [12/111], Loss: 0.2262\n",
      "Epoch [61/100], Step [14/111], Loss: 0.1843\n",
      "Epoch [61/100], Step [16/111], Loss: 0.1664\n",
      "Epoch [61/100], Step [18/111], Loss: 0.2039\n",
      "Epoch [61/100], Step [20/111], Loss: 0.2145\n",
      "Epoch [61/100], Step [22/111], Loss: 0.1360\n",
      "Epoch [61/100], Step [24/111], Loss: 0.1545\n",
      "Epoch [61/100], Step [26/111], Loss: 1.9580\n",
      "Epoch [61/100], Step [28/111], Loss: 0.1997\n",
      "Epoch [61/100], Step [30/111], Loss: 0.1456\n",
      "Epoch [61/100], Step [32/111], Loss: 0.2168\n",
      "Epoch [61/100], Step [34/111], Loss: 0.2421\n",
      "Epoch [61/100], Step [36/111], Loss: 0.1641\n",
      "Epoch [61/100], Step [38/111], Loss: 0.2827\n",
      "Epoch [61/100], Step [40/111], Loss: 0.2803\n",
      "Epoch [61/100], Step [42/111], Loss: 0.1874\n",
      "Epoch [61/100], Step [44/111], Loss: 0.2125\n",
      "Epoch [61/100], Step [46/111], Loss: 0.2896\n",
      "Epoch [61/100], Step [48/111], Loss: 5.1625\n",
      "Epoch [61/100], Step [50/111], Loss: 0.3054\n",
      "Epoch [61/100], Step [52/111], Loss: 0.2322\n",
      "Epoch [61/100], Step [54/111], Loss: 0.2741\n",
      "Epoch [61/100], Step [56/111], Loss: 0.2016\n",
      "Epoch [61/100], Step [58/111], Loss: 0.2539\n",
      "Epoch [61/100], Step [60/111], Loss: 0.2328\n",
      "Epoch [61/100], Step [62/111], Loss: 0.3401\n",
      "Epoch [61/100], Step [64/111], Loss: 0.2914\n",
      "Epoch [61/100], Step [66/111], Loss: 0.2142\n",
      "Epoch [61/100], Step [68/111], Loss: 0.2084\n",
      "Epoch [61/100], Step [70/111], Loss: 0.1922\n",
      "Epoch [61/100], Step [72/111], Loss: 0.2649\n",
      "Epoch [61/100], Step [74/111], Loss: 0.1484\n",
      "Epoch [61/100], Step [76/111], Loss: 0.2534\n",
      "Epoch [61/100], Step [78/111], Loss: 0.2513\n",
      "Epoch [61/100], Step [80/111], Loss: 0.3098\n",
      "Epoch [61/100], Step [82/111], Loss: 0.2148\n",
      "Epoch [61/100], Step [84/111], Loss: 0.5523\n",
      "Epoch [61/100], Step [86/111], Loss: 0.2570\n",
      "Epoch [61/100], Step [88/111], Loss: 0.1883\n",
      "Epoch [61/100], Step [90/111], Loss: 0.1964\n",
      "Epoch [61/100], Step [92/111], Loss: 0.2011\n",
      "Epoch [61/100], Step [94/111], Loss: 0.4314\n",
      "Epoch [61/100], Step [96/111], Loss: 0.5183\n",
      "Epoch [61/100], Step [98/111], Loss: 0.2992\n",
      "Epoch [61/100], Step [100/111], Loss: 0.2391\n",
      "Epoch [61/100], Step [102/111], Loss: 0.2984\n",
      "Epoch [61/100], Step [104/111], Loss: 0.2214\n",
      "Epoch [61/100], Step [106/111], Loss: 0.3362\n",
      "Epoch [61/100], Step [108/111], Loss: 0.3466\n",
      "Epoch [61/100], Step [110/111], Loss: 0.3998\n",
      "Epoch [62/100], Step [2/111], Loss: 0.3519\n",
      "Epoch [62/100], Step [4/111], Loss: 0.2348\n",
      "Epoch [62/100], Step [6/111], Loss: 0.2648\n",
      "Epoch [62/100], Step [8/111], Loss: 0.1940\n",
      "Epoch [62/100], Step [10/111], Loss: 0.2458\n",
      "Epoch [62/100], Step [12/111], Loss: 0.2524\n",
      "Epoch [62/100], Step [14/111], Loss: 0.2947\n",
      "Epoch [62/100], Step [16/111], Loss: 0.2152\n",
      "Epoch [62/100], Step [18/111], Loss: 0.2509\n",
      "Epoch [62/100], Step [20/111], Loss: 0.1730\n",
      "Epoch [62/100], Step [22/111], Loss: 0.1206\n",
      "Epoch [62/100], Step [24/111], Loss: 0.2411\n",
      "Epoch [62/100], Step [26/111], Loss: 0.2557\n",
      "Epoch [62/100], Step [28/111], Loss: 0.2814\n",
      "Epoch [62/100], Step [30/111], Loss: 0.1724\n",
      "Epoch [62/100], Step [32/111], Loss: 0.2750\n",
      "Epoch [62/100], Step [34/111], Loss: 0.2783\n",
      "Epoch [62/100], Step [36/111], Loss: 0.2087\n",
      "Epoch [62/100], Step [38/111], Loss: 0.3537\n",
      "Epoch [62/100], Step [40/111], Loss: 0.1949\n",
      "Epoch [62/100], Step [42/111], Loss: 0.3891\n",
      "Epoch [62/100], Step [44/111], Loss: 0.3416\n",
      "Epoch [62/100], Step [46/111], Loss: 0.2908\n",
      "Epoch [62/100], Step [48/111], Loss: 0.2308\n",
      "Epoch [62/100], Step [50/111], Loss: 0.3057\n",
      "Epoch [62/100], Step [52/111], Loss: 0.2755\n",
      "Epoch [62/100], Step [54/111], Loss: 0.3196\n",
      "Epoch [62/100], Step [56/111], Loss: 0.2114\n",
      "Epoch [62/100], Step [58/111], Loss: 0.2201\n",
      "Epoch [62/100], Step [60/111], Loss: 0.2866\n",
      "Epoch [62/100], Step [62/111], Loss: 0.1929\n",
      "Epoch [62/100], Step [64/111], Loss: 0.2154\n",
      "Epoch [62/100], Step [66/111], Loss: 0.2401\n",
      "Epoch [62/100], Step [68/111], Loss: 0.3683\n",
      "Epoch [62/100], Step [70/111], Loss: 0.2469\n",
      "Epoch [62/100], Step [72/111], Loss: 0.2142\n",
      "Epoch [62/100], Step [74/111], Loss: 0.1906\n",
      "Epoch [62/100], Step [76/111], Loss: 0.2274\n",
      "Epoch [62/100], Step [78/111], Loss: 0.2356\n",
      "Epoch [62/100], Step [80/111], Loss: 0.2423\n",
      "Epoch [62/100], Step [82/111], Loss: 0.2323\n",
      "Epoch [62/100], Step [84/111], Loss: 0.2380\n",
      "Epoch [62/100], Step [86/111], Loss: 0.2338\n",
      "Epoch [62/100], Step [88/111], Loss: 0.3153\n",
      "Epoch [62/100], Step [90/111], Loss: 0.3195\n",
      "Epoch [62/100], Step [92/111], Loss: 0.1887\n",
      "Epoch [62/100], Step [94/111], Loss: 0.2675\n",
      "Epoch [62/100], Step [96/111], Loss: 0.1955\n",
      "Epoch [62/100], Step [98/111], Loss: 0.2065\n",
      "Epoch [62/100], Step [100/111], Loss: 0.1887\n",
      "Epoch [62/100], Step [102/111], Loss: 0.2211\n",
      "Epoch [62/100], Step [104/111], Loss: 3.3147\n",
      "Epoch [62/100], Step [106/111], Loss: 0.1934\n",
      "Epoch [62/100], Step [108/111], Loss: 0.2180\n",
      "Epoch [62/100], Step [110/111], Loss: 0.2816\n",
      "Epoch [63/100], Step [2/111], Loss: 0.8787\n",
      "Epoch [63/100], Step [4/111], Loss: 1.2573\n",
      "Epoch [63/100], Step [6/111], Loss: 0.4995\n",
      "Epoch [63/100], Step [8/111], Loss: 0.7886\n",
      "Epoch [63/100], Step [10/111], Loss: 0.4480\n",
      "Epoch [63/100], Step [12/111], Loss: 0.8061\n",
      "Epoch [63/100], Step [14/111], Loss: 0.5279\n",
      "Epoch [63/100], Step [16/111], Loss: 0.6663\n",
      "Epoch [63/100], Step [18/111], Loss: 0.6042\n",
      "Epoch [63/100], Step [20/111], Loss: 0.3856\n",
      "Epoch [63/100], Step [22/111], Loss: 0.3896\n",
      "Epoch [63/100], Step [24/111], Loss: 0.2950\n",
      "Epoch [63/100], Step [26/111], Loss: 0.2381\n",
      "Epoch [63/100], Step [28/111], Loss: 0.5829\n",
      "Epoch [63/100], Step [30/111], Loss: 0.3471\n",
      "Epoch [63/100], Step [32/111], Loss: 0.4151\n",
      "Epoch [63/100], Step [34/111], Loss: 0.3454\n",
      "Epoch [63/100], Step [36/111], Loss: 0.2414\n",
      "Epoch [63/100], Step [38/111], Loss: 0.4105\n",
      "Epoch [63/100], Step [40/111], Loss: 0.2450\n",
      "Epoch [63/100], Step [42/111], Loss: 0.2521\n",
      "Epoch [63/100], Step [44/111], Loss: 0.3769\n",
      "Epoch [63/100], Step [46/111], Loss: 0.3214\n",
      "Epoch [63/100], Step [48/111], Loss: 1.6316\n",
      "Epoch [63/100], Step [50/111], Loss: 0.5127\n",
      "Epoch [63/100], Step [52/111], Loss: 3.6724\n",
      "Epoch [63/100], Step [54/111], Loss: 0.4982\n",
      "Epoch [63/100], Step [56/111], Loss: 1.0299\n",
      "Epoch [63/100], Step [58/111], Loss: 0.6086\n",
      "Epoch [63/100], Step [60/111], Loss: 0.5149\n",
      "Epoch [63/100], Step [62/111], Loss: 0.7365\n",
      "Epoch [63/100], Step [64/111], Loss: 0.4488\n",
      "Epoch [63/100], Step [66/111], Loss: 0.4225\n",
      "Epoch [63/100], Step [68/111], Loss: 4.7251\n",
      "Epoch [63/100], Step [70/111], Loss: 0.7176\n",
      "Epoch [63/100], Step [72/111], Loss: 0.4422\n",
      "Epoch [63/100], Step [74/111], Loss: 1.0566\n",
      "Epoch [63/100], Step [76/111], Loss: 0.5375\n",
      "Epoch [63/100], Step [78/111], Loss: 0.5882\n",
      "Epoch [63/100], Step [80/111], Loss: 0.6026\n",
      "Epoch [63/100], Step [82/111], Loss: 0.4323\n",
      "Epoch [63/100], Step [84/111], Loss: 0.5460\n",
      "Epoch [63/100], Step [86/111], Loss: 5.7319\n",
      "Epoch [63/100], Step [88/111], Loss: 0.6231\n",
      "Epoch [63/100], Step [90/111], Loss: 0.5150\n",
      "Epoch [63/100], Step [92/111], Loss: 0.4856\n",
      "Epoch [63/100], Step [94/111], Loss: 0.5466\n",
      "Epoch [63/100], Step [96/111], Loss: 0.4747\n",
      "Epoch [63/100], Step [98/111], Loss: 0.5191\n",
      "Epoch [63/100], Step [100/111], Loss: 1.2249\n",
      "Epoch [63/100], Step [102/111], Loss: 0.4915\n",
      "Epoch [63/100], Step [104/111], Loss: 2.6715\n",
      "Epoch [63/100], Step [106/111], Loss: 0.3694\n",
      "Epoch [63/100], Step [108/111], Loss: 0.6577\n",
      "Epoch [63/100], Step [110/111], Loss: 0.5017\n",
      "Epoch [64/100], Step [2/111], Loss: 0.6450\n",
      "Epoch [64/100], Step [4/111], Loss: 0.6989\n",
      "Epoch [64/100], Step [6/111], Loss: 0.9188\n",
      "Epoch [64/100], Step [8/111], Loss: 0.4927\n",
      "Epoch [64/100], Step [10/111], Loss: 0.5697\n",
      "Epoch [64/100], Step [12/111], Loss: 0.5222\n",
      "Epoch [64/100], Step [14/111], Loss: 0.7516\n",
      "Epoch [64/100], Step [16/111], Loss: 0.4143\n",
      "Epoch [64/100], Step [18/111], Loss: 0.9754\n",
      "Epoch [64/100], Step [20/111], Loss: 0.7024\n",
      "Epoch [64/100], Step [22/111], Loss: 0.5936\n",
      "Epoch [64/100], Step [24/111], Loss: 0.7412\n",
      "Epoch [64/100], Step [26/111], Loss: 4.4962\n",
      "Epoch [64/100], Step [28/111], Loss: 1.0925\n",
      "Epoch [64/100], Step [30/111], Loss: 0.5322\n",
      "Epoch [64/100], Step [32/111], Loss: 0.5674\n",
      "Epoch [64/100], Step [34/111], Loss: 0.5786\n",
      "Epoch [64/100], Step [36/111], Loss: 0.6421\n",
      "Epoch [64/100], Step [38/111], Loss: 4.0194\n",
      "Epoch [64/100], Step [40/111], Loss: 0.7385\n",
      "Epoch [64/100], Step [42/111], Loss: 0.4832\n",
      "Epoch [64/100], Step [44/111], Loss: 0.4603\n",
      "Epoch [64/100], Step [46/111], Loss: 0.3730\n",
      "Epoch [64/100], Step [48/111], Loss: 0.6095\n",
      "Epoch [64/100], Step [50/111], Loss: 0.6088\n",
      "Epoch [64/100], Step [52/111], Loss: 0.4930\n",
      "Epoch [64/100], Step [54/111], Loss: 0.6069\n",
      "Epoch [64/100], Step [56/111], Loss: 0.5115\n",
      "Epoch [64/100], Step [58/111], Loss: 0.7176\n",
      "Epoch [64/100], Step [60/111], Loss: 2.5000\n",
      "Epoch [64/100], Step [62/111], Loss: 0.4321\n",
      "Epoch [64/100], Step [64/111], Loss: 0.6402\n",
      "Epoch [64/100], Step [66/111], Loss: 0.4178\n",
      "Epoch [64/100], Step [68/111], Loss: 0.4055\n",
      "Epoch [64/100], Step [70/111], Loss: 0.5050\n",
      "Epoch [64/100], Step [72/111], Loss: 0.3959\n",
      "Epoch [64/100], Step [74/111], Loss: 0.8426\n",
      "Epoch [64/100], Step [76/111], Loss: 0.4375\n",
      "Epoch [64/100], Step [78/111], Loss: 0.4230\n",
      "Epoch [64/100], Step [80/111], Loss: 0.3754\n",
      "Epoch [64/100], Step [82/111], Loss: 0.6218\n",
      "Epoch [64/100], Step [84/111], Loss: 0.7230\n",
      "Epoch [64/100], Step [86/111], Loss: 0.5726\n",
      "Epoch [64/100], Step [88/111], Loss: 0.4895\n",
      "Epoch [64/100], Step [90/111], Loss: 0.4455\n",
      "Epoch [64/100], Step [92/111], Loss: 0.4187\n",
      "Epoch [64/100], Step [94/111], Loss: 0.6864\n",
      "Epoch [64/100], Step [96/111], Loss: 0.4458\n",
      "Epoch [64/100], Step [98/111], Loss: 0.6053\n",
      "Epoch [64/100], Step [100/111], Loss: 0.3723\n",
      "Epoch [64/100], Step [102/111], Loss: 0.4071\n",
      "Epoch [64/100], Step [104/111], Loss: 0.6630\n",
      "Epoch [64/100], Step [106/111], Loss: 0.3952\n",
      "Epoch [64/100], Step [108/111], Loss: 0.5582\n",
      "Epoch [64/100], Step [110/111], Loss: 0.4925\n",
      "Epoch [65/100], Step [2/111], Loss: 1.2033\n",
      "Epoch [65/100], Step [4/111], Loss: 0.3876\n",
      "Epoch [65/100], Step [6/111], Loss: 0.5179\n",
      "Epoch [65/100], Step [8/111], Loss: 0.3112\n",
      "Epoch [65/100], Step [10/111], Loss: 0.4931\n",
      "Epoch [65/100], Step [12/111], Loss: 0.4169\n",
      "Epoch [65/100], Step [14/111], Loss: 0.6329\n",
      "Epoch [65/100], Step [16/111], Loss: 0.4692\n",
      "Epoch [65/100], Step [18/111], Loss: 0.5408\n",
      "Epoch [65/100], Step [20/111], Loss: 0.7563\n",
      "Epoch [65/100], Step [22/111], Loss: 0.4546\n",
      "Epoch [65/100], Step [24/111], Loss: 0.6038\n",
      "Epoch [65/100], Step [26/111], Loss: 0.4211\n",
      "Epoch [65/100], Step [28/111], Loss: 0.3556\n",
      "Epoch [65/100], Step [30/111], Loss: 0.3832\n",
      "Epoch [65/100], Step [32/111], Loss: 0.2942\n",
      "Epoch [65/100], Step [34/111], Loss: 0.3879\n",
      "Epoch [65/100], Step [36/111], Loss: 0.3177\n",
      "Epoch [65/100], Step [38/111], Loss: 2.0574\n",
      "Epoch [65/100], Step [40/111], Loss: 0.6024\n",
      "Epoch [65/100], Step [42/111], Loss: 0.3822\n",
      "Epoch [65/100], Step [44/111], Loss: 0.2811\n",
      "Epoch [65/100], Step [46/111], Loss: 0.3601\n",
      "Epoch [65/100], Step [48/111], Loss: 0.3611\n",
      "Epoch [65/100], Step [50/111], Loss: 0.3853\n",
      "Epoch [65/100], Step [52/111], Loss: 0.4062\n",
      "Epoch [65/100], Step [54/111], Loss: 1.9068\n",
      "Epoch [65/100], Step [56/111], Loss: 0.4073\n",
      "Epoch [65/100], Step [58/111], Loss: 0.3682\n",
      "Epoch [65/100], Step [60/111], Loss: 0.3411\n",
      "Epoch [65/100], Step [62/111], Loss: 0.4351\n",
      "Epoch [65/100], Step [64/111], Loss: 0.3343\n",
      "Epoch [65/100], Step [66/111], Loss: 0.2625\n",
      "Epoch [65/100], Step [68/111], Loss: 0.3238\n",
      "Epoch [65/100], Step [70/111], Loss: 0.2894\n",
      "Epoch [65/100], Step [72/111], Loss: 0.3749\n",
      "Epoch [65/100], Step [74/111], Loss: 0.2841\n",
      "Epoch [65/100], Step [76/111], Loss: 0.3741\n",
      "Epoch [65/100], Step [78/111], Loss: 0.3350\n",
      "Epoch [65/100], Step [80/111], Loss: 0.3204\n",
      "Epoch [65/100], Step [82/111], Loss: 0.4062\n",
      "Epoch [65/100], Step [84/111], Loss: 0.3303\n",
      "Epoch [65/100], Step [86/111], Loss: 0.2393\n",
      "Epoch [65/100], Step [88/111], Loss: 0.2086\n",
      "Epoch [65/100], Step [90/111], Loss: 0.2538\n",
      "Epoch [65/100], Step [92/111], Loss: 0.2623\n",
      "Epoch [65/100], Step [94/111], Loss: 0.3156\n",
      "Epoch [65/100], Step [96/111], Loss: 0.2562\n",
      "Epoch [65/100], Step [98/111], Loss: 5.5774\n",
      "Epoch [65/100], Step [100/111], Loss: 0.4509\n",
      "Epoch [65/100], Step [102/111], Loss: 0.2997\n",
      "Epoch [65/100], Step [104/111], Loss: 0.3334\n",
      "Epoch [65/100], Step [106/111], Loss: 0.2593\n",
      "Epoch [65/100], Step [108/111], Loss: 0.4348\n",
      "Epoch [65/100], Step [110/111], Loss: 0.3067\n",
      "Epoch [66/100], Step [2/111], Loss: 0.2204\n",
      "Epoch [66/100], Step [4/111], Loss: 0.2576\n",
      "Epoch [66/100], Step [6/111], Loss: 0.4505\n",
      "Epoch [66/100], Step [8/111], Loss: 0.2670\n",
      "Epoch [66/100], Step [10/111], Loss: 0.2851\n",
      "Epoch [66/100], Step [12/111], Loss: 0.2814\n",
      "Epoch [66/100], Step [14/111], Loss: 0.2726\n",
      "Epoch [66/100], Step [16/111], Loss: 0.2226\n",
      "Epoch [66/100], Step [18/111], Loss: 0.2156\n",
      "Epoch [66/100], Step [20/111], Loss: 0.3160\n",
      "Epoch [66/100], Step [22/111], Loss: 0.3394\n",
      "Epoch [66/100], Step [24/111], Loss: 0.3892\n",
      "Epoch [66/100], Step [26/111], Loss: 0.5113\n",
      "Epoch [66/100], Step [28/111], Loss: 0.2593\n",
      "Epoch [66/100], Step [30/111], Loss: 0.3258\n",
      "Epoch [66/100], Step [32/111], Loss: 0.2548\n",
      "Epoch [66/100], Step [34/111], Loss: 0.2752\n",
      "Epoch [66/100], Step [36/111], Loss: 0.2071\n",
      "Epoch [66/100], Step [38/111], Loss: 0.3269\n",
      "Epoch [66/100], Step [40/111], Loss: 0.2424\n",
      "Epoch [66/100], Step [42/111], Loss: 0.2130\n",
      "Epoch [66/100], Step [44/111], Loss: 0.3102\n",
      "Epoch [66/100], Step [46/111], Loss: 0.2655\n",
      "Epoch [66/100], Step [48/111], Loss: 0.2983\n",
      "Epoch [66/100], Step [50/111], Loss: 0.3396\n",
      "Epoch [66/100], Step [52/111], Loss: 0.2910\n",
      "Epoch [66/100], Step [54/111], Loss: 0.4462\n",
      "Epoch [66/100], Step [56/111], Loss: 0.2235\n",
      "Epoch [66/100], Step [58/111], Loss: 0.2542\n",
      "Epoch [66/100], Step [60/111], Loss: 0.2564\n",
      "Epoch [66/100], Step [62/111], Loss: 0.2659\n",
      "Epoch [66/100], Step [64/111], Loss: 0.2692\n",
      "Epoch [66/100], Step [66/111], Loss: 0.2476\n",
      "Epoch [66/100], Step [68/111], Loss: 0.2622\n",
      "Epoch [66/100], Step [70/111], Loss: 0.2904\n",
      "Epoch [66/100], Step [72/111], Loss: 0.2483\n",
      "Epoch [66/100], Step [74/111], Loss: 0.2957\n",
      "Epoch [66/100], Step [76/111], Loss: 0.3184\n",
      "Epoch [66/100], Step [78/111], Loss: 0.3654\n",
      "Epoch [66/100], Step [80/111], Loss: 0.7265\n",
      "Epoch [66/100], Step [82/111], Loss: 0.2628\n",
      "Epoch [66/100], Step [84/111], Loss: 0.3381\n",
      "Epoch [66/100], Step [86/111], Loss: 0.2542\n",
      "Epoch [66/100], Step [88/111], Loss: 0.2327\n",
      "Epoch [66/100], Step [90/111], Loss: 0.2922\n",
      "Epoch [66/100], Step [92/111], Loss: 0.2400\n",
      "Epoch [66/100], Step [94/111], Loss: 0.3271\n",
      "Epoch [66/100], Step [96/111], Loss: 0.2408\n",
      "Epoch [66/100], Step [98/111], Loss: 0.2747\n",
      "Epoch [66/100], Step [100/111], Loss: 1.9129\n",
      "Epoch [66/100], Step [102/111], Loss: 2.7375\n",
      "Epoch [66/100], Step [104/111], Loss: 0.2807\n",
      "Epoch [66/100], Step [106/111], Loss: 0.2007\n",
      "Epoch [66/100], Step [108/111], Loss: 0.3307\n",
      "Epoch [66/100], Step [110/111], Loss: 0.1807\n",
      "Epoch [67/100], Step [2/111], Loss: 0.2110\n",
      "Epoch [67/100], Step [4/111], Loss: 0.2402\n",
      "Epoch [67/100], Step [6/111], Loss: 0.4119\n",
      "Epoch [67/100], Step [8/111], Loss: 0.7527\n",
      "Epoch [67/100], Step [10/111], Loss: 0.3065\n",
      "Epoch [67/100], Step [12/111], Loss: 0.2569\n",
      "Epoch [67/100], Step [14/111], Loss: 0.2774\n",
      "Epoch [67/100], Step [16/111], Loss: 0.3118\n",
      "Epoch [67/100], Step [18/111], Loss: 0.2167\n",
      "Epoch [67/100], Step [20/111], Loss: 0.2631\n",
      "Epoch [67/100], Step [22/111], Loss: 0.2464\n",
      "Epoch [67/100], Step [24/111], Loss: 0.2449\n",
      "Epoch [67/100], Step [26/111], Loss: 0.2199\n",
      "Epoch [67/100], Step [28/111], Loss: 0.3745\n",
      "Epoch [67/100], Step [30/111], Loss: 0.2938\n",
      "Epoch [67/100], Step [32/111], Loss: 0.2717\n",
      "Epoch [67/100], Step [34/111], Loss: 0.2839\n",
      "Epoch [67/100], Step [36/111], Loss: 0.2003\n",
      "Epoch [67/100], Step [38/111], Loss: 0.1907\n",
      "Epoch [67/100], Step [40/111], Loss: 0.2173\n",
      "Epoch [67/100], Step [42/111], Loss: 0.2042\n",
      "Epoch [67/100], Step [44/111], Loss: 0.2813\n",
      "Epoch [67/100], Step [46/111], Loss: 0.2518\n",
      "Epoch [67/100], Step [48/111], Loss: 0.2727\n",
      "Epoch [67/100], Step [50/111], Loss: 0.2074\n",
      "Epoch [67/100], Step [52/111], Loss: 0.2185\n",
      "Epoch [67/100], Step [54/111], Loss: 0.1882\n",
      "Epoch [67/100], Step [56/111], Loss: 0.1711\n",
      "Epoch [67/100], Step [58/111], Loss: 0.1798\n",
      "Epoch [67/100], Step [60/111], Loss: 0.2028\n",
      "Epoch [67/100], Step [62/111], Loss: 0.2052\n",
      "Epoch [67/100], Step [64/111], Loss: 0.1665\n",
      "Epoch [67/100], Step [66/111], Loss: 0.2721\n",
      "Epoch [67/100], Step [68/111], Loss: 0.1969\n",
      "Epoch [67/100], Step [70/111], Loss: 0.1601\n",
      "Epoch [67/100], Step [72/111], Loss: 2.2175\n",
      "Epoch [67/100], Step [74/111], Loss: 0.2312\n",
      "Epoch [67/100], Step [76/111], Loss: 0.2944\n",
      "Epoch [67/100], Step [78/111], Loss: 0.2037\n",
      "Epoch [67/100], Step [80/111], Loss: 0.2435\n",
      "Epoch [67/100], Step [82/111], Loss: 0.2382\n",
      "Epoch [67/100], Step [84/111], Loss: 0.1956\n",
      "Epoch [67/100], Step [86/111], Loss: 0.2071\n",
      "Epoch [67/100], Step [88/111], Loss: 0.3642\n",
      "Epoch [67/100], Step [90/111], Loss: 0.1809\n",
      "Epoch [67/100], Step [92/111], Loss: 0.2849\n",
      "Epoch [67/100], Step [94/111], Loss: 0.2442\n",
      "Epoch [67/100], Step [96/111], Loss: 0.2569\n",
      "Epoch [67/100], Step [98/111], Loss: 0.2450\n",
      "Epoch [67/100], Step [100/111], Loss: 0.3359\n",
      "Epoch [67/100], Step [102/111], Loss: 0.1862\n",
      "Epoch [67/100], Step [104/111], Loss: 0.3028\n",
      "Epoch [67/100], Step [106/111], Loss: 0.2298\n",
      "Epoch [67/100], Step [108/111], Loss: 0.2462\n",
      "Epoch [67/100], Step [110/111], Loss: 0.2364\n",
      "Epoch [68/100], Step [2/111], Loss: 0.2990\n",
      "Epoch [68/100], Step [4/111], Loss: 0.4248\n",
      "Epoch [68/100], Step [6/111], Loss: 0.2386\n",
      "Epoch [68/100], Step [8/111], Loss: 0.2146\n",
      "Epoch [68/100], Step [10/111], Loss: 0.2989\n",
      "Epoch [68/100], Step [12/111], Loss: 0.5415\n",
      "Epoch [68/100], Step [14/111], Loss: 0.2745\n",
      "Epoch [68/100], Step [16/111], Loss: 0.3174\n",
      "Epoch [68/100], Step [18/111], Loss: 0.2966\n",
      "Epoch [68/100], Step [20/111], Loss: 0.2125\n",
      "Epoch [68/100], Step [22/111], Loss: 0.1825\n",
      "Epoch [68/100], Step [24/111], Loss: 0.2507\n",
      "Epoch [68/100], Step [26/111], Loss: 0.2076\n",
      "Epoch [68/100], Step [28/111], Loss: 2.1700\n",
      "Epoch [68/100], Step [30/111], Loss: 0.1875\n",
      "Epoch [68/100], Step [32/111], Loss: 0.1889\n",
      "Epoch [68/100], Step [34/111], Loss: 0.2745\n",
      "Epoch [68/100], Step [36/111], Loss: 0.2490\n",
      "Epoch [68/100], Step [38/111], Loss: 0.2591\n",
      "Epoch [68/100], Step [40/111], Loss: 0.2184\n",
      "Epoch [68/100], Step [42/111], Loss: 0.2197\n",
      "Epoch [68/100], Step [44/111], Loss: 0.2468\n",
      "Epoch [68/100], Step [46/111], Loss: 0.1982\n",
      "Epoch [68/100], Step [48/111], Loss: 4.8459\n",
      "Epoch [68/100], Step [50/111], Loss: 0.2509\n",
      "Epoch [68/100], Step [52/111], Loss: 0.2720\n",
      "Epoch [68/100], Step [54/111], Loss: 0.2109\n",
      "Epoch [68/100], Step [56/111], Loss: 0.1874\n",
      "Epoch [68/100], Step [58/111], Loss: 0.1957\n",
      "Epoch [68/100], Step [60/111], Loss: 0.2481\n",
      "Epoch [68/100], Step [62/111], Loss: 0.2213\n",
      "Epoch [68/100], Step [64/111], Loss: 0.3363\n",
      "Epoch [68/100], Step [66/111], Loss: 0.2978\n",
      "Epoch [68/100], Step [68/111], Loss: 0.2772\n",
      "Epoch [68/100], Step [70/111], Loss: 0.2233\n",
      "Epoch [68/100], Step [72/111], Loss: 0.3182\n",
      "Epoch [68/100], Step [74/111], Loss: 0.1729\n",
      "Epoch [68/100], Step [76/111], Loss: 0.3358\n",
      "Epoch [68/100], Step [78/111], Loss: 0.2799\n",
      "Epoch [68/100], Step [80/111], Loss: 0.2899\n",
      "Epoch [68/100], Step [82/111], Loss: 0.3073\n",
      "Epoch [68/100], Step [84/111], Loss: 0.3541\n",
      "Epoch [68/100], Step [86/111], Loss: 0.2233\n",
      "Epoch [68/100], Step [88/111], Loss: 0.3234\n",
      "Epoch [68/100], Step [90/111], Loss: 0.2941\n",
      "Epoch [68/100], Step [92/111], Loss: 0.2526\n",
      "Epoch [68/100], Step [94/111], Loss: 0.2921\n",
      "Epoch [68/100], Step [96/111], Loss: 0.3137\n",
      "Epoch [68/100], Step [98/111], Loss: 0.2432\n",
      "Epoch [68/100], Step [100/111], Loss: 0.2996\n",
      "Epoch [68/100], Step [102/111], Loss: 0.2334\n",
      "Epoch [68/100], Step [104/111], Loss: 0.2860\n",
      "Epoch [68/100], Step [106/111], Loss: 0.2620\n",
      "Epoch [68/100], Step [108/111], Loss: 0.2327\n",
      "Epoch [68/100], Step [110/111], Loss: 0.3749\n",
      "Epoch [69/100], Step [2/111], Loss: 0.2436\n",
      "Epoch [69/100], Step [4/111], Loss: 0.1776\n",
      "Epoch [69/100], Step [6/111], Loss: 0.1815\n",
      "Epoch [69/100], Step [8/111], Loss: 0.2591\n",
      "Epoch [69/100], Step [10/111], Loss: 0.1620\n",
      "Epoch [69/100], Step [12/111], Loss: 0.1886\n",
      "Epoch [69/100], Step [14/111], Loss: 0.2227\n",
      "Epoch [69/100], Step [16/111], Loss: 0.1766\n",
      "Epoch [69/100], Step [18/111], Loss: 0.2376\n",
      "Epoch [69/100], Step [20/111], Loss: 0.1643\n",
      "Epoch [69/100], Step [22/111], Loss: 0.2388\n",
      "Epoch [69/100], Step [24/111], Loss: 0.1759\n",
      "Epoch [69/100], Step [26/111], Loss: 0.1340\n",
      "Epoch [69/100], Step [28/111], Loss: 0.1853\n",
      "Epoch [69/100], Step [30/111], Loss: 2.6586\n",
      "Epoch [69/100], Step [32/111], Loss: 0.2330\n",
      "Epoch [69/100], Step [34/111], Loss: 0.1913\n",
      "Epoch [69/100], Step [36/111], Loss: 0.1908\n",
      "Epoch [69/100], Step [38/111], Loss: 0.1926\n",
      "Epoch [69/100], Step [40/111], Loss: 0.1884\n",
      "Epoch [69/100], Step [42/111], Loss: 0.1672\n",
      "Epoch [69/100], Step [44/111], Loss: 0.2907\n",
      "Epoch [69/100], Step [46/111], Loss: 0.1715\n",
      "Epoch [69/100], Step [48/111], Loss: 0.2097\n",
      "Epoch [69/100], Step [50/111], Loss: 0.2606\n",
      "Epoch [69/100], Step [52/111], Loss: 0.1658\n",
      "Epoch [69/100], Step [54/111], Loss: 0.2275\n",
      "Epoch [69/100], Step [56/111], Loss: 0.2070\n",
      "Epoch [69/100], Step [58/111], Loss: 0.2416\n",
      "Epoch [69/100], Step [60/111], Loss: 0.2688\n",
      "Epoch [69/100], Step [62/111], Loss: 0.2374\n",
      "Epoch [69/100], Step [64/111], Loss: 0.1484\n",
      "Epoch [69/100], Step [66/111], Loss: 0.1861\n",
      "Epoch [69/100], Step [68/111], Loss: 0.2512\n",
      "Epoch [69/100], Step [70/111], Loss: 0.2393\n",
      "Epoch [69/100], Step [72/111], Loss: 0.1968\n",
      "Epoch [69/100], Step [74/111], Loss: 0.2930\n",
      "Epoch [69/100], Step [76/111], Loss: 0.3632\n",
      "Epoch [69/100], Step [78/111], Loss: 0.1502\n",
      "Epoch [69/100], Step [80/111], Loss: 2.6505\n",
      "Epoch [69/100], Step [82/111], Loss: 0.1929\n",
      "Epoch [69/100], Step [84/111], Loss: 0.2488\n",
      "Epoch [69/100], Step [86/111], Loss: 0.2102\n",
      "Epoch [69/100], Step [88/111], Loss: 0.4260\n",
      "Epoch [69/100], Step [90/111], Loss: 0.2720\n",
      "Epoch [69/100], Step [92/111], Loss: 0.2756\n",
      "Epoch [69/100], Step [94/111], Loss: 0.2237\n",
      "Epoch [69/100], Step [96/111], Loss: 0.1940\n",
      "Epoch [69/100], Step [98/111], Loss: 0.1773\n",
      "Epoch [69/100], Step [100/111], Loss: 0.1676\n",
      "Epoch [69/100], Step [102/111], Loss: 0.1753\n",
      "Epoch [69/100], Step [104/111], Loss: 0.1840\n",
      "Epoch [69/100], Step [106/111], Loss: 0.1848\n",
      "Epoch [69/100], Step [108/111], Loss: 0.2105\n",
      "Epoch [69/100], Step [110/111], Loss: 3.8671\n",
      "Epoch [70/100], Step [2/111], Loss: 3.5801\n",
      "Epoch [70/100], Step [4/111], Loss: 0.2226\n",
      "Epoch [70/100], Step [6/111], Loss: 0.1206\n",
      "Epoch [70/100], Step [8/111], Loss: 0.3190\n",
      "Epoch [70/100], Step [10/111], Loss: 0.2927\n",
      "Epoch [70/100], Step [12/111], Loss: 0.2528\n",
      "Epoch [70/100], Step [14/111], Loss: 0.2211\n",
      "Epoch [70/100], Step [16/111], Loss: 0.2881\n",
      "Epoch [70/100], Step [18/111], Loss: 0.1824\n",
      "Epoch [70/100], Step [20/111], Loss: 0.1664\n",
      "Epoch [70/100], Step [22/111], Loss: 0.2120\n",
      "Epoch [70/100], Step [24/111], Loss: 0.1535\n",
      "Epoch [70/100], Step [26/111], Loss: 0.1470\n",
      "Epoch [70/100], Step [28/111], Loss: 0.2428\n",
      "Epoch [70/100], Step [30/111], Loss: 0.3089\n",
      "Epoch [70/100], Step [32/111], Loss: 0.2085\n",
      "Epoch [70/100], Step [34/111], Loss: 0.2316\n",
      "Epoch [70/100], Step [36/111], Loss: 0.2154\n",
      "Epoch [70/100], Step [38/111], Loss: 0.1968\n",
      "Epoch [70/100], Step [40/111], Loss: 2.6816\n",
      "Epoch [70/100], Step [42/111], Loss: 0.3508\n",
      "Epoch [70/100], Step [44/111], Loss: 0.2452\n",
      "Epoch [70/100], Step [46/111], Loss: 0.1713\n",
      "Epoch [70/100], Step [48/111], Loss: 0.1852\n",
      "Epoch [70/100], Step [50/111], Loss: 0.2406\n",
      "Epoch [70/100], Step [52/111], Loss: 0.1667\n",
      "Epoch [70/100], Step [54/111], Loss: 3.3187\n",
      "Epoch [70/100], Step [56/111], Loss: 0.1955\n",
      "Epoch [70/100], Step [58/111], Loss: 0.2457\n",
      "Epoch [70/100], Step [60/111], Loss: 0.1389\n",
      "Epoch [70/100], Step [62/111], Loss: 0.1683\n",
      "Epoch [70/100], Step [64/111], Loss: 0.2127\n",
      "Epoch [70/100], Step [66/111], Loss: 0.2132\n",
      "Epoch [70/100], Step [68/111], Loss: 0.2990\n",
      "Epoch [70/100], Step [70/111], Loss: 0.1819\n",
      "Epoch [70/100], Step [72/111], Loss: 0.2331\n",
      "Epoch [70/100], Step [74/111], Loss: 0.2333\n",
      "Epoch [70/100], Step [76/111], Loss: 0.1943\n",
      "Epoch [70/100], Step [78/111], Loss: 0.3181\n",
      "Epoch [70/100], Step [80/111], Loss: 0.2117\n",
      "Epoch [70/100], Step [82/111], Loss: 0.2201\n",
      "Epoch [70/100], Step [84/111], Loss: 0.2420\n",
      "Epoch [70/100], Step [86/111], Loss: 2.4333\n",
      "Epoch [70/100], Step [88/111], Loss: 0.2010\n",
      "Epoch [70/100], Step [90/111], Loss: 0.1660\n",
      "Epoch [70/100], Step [92/111], Loss: 0.2086\n",
      "Epoch [70/100], Step [94/111], Loss: 0.1813\n",
      "Epoch [70/100], Step [96/111], Loss: 0.1666\n",
      "Epoch [70/100], Step [98/111], Loss: 0.2277\n",
      "Epoch [70/100], Step [100/111], Loss: 0.1985\n",
      "Epoch [70/100], Step [102/111], Loss: 0.2082\n",
      "Epoch [70/100], Step [104/111], Loss: 0.2727\n",
      "Epoch [70/100], Step [106/111], Loss: 0.2295\n",
      "Epoch [70/100], Step [108/111], Loss: 0.1730\n",
      "Epoch [70/100], Step [110/111], Loss: 0.2466\n",
      "Epoch [71/100], Step [2/111], Loss: 0.2934\n",
      "Epoch [71/100], Step [4/111], Loss: 0.2206\n",
      "Epoch [71/100], Step [6/111], Loss: 0.1558\n",
      "Epoch [71/100], Step [8/111], Loss: 0.2135\n",
      "Epoch [71/100], Step [10/111], Loss: 0.1821\n",
      "Epoch [71/100], Step [12/111], Loss: 0.2298\n",
      "Epoch [71/100], Step [14/111], Loss: 0.2418\n",
      "Epoch [71/100], Step [16/111], Loss: 0.2228\n",
      "Epoch [71/100], Step [18/111], Loss: 0.3419\n",
      "Epoch [71/100], Step [20/111], Loss: 0.2364\n",
      "Epoch [71/100], Step [22/111], Loss: 0.2039\n",
      "Epoch [71/100], Step [24/111], Loss: 0.1767\n",
      "Epoch [71/100], Step [26/111], Loss: 0.2104\n",
      "Epoch [71/100], Step [28/111], Loss: 0.2157\n",
      "Epoch [71/100], Step [30/111], Loss: 0.2517\n",
      "Epoch [71/100], Step [32/111], Loss: 0.1704\n",
      "Epoch [71/100], Step [34/111], Loss: 0.2102\n",
      "Epoch [71/100], Step [36/111], Loss: 4.8354\n",
      "Epoch [71/100], Step [38/111], Loss: 0.1732\n",
      "Epoch [71/100], Step [40/111], Loss: 0.2075\n",
      "Epoch [71/100], Step [42/111], Loss: 0.2201\n",
      "Epoch [71/100], Step [44/111], Loss: 0.1850\n",
      "Epoch [71/100], Step [46/111], Loss: 0.1557\n",
      "Epoch [71/100], Step [48/111], Loss: 0.1836\n",
      "Epoch [71/100], Step [50/111], Loss: 0.1777\n",
      "Epoch [71/100], Step [52/111], Loss: 0.1808\n",
      "Epoch [71/100], Step [54/111], Loss: 0.1609\n",
      "Epoch [71/100], Step [56/111], Loss: 0.2728\n",
      "Epoch [71/100], Step [58/111], Loss: 0.1785\n",
      "Epoch [71/100], Step [60/111], Loss: 0.1671\n",
      "Epoch [71/100], Step [62/111], Loss: 0.1719\n",
      "Epoch [71/100], Step [64/111], Loss: 0.1692\n",
      "Epoch [71/100], Step [66/111], Loss: 0.1862\n",
      "Epoch [71/100], Step [68/111], Loss: 0.1731\n",
      "Epoch [71/100], Step [70/111], Loss: 0.1598\n",
      "Epoch [71/100], Step [72/111], Loss: 0.2044\n",
      "Epoch [71/100], Step [74/111], Loss: 0.1003\n",
      "Epoch [71/100], Step [76/111], Loss: 0.2019\n",
      "Epoch [71/100], Step [78/111], Loss: 0.2509\n",
      "Epoch [71/100], Step [80/111], Loss: 0.2256\n",
      "Epoch [71/100], Step [82/111], Loss: 0.2390\n",
      "Epoch [71/100], Step [84/111], Loss: 0.1636\n",
      "Epoch [71/100], Step [86/111], Loss: 0.1656\n",
      "Epoch [71/100], Step [88/111], Loss: 0.1641\n",
      "Epoch [71/100], Step [90/111], Loss: 0.1865\n",
      "Epoch [71/100], Step [92/111], Loss: 0.1859\n",
      "Epoch [71/100], Step [94/111], Loss: 0.2099\n",
      "Epoch [71/100], Step [96/111], Loss: 0.1845\n",
      "Epoch [71/100], Step [98/111], Loss: 0.2434\n",
      "Epoch [71/100], Step [100/111], Loss: 0.1948\n",
      "Epoch [71/100], Step [102/111], Loss: 0.1952\n",
      "Epoch [71/100], Step [104/111], Loss: 0.6684\n",
      "Epoch [71/100], Step [106/111], Loss: 0.2801\n",
      "Epoch [71/100], Step [108/111], Loss: 0.2282\n",
      "Epoch [71/100], Step [110/111], Loss: 3.2236\n",
      "Epoch [72/100], Step [2/111], Loss: 0.2864\n",
      "Epoch [72/100], Step [4/111], Loss: 0.2202\n",
      "Epoch [72/100], Step [6/111], Loss: 0.2327\n",
      "Epoch [72/100], Step [8/111], Loss: 0.1865\n",
      "Epoch [72/100], Step [10/111], Loss: 0.2477\n",
      "Epoch [72/100], Step [12/111], Loss: 0.1832\n",
      "Epoch [72/100], Step [14/111], Loss: 0.2074\n",
      "Epoch [72/100], Step [16/111], Loss: 0.1750\n",
      "Epoch [72/100], Step [18/111], Loss: 0.2093\n",
      "Epoch [72/100], Step [20/111], Loss: 0.1746\n",
      "Epoch [72/100], Step [22/111], Loss: 0.1928\n",
      "Epoch [72/100], Step [24/111], Loss: 0.2275\n",
      "Epoch [72/100], Step [26/111], Loss: 0.1454\n",
      "Epoch [72/100], Step [28/111], Loss: 0.2159\n",
      "Epoch [72/100], Step [30/111], Loss: 0.1856\n",
      "Epoch [72/100], Step [32/111], Loss: 0.2174\n",
      "Epoch [72/100], Step [34/111], Loss: 0.2130\n",
      "Epoch [72/100], Step [36/111], Loss: 0.2259\n",
      "Epoch [72/100], Step [38/111], Loss: 0.1922\n",
      "Epoch [72/100], Step [40/111], Loss: 0.1601\n",
      "Epoch [72/100], Step [42/111], Loss: 0.1809\n",
      "Epoch [72/100], Step [44/111], Loss: 0.3952\n",
      "Epoch [72/100], Step [46/111], Loss: 0.2536\n",
      "Epoch [72/100], Step [48/111], Loss: 0.1715\n",
      "Epoch [72/100], Step [50/111], Loss: 0.1969\n",
      "Epoch [72/100], Step [52/111], Loss: 0.1692\n",
      "Epoch [72/100], Step [54/111], Loss: 0.1876\n",
      "Epoch [72/100], Step [56/111], Loss: 0.2113\n",
      "Epoch [72/100], Step [58/111], Loss: 0.1869\n",
      "Epoch [72/100], Step [60/111], Loss: 0.2821\n",
      "Epoch [72/100], Step [62/111], Loss: 0.2467\n",
      "Epoch [72/100], Step [64/111], Loss: 0.2466\n",
      "Epoch [72/100], Step [66/111], Loss: 0.2223\n",
      "Epoch [72/100], Step [68/111], Loss: 0.3593\n",
      "Epoch [72/100], Step [70/111], Loss: 0.1757\n",
      "Epoch [72/100], Step [72/111], Loss: 0.1668\n",
      "Epoch [72/100], Step [74/111], Loss: 0.1561\n",
      "Epoch [72/100], Step [76/111], Loss: 0.2282\n",
      "Epoch [72/100], Step [78/111], Loss: 0.2509\n",
      "Epoch [72/100], Step [80/111], Loss: 0.2923\n",
      "Epoch [72/100], Step [82/111], Loss: 0.1859\n",
      "Epoch [72/100], Step [84/111], Loss: 0.1643\n",
      "Epoch [72/100], Step [86/111], Loss: 0.2437\n",
      "Epoch [72/100], Step [88/111], Loss: 0.2353\n",
      "Epoch [72/100], Step [90/111], Loss: 0.2567\n",
      "Epoch [72/100], Step [92/111], Loss: 0.1837\n",
      "Epoch [72/100], Step [94/111], Loss: 0.2519\n",
      "Epoch [72/100], Step [96/111], Loss: 0.2354\n",
      "Epoch [72/100], Step [98/111], Loss: 0.2441\n",
      "Epoch [72/100], Step [100/111], Loss: 0.1794\n",
      "Epoch [72/100], Step [102/111], Loss: 0.2300\n",
      "Epoch [72/100], Step [104/111], Loss: 0.2652\n",
      "Epoch [72/100], Step [106/111], Loss: 0.2786\n",
      "Epoch [72/100], Step [108/111], Loss: 2.7020\n",
      "Epoch [72/100], Step [110/111], Loss: 0.3405\n",
      "Epoch [73/100], Step [2/111], Loss: 0.1983\n",
      "Epoch [73/100], Step [4/111], Loss: 0.3321\n",
      "Epoch [73/100], Step [6/111], Loss: 0.2209\n",
      "Epoch [73/100], Step [8/111], Loss: 0.1912\n",
      "Epoch [73/100], Step [10/111], Loss: 4.0835\n",
      "Epoch [73/100], Step [12/111], Loss: 0.3187\n",
      "Epoch [73/100], Step [14/111], Loss: 0.2496\n",
      "Epoch [73/100], Step [16/111], Loss: 0.3193\n",
      "Epoch [73/100], Step [18/111], Loss: 0.2428\n",
      "Epoch [73/100], Step [20/111], Loss: 0.2428\n",
      "Epoch [73/100], Step [22/111], Loss: 0.2310\n",
      "Epoch [73/100], Step [24/111], Loss: 0.1824\n",
      "Epoch [73/100], Step [26/111], Loss: 0.1705\n",
      "Epoch [73/100], Step [28/111], Loss: 0.2505\n",
      "Epoch [73/100], Step [30/111], Loss: 0.1712\n",
      "Epoch [73/100], Step [32/111], Loss: 0.2742\n",
      "Epoch [73/100], Step [34/111], Loss: 0.2258\n",
      "Epoch [73/100], Step [36/111], Loss: 0.2029\n",
      "Epoch [73/100], Step [38/111], Loss: 0.2315\n",
      "Epoch [73/100], Step [40/111], Loss: 2.1908\n",
      "Epoch [73/100], Step [42/111], Loss: 0.2429\n",
      "Epoch [73/100], Step [44/111], Loss: 0.2547\n",
      "Epoch [73/100], Step [46/111], Loss: 0.1911\n",
      "Epoch [73/100], Step [48/111], Loss: 0.2123\n",
      "Epoch [73/100], Step [50/111], Loss: 0.2108\n",
      "Epoch [73/100], Step [52/111], Loss: 0.2986\n",
      "Epoch [73/100], Step [54/111], Loss: 0.2594\n",
      "Epoch [73/100], Step [56/111], Loss: 0.2086\n",
      "Epoch [73/100], Step [58/111], Loss: 0.2218\n",
      "Epoch [73/100], Step [60/111], Loss: 0.2617\n",
      "Epoch [73/100], Step [62/111], Loss: 0.5426\n",
      "Epoch [73/100], Step [64/111], Loss: 0.3005\n",
      "Epoch [73/100], Step [66/111], Loss: 0.2745\n",
      "Epoch [73/100], Step [68/111], Loss: 0.2780\n",
      "Epoch [73/100], Step [70/111], Loss: 0.2190\n",
      "Epoch [73/100], Step [72/111], Loss: 0.1697\n",
      "Epoch [73/100], Step [74/111], Loss: 0.1713\n",
      "Epoch [73/100], Step [76/111], Loss: 0.1945\n",
      "Epoch [73/100], Step [78/111], Loss: 0.2054\n",
      "Epoch [73/100], Step [80/111], Loss: 0.2147\n",
      "Epoch [73/100], Step [82/111], Loss: 0.6903\n",
      "Epoch [73/100], Step [84/111], Loss: 0.1744\n",
      "Epoch [73/100], Step [86/111], Loss: 0.1809\n",
      "Epoch [73/100], Step [88/111], Loss: 0.2661\n",
      "Epoch [73/100], Step [90/111], Loss: 0.1392\n",
      "Epoch [73/100], Step [92/111], Loss: 0.1998\n",
      "Epoch [73/100], Step [94/111], Loss: 0.2177\n",
      "Epoch [73/100], Step [96/111], Loss: 0.2294\n",
      "Epoch [73/100], Step [98/111], Loss: 0.2472\n",
      "Epoch [73/100], Step [100/111], Loss: 0.2381\n",
      "Epoch [73/100], Step [102/111], Loss: 0.2182\n",
      "Epoch [73/100], Step [104/111], Loss: 0.1981\n",
      "Epoch [73/100], Step [106/111], Loss: 0.1480\n",
      "Epoch [73/100], Step [108/111], Loss: 2.9819\n",
      "Epoch [73/100], Step [110/111], Loss: 0.1316\n",
      "Epoch [74/100], Step [2/111], Loss: 0.2921\n",
      "Epoch [74/100], Step [4/111], Loss: 0.1733\n",
      "Epoch [74/100], Step [6/111], Loss: 0.2209\n",
      "Epoch [74/100], Step [8/111], Loss: 0.1714\n",
      "Epoch [74/100], Step [10/111], Loss: 0.2388\n",
      "Epoch [74/100], Step [12/111], Loss: 0.1410\n",
      "Epoch [74/100], Step [14/111], Loss: 0.6540\n",
      "Epoch [74/100], Step [16/111], Loss: 0.1673\n",
      "Epoch [74/100], Step [18/111], Loss: 2.2195\n",
      "Epoch [74/100], Step [20/111], Loss: 0.2179\n",
      "Epoch [74/100], Step [22/111], Loss: 0.2292\n",
      "Epoch [74/100], Step [24/111], Loss: 0.2086\n",
      "Epoch [74/100], Step [26/111], Loss: 0.1643\n",
      "Epoch [74/100], Step [28/111], Loss: 0.3042\n",
      "Epoch [74/100], Step [30/111], Loss: 0.2642\n",
      "Epoch [74/100], Step [32/111], Loss: 0.2113\n",
      "Epoch [74/100], Step [34/111], Loss: 0.2372\n",
      "Epoch [74/100], Step [36/111], Loss: 0.1656\n",
      "Epoch [74/100], Step [38/111], Loss: 0.2251\n",
      "Epoch [74/100], Step [40/111], Loss: 0.1714\n",
      "Epoch [74/100], Step [42/111], Loss: 0.2679\n",
      "Epoch [74/100], Step [44/111], Loss: 0.2020\n",
      "Epoch [74/100], Step [46/111], Loss: 0.1790\n",
      "Epoch [74/100], Step [48/111], Loss: 0.2888\n",
      "Epoch [74/100], Step [50/111], Loss: 0.1535\n",
      "Epoch [74/100], Step [52/111], Loss: 0.2257\n",
      "Epoch [74/100], Step [54/111], Loss: 0.2044\n",
      "Epoch [74/100], Step [56/111], Loss: 0.1794\n",
      "Epoch [74/100], Step [58/111], Loss: 0.1926\n",
      "Epoch [74/100], Step [60/111], Loss: 0.2385\n",
      "Epoch [74/100], Step [62/111], Loss: 0.2090\n",
      "Epoch [74/100], Step [64/111], Loss: 0.2320\n",
      "Epoch [74/100], Step [66/111], Loss: 0.1554\n",
      "Epoch [74/100], Step [68/111], Loss: 0.1903\n",
      "Epoch [74/100], Step [70/111], Loss: 0.1455\n",
      "Epoch [74/100], Step [72/111], Loss: 0.1484\n",
      "Epoch [74/100], Step [74/111], Loss: 0.1964\n",
      "Epoch [74/100], Step [76/111], Loss: 0.1925\n",
      "Epoch [74/100], Step [78/111], Loss: 0.1825\n",
      "Epoch [74/100], Step [80/111], Loss: 0.1983\n",
      "Epoch [74/100], Step [82/111], Loss: 0.1722\n",
      "Epoch [74/100], Step [84/111], Loss: 0.2157\n",
      "Epoch [74/100], Step [86/111], Loss: 0.1974\n",
      "Epoch [74/100], Step [88/111], Loss: 0.2943\n",
      "Epoch [74/100], Step [90/111], Loss: 0.2829\n",
      "Epoch [74/100], Step [92/111], Loss: 0.1649\n",
      "Epoch [74/100], Step [94/111], Loss: 0.1983\n",
      "Epoch [74/100], Step [96/111], Loss: 0.1459\n",
      "Epoch [74/100], Step [98/111], Loss: 1.9099\n",
      "Epoch [74/100], Step [100/111], Loss: 0.1860\n",
      "Epoch [74/100], Step [102/111], Loss: 0.2455\n",
      "Epoch [74/100], Step [104/111], Loss: 0.2993\n",
      "Epoch [74/100], Step [106/111], Loss: 0.1234\n",
      "Epoch [74/100], Step [108/111], Loss: 0.2081\n",
      "Epoch [74/100], Step [110/111], Loss: 0.2117\n",
      "Epoch [75/100], Step [2/111], Loss: 0.2829\n",
      "Epoch [75/100], Step [4/111], Loss: 0.1855\n",
      "Epoch [75/100], Step [6/111], Loss: 0.2416\n",
      "Epoch [75/100], Step [8/111], Loss: 0.2360\n",
      "Epoch [75/100], Step [10/111], Loss: 0.2365\n",
      "Epoch [75/100], Step [12/111], Loss: 0.2094\n",
      "Epoch [75/100], Step [14/111], Loss: 0.1286\n",
      "Epoch [75/100], Step [16/111], Loss: 0.2525\n",
      "Epoch [75/100], Step [18/111], Loss: 0.2656\n",
      "Epoch [75/100], Step [20/111], Loss: 0.2941\n",
      "Epoch [75/100], Step [22/111], Loss: 0.2861\n",
      "Epoch [75/100], Step [24/111], Loss: 0.2765\n",
      "Epoch [75/100], Step [26/111], Loss: 0.2284\n",
      "Epoch [75/100], Step [28/111], Loss: 0.2205\n",
      "Epoch [75/100], Step [30/111], Loss: 0.2402\n",
      "Epoch [75/100], Step [32/111], Loss: 0.2439\n",
      "Epoch [75/100], Step [34/111], Loss: 0.1329\n",
      "Epoch [75/100], Step [36/111], Loss: 0.1812\n",
      "Epoch [75/100], Step [38/111], Loss: 0.2279\n",
      "Epoch [75/100], Step [40/111], Loss: 0.2083\n",
      "Epoch [75/100], Step [42/111], Loss: 0.4584\n",
      "Epoch [75/100], Step [44/111], Loss: 0.1513\n",
      "Epoch [75/100], Step [46/111], Loss: 0.1850\n",
      "Epoch [75/100], Step [48/111], Loss: 0.1805\n",
      "Epoch [75/100], Step [50/111], Loss: 0.1985\n",
      "Epoch [75/100], Step [52/111], Loss: 0.1525\n",
      "Epoch [75/100], Step [54/111], Loss: 0.2190\n",
      "Epoch [75/100], Step [56/111], Loss: 0.2316\n",
      "Epoch [75/100], Step [58/111], Loss: 0.2159\n",
      "Epoch [75/100], Step [60/111], Loss: 0.2518\n",
      "Epoch [75/100], Step [62/111], Loss: 0.2086\n",
      "Epoch [75/100], Step [64/111], Loss: 0.2027\n",
      "Epoch [75/100], Step [66/111], Loss: 0.2176\n",
      "Epoch [75/100], Step [68/111], Loss: 4.3470\n",
      "Epoch [75/100], Step [70/111], Loss: 0.2568\n",
      "Epoch [75/100], Step [72/111], Loss: 0.1951\n",
      "Epoch [75/100], Step [74/111], Loss: 0.1921\n",
      "Epoch [75/100], Step [76/111], Loss: 0.2425\n",
      "Epoch [75/100], Step [78/111], Loss: 0.2200\n",
      "Epoch [75/100], Step [80/111], Loss: 0.1728\n",
      "Epoch [75/100], Step [82/111], Loss: 0.2517\n",
      "Epoch [75/100], Step [84/111], Loss: 0.1503\n",
      "Epoch [75/100], Step [86/111], Loss: 0.1656\n",
      "Epoch [75/100], Step [88/111], Loss: 0.2777\n",
      "Epoch [75/100], Step [90/111], Loss: 0.1795\n",
      "Epoch [75/100], Step [92/111], Loss: 2.9798\n",
      "Epoch [75/100], Step [94/111], Loss: 0.2442\n",
      "Epoch [75/100], Step [96/111], Loss: 0.2158\n",
      "Epoch [75/100], Step [98/111], Loss: 0.1862\n",
      "Epoch [75/100], Step [100/111], Loss: 0.1646\n",
      "Epoch [75/100], Step [102/111], Loss: 0.1630\n",
      "Epoch [75/100], Step [104/111], Loss: 0.1701\n",
      "Epoch [75/100], Step [106/111], Loss: 0.1619\n",
      "Epoch [75/100], Step [108/111], Loss: 0.1425\n",
      "Epoch [75/100], Step [110/111], Loss: 0.1234\n",
      "Epoch [76/100], Step [2/111], Loss: 0.1428\n",
      "Epoch [76/100], Step [4/111], Loss: 0.1575\n",
      "Epoch [76/100], Step [6/111], Loss: 3.4820\n",
      "Epoch [76/100], Step [8/111], Loss: 0.2187\n",
      "Epoch [76/100], Step [10/111], Loss: 0.1708\n",
      "Epoch [76/100], Step [12/111], Loss: 0.1601\n",
      "Epoch [76/100], Step [14/111], Loss: 0.1358\n",
      "Epoch [76/100], Step [16/111], Loss: 0.2086\n",
      "Epoch [76/100], Step [18/111], Loss: 0.2552\n",
      "Epoch [76/100], Step [20/111], Loss: 0.1514\n",
      "Epoch [76/100], Step [22/111], Loss: 0.2969\n",
      "Epoch [76/100], Step [24/111], Loss: 0.2001\n",
      "Epoch [76/100], Step [26/111], Loss: 0.2100\n",
      "Epoch [76/100], Step [28/111], Loss: 0.1574\n",
      "Epoch [76/100], Step [30/111], Loss: 0.2530\n",
      "Epoch [76/100], Step [32/111], Loss: 0.2581\n",
      "Epoch [76/100], Step [34/111], Loss: 0.1709\n",
      "Epoch [76/100], Step [36/111], Loss: 0.2182\n",
      "Epoch [76/100], Step [38/111], Loss: 0.2033\n",
      "Epoch [76/100], Step [40/111], Loss: 0.1382\n",
      "Epoch [76/100], Step [42/111], Loss: 0.1882\n",
      "Epoch [76/100], Step [44/111], Loss: 0.2349\n",
      "Epoch [76/100], Step [46/111], Loss: 0.1666\n",
      "Epoch [76/100], Step [48/111], Loss: 0.1787\n",
      "Epoch [76/100], Step [50/111], Loss: 0.1641\n",
      "Epoch [76/100], Step [52/111], Loss: 0.1807\n",
      "Epoch [76/100], Step [54/111], Loss: 0.1972\n",
      "Epoch [76/100], Step [56/111], Loss: 0.1297\n",
      "Epoch [76/100], Step [58/111], Loss: 0.1714\n",
      "Epoch [76/100], Step [60/111], Loss: 0.1786\n",
      "Epoch [76/100], Step [62/111], Loss: 0.2069\n",
      "Epoch [76/100], Step [64/111], Loss: 0.1991\n",
      "Epoch [76/100], Step [66/111], Loss: 0.2232\n",
      "Epoch [76/100], Step [68/111], Loss: 0.2051\n",
      "Epoch [76/100], Step [70/111], Loss: 0.1722\n",
      "Epoch [76/100], Step [72/111], Loss: 0.1801\n",
      "Epoch [76/100], Step [74/111], Loss: 0.1616\n",
      "Epoch [76/100], Step [76/111], Loss: 0.1720\n",
      "Epoch [76/100], Step [78/111], Loss: 3.4651\n",
      "Epoch [76/100], Step [80/111], Loss: 0.2194\n",
      "Epoch [76/100], Step [82/111], Loss: 0.2415\n",
      "Epoch [76/100], Step [84/111], Loss: 0.2712\n",
      "Epoch [76/100], Step [86/111], Loss: 0.3336\n",
      "Epoch [76/100], Step [88/111], Loss: 0.2108\n",
      "Epoch [76/100], Step [90/111], Loss: 0.2065\n",
      "Epoch [76/100], Step [92/111], Loss: 0.2187\n",
      "Epoch [76/100], Step [94/111], Loss: 0.2782\n",
      "Epoch [76/100], Step [96/111], Loss: 0.2660\n",
      "Epoch [76/100], Step [98/111], Loss: 0.2665\n",
      "Epoch [76/100], Step [100/111], Loss: 0.2924\n",
      "Epoch [76/100], Step [102/111], Loss: 0.2043\n",
      "Epoch [76/100], Step [104/111], Loss: 0.2171\n",
      "Epoch [76/100], Step [106/111], Loss: 0.1892\n",
      "Epoch [76/100], Step [108/111], Loss: 0.1605\n",
      "Epoch [76/100], Step [110/111], Loss: 0.2343\n",
      "Epoch [77/100], Step [2/111], Loss: 0.2002\n",
      "Epoch [77/100], Step [4/111], Loss: 0.2557\n",
      "Epoch [77/100], Step [6/111], Loss: 0.2984\n",
      "Epoch [77/100], Step [8/111], Loss: 0.2590\n",
      "Epoch [77/100], Step [10/111], Loss: 0.3228\n",
      "Epoch [77/100], Step [12/111], Loss: 0.3220\n",
      "Epoch [77/100], Step [14/111], Loss: 0.3348\n",
      "Epoch [77/100], Step [16/111], Loss: 0.3345\n",
      "Epoch [77/100], Step [18/111], Loss: 0.2412\n",
      "Epoch [77/100], Step [20/111], Loss: 0.2798\n",
      "Epoch [77/100], Step [22/111], Loss: 0.3553\n",
      "Epoch [77/100], Step [24/111], Loss: 0.2472\n",
      "Epoch [77/100], Step [26/111], Loss: 0.2743\n",
      "Epoch [77/100], Step [28/111], Loss: 0.2695\n",
      "Epoch [77/100], Step [30/111], Loss: 0.2725\n",
      "Epoch [77/100], Step [32/111], Loss: 0.2659\n",
      "Epoch [77/100], Step [34/111], Loss: 0.3690\n",
      "Epoch [77/100], Step [36/111], Loss: 0.3394\n",
      "Epoch [77/100], Step [38/111], Loss: 0.2496\n",
      "Epoch [77/100], Step [40/111], Loss: 0.2698\n",
      "Epoch [77/100], Step [42/111], Loss: 0.4392\n",
      "Epoch [77/100], Step [44/111], Loss: 0.2501\n",
      "Epoch [77/100], Step [46/111], Loss: 0.2505\n",
      "Epoch [77/100], Step [48/111], Loss: 0.3338\n",
      "Epoch [77/100], Step [50/111], Loss: 0.2953\n",
      "Epoch [77/100], Step [52/111], Loss: 0.3241\n",
      "Epoch [77/100], Step [54/111], Loss: 0.2123\n",
      "Epoch [77/100], Step [56/111], Loss: 0.2714\n",
      "Epoch [77/100], Step [58/111], Loss: 0.2968\n",
      "Epoch [77/100], Step [60/111], Loss: 0.2086\n",
      "Epoch [77/100], Step [62/111], Loss: 0.2559\n",
      "Epoch [77/100], Step [64/111], Loss: 0.2396\n",
      "Epoch [77/100], Step [66/111], Loss: 0.2984\n",
      "Epoch [77/100], Step [68/111], Loss: 0.3345\n",
      "Epoch [77/100], Step [70/111], Loss: 0.2316\n",
      "Epoch [77/100], Step [72/111], Loss: 0.3326\n",
      "Epoch [77/100], Step [74/111], Loss: 0.2252\n",
      "Epoch [77/100], Step [76/111], Loss: 0.2979\n",
      "Epoch [77/100], Step [78/111], Loss: 0.2519\n",
      "Epoch [77/100], Step [80/111], Loss: 0.2818\n",
      "Epoch [77/100], Step [82/111], Loss: 0.3468\n",
      "Epoch [77/100], Step [84/111], Loss: 0.2978\n",
      "Epoch [77/100], Step [86/111], Loss: 0.3648\n",
      "Epoch [77/100], Step [88/111], Loss: 0.2589\n",
      "Epoch [77/100], Step [90/111], Loss: 0.3186\n",
      "Epoch [77/100], Step [92/111], Loss: 0.9525\n",
      "Epoch [77/100], Step [94/111], Loss: 0.2984\n",
      "Epoch [77/100], Step [96/111], Loss: 0.3701\n",
      "Epoch [77/100], Step [98/111], Loss: 0.3603\n",
      "Epoch [77/100], Step [100/111], Loss: 0.3635\n",
      "Epoch [77/100], Step [102/111], Loss: 0.3300\n",
      "Epoch [77/100], Step [104/111], Loss: 0.3605\n",
      "Epoch [77/100], Step [106/111], Loss: 0.4628\n",
      "Epoch [77/100], Step [108/111], Loss: 0.4928\n",
      "Epoch [77/100], Step [110/111], Loss: 0.4131\n",
      "Epoch [78/100], Step [2/111], Loss: 0.2837\n",
      "Epoch [78/100], Step [4/111], Loss: 0.4660\n",
      "Epoch [78/100], Step [6/111], Loss: 0.3882\n",
      "Epoch [78/100], Step [8/111], Loss: 0.6308\n",
      "Epoch [78/100], Step [10/111], Loss: 0.3760\n",
      "Epoch [78/100], Step [12/111], Loss: 0.3966\n",
      "Epoch [78/100], Step [14/111], Loss: 0.4575\n",
      "Epoch [78/100], Step [16/111], Loss: 0.4910\n",
      "Epoch [78/100], Step [18/111], Loss: 2.1651\n",
      "Epoch [78/100], Step [20/111], Loss: 0.3690\n",
      "Epoch [78/100], Step [22/111], Loss: 0.7004\n",
      "Epoch [78/100], Step [24/111], Loss: 0.6115\n",
      "Epoch [78/100], Step [26/111], Loss: 0.4245\n",
      "Epoch [78/100], Step [28/111], Loss: 0.5484\n",
      "Epoch [78/100], Step [30/111], Loss: 0.4944\n",
      "Epoch [78/100], Step [32/111], Loss: 0.7327\n",
      "Epoch [78/100], Step [34/111], Loss: 0.4864\n",
      "Epoch [78/100], Step [36/111], Loss: 0.3814\n",
      "Epoch [78/100], Step [38/111], Loss: 0.4286\n",
      "Epoch [78/100], Step [40/111], Loss: 0.4338\n",
      "Epoch [78/100], Step [42/111], Loss: 0.3750\n",
      "Epoch [78/100], Step [44/111], Loss: 0.6748\n",
      "Epoch [78/100], Step [46/111], Loss: 0.5978\n",
      "Epoch [78/100], Step [48/111], Loss: 0.3990\n",
      "Epoch [78/100], Step [50/111], Loss: 0.4176\n",
      "Epoch [78/100], Step [52/111], Loss: 0.3943\n",
      "Epoch [78/100], Step [54/111], Loss: 0.5510\n",
      "Epoch [78/100], Step [56/111], Loss: 0.3944\n",
      "Epoch [78/100], Step [58/111], Loss: 0.6439\n",
      "Epoch [78/100], Step [60/111], Loss: 0.5984\n",
      "Epoch [78/100], Step [62/111], Loss: 0.3213\n",
      "Epoch [78/100], Step [64/111], Loss: 0.6661\n",
      "Epoch [78/100], Step [66/111], Loss: 0.5139\n",
      "Epoch [78/100], Step [68/111], Loss: 0.5440\n",
      "Epoch [78/100], Step [70/111], Loss: 0.4797\n",
      "Epoch [78/100], Step [72/111], Loss: 0.4361\n",
      "Epoch [78/100], Step [74/111], Loss: 0.3586\n",
      "Epoch [78/100], Step [76/111], Loss: 0.3730\n",
      "Epoch [78/100], Step [78/111], Loss: 0.3495\n",
      "Epoch [78/100], Step [80/111], Loss: 0.2874\n",
      "Epoch [78/100], Step [82/111], Loss: 0.3912\n",
      "Epoch [78/100], Step [84/111], Loss: 0.3577\n",
      "Epoch [78/100], Step [86/111], Loss: 0.3436\n",
      "Epoch [78/100], Step [88/111], Loss: 0.3740\n",
      "Epoch [78/100], Step [90/111], Loss: 0.6113\n",
      "Epoch [78/100], Step [92/111], Loss: 0.4302\n",
      "Epoch [78/100], Step [94/111], Loss: 0.3705\n",
      "Epoch [78/100], Step [96/111], Loss: 0.3002\n",
      "Epoch [78/100], Step [98/111], Loss: 0.3250\n",
      "Epoch [78/100], Step [100/111], Loss: 0.3147\n",
      "Epoch [78/100], Step [102/111], Loss: 0.3930\n",
      "Epoch [78/100], Step [104/111], Loss: 0.3457\n",
      "Epoch [78/100], Step [106/111], Loss: 0.4175\n",
      "Epoch [78/100], Step [108/111], Loss: 0.5915\n",
      "Epoch [78/100], Step [110/111], Loss: 0.5254\n",
      "Epoch [79/100], Step [2/111], Loss: 0.4235\n",
      "Epoch [79/100], Step [4/111], Loss: 0.4711\n",
      "Epoch [79/100], Step [6/111], Loss: 0.4486\n",
      "Epoch [79/100], Step [8/111], Loss: 0.4758\n",
      "Epoch [79/100], Step [10/111], Loss: 0.3546\n",
      "Epoch [79/100], Step [12/111], Loss: 0.3159\n",
      "Epoch [79/100], Step [14/111], Loss: 0.4599\n",
      "Epoch [79/100], Step [16/111], Loss: 0.4466\n",
      "Epoch [79/100], Step [18/111], Loss: 0.3617\n",
      "Epoch [79/100], Step [20/111], Loss: 0.4018\n",
      "Epoch [79/100], Step [22/111], Loss: 0.3711\n",
      "Epoch [79/100], Step [24/111], Loss: 0.3119\n",
      "Epoch [79/100], Step [26/111], Loss: 0.4602\n",
      "Epoch [79/100], Step [28/111], Loss: 0.3682\n",
      "Epoch [79/100], Step [30/111], Loss: 0.3268\n",
      "Epoch [79/100], Step [32/111], Loss: 2.8743\n",
      "Epoch [79/100], Step [34/111], Loss: 0.4253\n",
      "Epoch [79/100], Step [36/111], Loss: 0.5748\n",
      "Epoch [79/100], Step [38/111], Loss: 0.3550\n",
      "Epoch [79/100], Step [40/111], Loss: 0.3739\n",
      "Epoch [79/100], Step [42/111], Loss: 0.3601\n",
      "Epoch [79/100], Step [44/111], Loss: 0.3883\n",
      "Epoch [79/100], Step [46/111], Loss: 0.3850\n",
      "Epoch [79/100], Step [48/111], Loss: 0.4121\n",
      "Epoch [79/100], Step [50/111], Loss: 0.2891\n",
      "Epoch [79/100], Step [52/111], Loss: 0.2857\n",
      "Epoch [79/100], Step [54/111], Loss: 0.3545\n",
      "Epoch [79/100], Step [56/111], Loss: 0.2894\n",
      "Epoch [79/100], Step [58/111], Loss: 0.4369\n",
      "Epoch [79/100], Step [60/111], Loss: 0.3805\n",
      "Epoch [79/100], Step [62/111], Loss: 0.4191\n",
      "Epoch [79/100], Step [64/111], Loss: 0.2184\n",
      "Epoch [79/100], Step [66/111], Loss: 0.3736\n",
      "Epoch [79/100], Step [68/111], Loss: 0.3585\n",
      "Epoch [79/100], Step [70/111], Loss: 0.2593\n",
      "Epoch [79/100], Step [72/111], Loss: 0.3167\n",
      "Epoch [79/100], Step [74/111], Loss: 0.2637\n",
      "Epoch [79/100], Step [76/111], Loss: 0.3715\n",
      "Epoch [79/100], Step [78/111], Loss: 0.3007\n",
      "Epoch [79/100], Step [80/111], Loss: 0.3033\n",
      "Epoch [79/100], Step [82/111], Loss: 0.2758\n",
      "Epoch [79/100], Step [84/111], Loss: 0.3479\n",
      "Epoch [79/100], Step [86/111], Loss: 0.2532\n",
      "Epoch [79/100], Step [88/111], Loss: 0.2515\n",
      "Epoch [79/100], Step [90/111], Loss: 0.2958\n",
      "Epoch [79/100], Step [92/111], Loss: 0.3499\n",
      "Epoch [79/100], Step [94/111], Loss: 0.3486\n",
      "Epoch [79/100], Step [96/111], Loss: 0.3772\n",
      "Epoch [79/100], Step [98/111], Loss: 0.2724\n",
      "Epoch [79/100], Step [100/111], Loss: 0.3888\n",
      "Epoch [79/100], Step [102/111], Loss: 0.2521\n",
      "Epoch [79/100], Step [104/111], Loss: 0.2824\n",
      "Epoch [79/100], Step [106/111], Loss: 0.2536\n",
      "Epoch [79/100], Step [108/111], Loss: 0.2682\n",
      "Epoch [79/100], Step [110/111], Loss: 0.1793\n",
      "Epoch [80/100], Step [2/111], Loss: 0.2429\n",
      "Epoch [80/100], Step [4/111], Loss: 0.2265\n",
      "Epoch [80/100], Step [6/111], Loss: 0.2144\n",
      "Epoch [80/100], Step [8/111], Loss: 0.3783\n",
      "Epoch [80/100], Step [10/111], Loss: 0.2398\n",
      "Epoch [80/100], Step [12/111], Loss: 0.2562\n",
      "Epoch [80/100], Step [14/111], Loss: 0.2405\n",
      "Epoch [80/100], Step [16/111], Loss: 0.2750\n",
      "Epoch [80/100], Step [18/111], Loss: 0.2358\n",
      "Epoch [80/100], Step [20/111], Loss: 0.2745\n",
      "Epoch [80/100], Step [22/111], Loss: 0.2365\n",
      "Epoch [80/100], Step [24/111], Loss: 0.2610\n",
      "Epoch [80/100], Step [26/111], Loss: 0.2138\n",
      "Epoch [80/100], Step [28/111], Loss: 0.2208\n",
      "Epoch [80/100], Step [30/111], Loss: 0.2034\n",
      "Epoch [80/100], Step [32/111], Loss: 0.2785\n",
      "Epoch [80/100], Step [34/111], Loss: 1.8211\n",
      "Epoch [80/100], Step [36/111], Loss: 0.2672\n",
      "Epoch [80/100], Step [38/111], Loss: 0.2352\n",
      "Epoch [80/100], Step [40/111], Loss: 0.1822\n",
      "Epoch [80/100], Step [42/111], Loss: 0.2322\n",
      "Epoch [80/100], Step [44/111], Loss: 0.2247\n",
      "Epoch [80/100], Step [46/111], Loss: 0.2271\n",
      "Epoch [80/100], Step [48/111], Loss: 0.2400\n",
      "Epoch [80/100], Step [50/111], Loss: 0.2415\n",
      "Epoch [80/100], Step [52/111], Loss: 0.4113\n",
      "Epoch [80/100], Step [54/111], Loss: 0.2111\n",
      "Epoch [80/100], Step [56/111], Loss: 0.2136\n",
      "Epoch [80/100], Step [58/111], Loss: 3.9584\n",
      "Epoch [80/100], Step [60/111], Loss: 0.2184\n",
      "Epoch [80/100], Step [62/111], Loss: 0.1939\n",
      "Epoch [80/100], Step [64/111], Loss: 0.2064\n",
      "Epoch [80/100], Step [66/111], Loss: 0.1935\n",
      "Epoch [80/100], Step [68/111], Loss: 0.2949\n",
      "Epoch [80/100], Step [70/111], Loss: 0.2612\n",
      "Epoch [80/100], Step [72/111], Loss: 0.2660\n",
      "Epoch [80/100], Step [74/111], Loss: 0.2132\n",
      "Epoch [80/100], Step [76/111], Loss: 0.1533\n",
      "Epoch [80/100], Step [78/111], Loss: 0.1492\n",
      "Epoch [80/100], Step [80/111], Loss: 3.1979\n",
      "Epoch [80/100], Step [82/111], Loss: 0.1990\n",
      "Epoch [80/100], Step [84/111], Loss: 0.2210\n",
      "Epoch [80/100], Step [86/111], Loss: 0.2496\n",
      "Epoch [80/100], Step [88/111], Loss: 0.2033\n",
      "Epoch [80/100], Step [90/111], Loss: 0.2690\n",
      "Epoch [80/100], Step [92/111], Loss: 0.1736\n",
      "Epoch [80/100], Step [94/111], Loss: 0.1874\n",
      "Epoch [80/100], Step [96/111], Loss: 0.2019\n",
      "Epoch [80/100], Step [98/111], Loss: 0.2613\n",
      "Epoch [80/100], Step [100/111], Loss: 0.1896\n",
      "Epoch [80/100], Step [102/111], Loss: 0.2194\n",
      "Epoch [80/100], Step [104/111], Loss: 0.1878\n",
      "Epoch [80/100], Step [106/111], Loss: 0.2737\n",
      "Epoch [80/100], Step [108/111], Loss: 0.3089\n",
      "Epoch [80/100], Step [110/111], Loss: 0.2355\n",
      "Epoch [81/100], Step [2/111], Loss: 0.2776\n",
      "Epoch [81/100], Step [4/111], Loss: 0.4177\n",
      "Epoch [81/100], Step [6/111], Loss: 0.1756\n",
      "Epoch [81/100], Step [8/111], Loss: 0.2574\n",
      "Epoch [81/100], Step [10/111], Loss: 0.2951\n",
      "Epoch [81/100], Step [12/111], Loss: 0.2553\n",
      "Epoch [81/100], Step [14/111], Loss: 0.2385\n",
      "Epoch [81/100], Step [16/111], Loss: 0.2143\n",
      "Epoch [81/100], Step [18/111], Loss: 0.3273\n",
      "Epoch [81/100], Step [20/111], Loss: 0.2426\n",
      "Epoch [81/100], Step [22/111], Loss: 0.2005\n",
      "Epoch [81/100], Step [24/111], Loss: 0.2999\n",
      "Epoch [81/100], Step [26/111], Loss: 3.1341\n",
      "Epoch [81/100], Step [28/111], Loss: 0.1944\n",
      "Epoch [81/100], Step [30/111], Loss: 0.1827\n",
      "Epoch [81/100], Step [32/111], Loss: 0.1838\n",
      "Epoch [81/100], Step [34/111], Loss: 0.2291\n",
      "Epoch [81/100], Step [36/111], Loss: 0.2161\n",
      "Epoch [81/100], Step [38/111], Loss: 0.2339\n",
      "Epoch [81/100], Step [40/111], Loss: 0.2377\n",
      "Epoch [81/100], Step [42/111], Loss: 0.2296\n",
      "Epoch [81/100], Step [44/111], Loss: 0.2022\n",
      "Epoch [81/100], Step [46/111], Loss: 0.2663\n",
      "Epoch [81/100], Step [48/111], Loss: 0.2004\n",
      "Epoch [81/100], Step [50/111], Loss: 0.2320\n",
      "Epoch [81/100], Step [52/111], Loss: 0.1697\n",
      "Epoch [81/100], Step [54/111], Loss: 0.1262\n",
      "Epoch [81/100], Step [56/111], Loss: 0.1868\n",
      "Epoch [81/100], Step [58/111], Loss: 0.1503\n",
      "Epoch [81/100], Step [60/111], Loss: 0.1658\n",
      "Epoch [81/100], Step [62/111], Loss: 0.1672\n",
      "Epoch [81/100], Step [64/111], Loss: 0.2373\n",
      "Epoch [81/100], Step [66/111], Loss: 0.2090\n",
      "Epoch [81/100], Step [68/111], Loss: 0.1610\n",
      "Epoch [81/100], Step [70/111], Loss: 0.2122\n",
      "Epoch [81/100], Step [72/111], Loss: 0.1420\n",
      "Epoch [81/100], Step [74/111], Loss: 0.2100\n",
      "Epoch [81/100], Step [76/111], Loss: 0.1751\n",
      "Epoch [81/100], Step [78/111], Loss: 0.2372\n",
      "Epoch [81/100], Step [80/111], Loss: 0.1651\n",
      "Epoch [81/100], Step [82/111], Loss: 0.2083\n",
      "Epoch [81/100], Step [84/111], Loss: 0.2004\n",
      "Epoch [81/100], Step [86/111], Loss: 0.2175\n",
      "Epoch [81/100], Step [88/111], Loss: 0.2027\n",
      "Epoch [81/100], Step [90/111], Loss: 0.1589\n",
      "Epoch [81/100], Step [92/111], Loss: 0.2011\n",
      "Epoch [81/100], Step [94/111], Loss: 0.1725\n",
      "Epoch [81/100], Step [96/111], Loss: 0.1766\n",
      "Epoch [81/100], Step [98/111], Loss: 0.2375\n",
      "Epoch [81/100], Step [100/111], Loss: 0.1706\n",
      "Epoch [81/100], Step [102/111], Loss: 0.2123\n",
      "Epoch [81/100], Step [104/111], Loss: 0.1745\n",
      "Epoch [81/100], Step [106/111], Loss: 0.1220\n",
      "Epoch [81/100], Step [108/111], Loss: 0.2560\n",
      "Epoch [81/100], Step [110/111], Loss: 0.1286\n",
      "Epoch [82/100], Step [2/111], Loss: 0.1566\n",
      "Epoch [82/100], Step [4/111], Loss: 0.2503\n",
      "Epoch [82/100], Step [6/111], Loss: 0.1948\n",
      "Epoch [82/100], Step [8/111], Loss: 1.9177\n",
      "Epoch [82/100], Step [10/111], Loss: 0.1880\n",
      "Epoch [82/100], Step [12/111], Loss: 0.1797\n",
      "Epoch [82/100], Step [14/111], Loss: 0.2251\n",
      "Epoch [82/100], Step [16/111], Loss: 0.1678\n",
      "Epoch [82/100], Step [18/111], Loss: 0.1567\n",
      "Epoch [82/100], Step [20/111], Loss: 0.1395\n",
      "Epoch [82/100], Step [22/111], Loss: 0.1611\n",
      "Epoch [82/100], Step [24/111], Loss: 0.1819\n",
      "Epoch [82/100], Step [26/111], Loss: 0.1953\n",
      "Epoch [82/100], Step [28/111], Loss: 0.1502\n",
      "Epoch [82/100], Step [30/111], Loss: 0.3306\n",
      "Epoch [82/100], Step [32/111], Loss: 0.1687\n",
      "Epoch [82/100], Step [34/111], Loss: 0.1953\n",
      "Epoch [82/100], Step [36/111], Loss: 1.9566\n",
      "Epoch [82/100], Step [38/111], Loss: 0.1749\n",
      "Epoch [82/100], Step [40/111], Loss: 0.1669\n",
      "Epoch [82/100], Step [42/111], Loss: 0.2551\n",
      "Epoch [82/100], Step [44/111], Loss: 0.2074\n",
      "Epoch [82/100], Step [46/111], Loss: 0.2442\n",
      "Epoch [82/100], Step [48/111], Loss: 0.1518\n",
      "Epoch [82/100], Step [50/111], Loss: 0.2223\n",
      "Epoch [82/100], Step [52/111], Loss: 0.1809\n",
      "Epoch [82/100], Step [54/111], Loss: 0.1170\n",
      "Epoch [82/100], Step [56/111], Loss: 0.2816\n",
      "Epoch [82/100], Step [58/111], Loss: 0.2200\n",
      "Epoch [82/100], Step [60/111], Loss: 0.1508\n",
      "Epoch [82/100], Step [62/111], Loss: 0.1914\n",
      "Epoch [82/100], Step [64/111], Loss: 0.1702\n",
      "Epoch [82/100], Step [66/111], Loss: 0.1310\n",
      "Epoch [82/100], Step [68/111], Loss: 0.1879\n",
      "Epoch [82/100], Step [70/111], Loss: 0.1835\n",
      "Epoch [82/100], Step [72/111], Loss: 0.2116\n",
      "Epoch [82/100], Step [74/111], Loss: 0.1827\n",
      "Epoch [82/100], Step [76/111], Loss: 0.3330\n",
      "Epoch [82/100], Step [78/111], Loss: 0.1637\n",
      "Epoch [82/100], Step [80/111], Loss: 2.9808\n",
      "Epoch [82/100], Step [82/111], Loss: 0.3020\n",
      "Epoch [82/100], Step [84/111], Loss: 0.1872\n",
      "Epoch [82/100], Step [86/111], Loss: 0.2333\n",
      "Epoch [82/100], Step [88/111], Loss: 0.3618\n",
      "Epoch [82/100], Step [90/111], Loss: 0.1739\n",
      "Epoch [82/100], Step [92/111], Loss: 0.2011\n",
      "Epoch [82/100], Step [94/111], Loss: 0.2563\n",
      "Epoch [82/100], Step [96/111], Loss: 4.7372\n",
      "Epoch [82/100], Step [98/111], Loss: 0.2311\n",
      "Epoch [82/100], Step [100/111], Loss: 0.2347\n",
      "Epoch [82/100], Step [102/111], Loss: 0.2522\n",
      "Epoch [82/100], Step [104/111], Loss: 0.2198\n",
      "Epoch [82/100], Step [106/111], Loss: 0.1878\n",
      "Epoch [82/100], Step [108/111], Loss: 0.3163\n",
      "Epoch [82/100], Step [110/111], Loss: 0.1584\n",
      "Epoch [83/100], Step [2/111], Loss: 0.2044\n",
      "Epoch [83/100], Step [4/111], Loss: 0.3524\n",
      "Epoch [83/100], Step [6/111], Loss: 0.2020\n",
      "Epoch [83/100], Step [8/111], Loss: 0.2397\n",
      "Epoch [83/100], Step [10/111], Loss: 2.4548\n",
      "Epoch [83/100], Step [12/111], Loss: 0.1193\n",
      "Epoch [83/100], Step [14/111], Loss: 0.2072\n",
      "Epoch [83/100], Step [16/111], Loss: 2.5231\n",
      "Epoch [83/100], Step [18/111], Loss: 0.2145\n",
      "Epoch [83/100], Step [20/111], Loss: 0.2791\n",
      "Epoch [83/100], Step [22/111], Loss: 0.2030\n",
      "Epoch [83/100], Step [24/111], Loss: 0.2228\n",
      "Epoch [83/100], Step [26/111], Loss: 0.1919\n",
      "Epoch [83/100], Step [28/111], Loss: 0.1543\n",
      "Epoch [83/100], Step [30/111], Loss: 0.1777\n",
      "Epoch [83/100], Step [32/111], Loss: 0.2014\n",
      "Epoch [83/100], Step [34/111], Loss: 0.1585\n",
      "Epoch [83/100], Step [36/111], Loss: 0.1558\n",
      "Epoch [83/100], Step [38/111], Loss: 0.1378\n",
      "Epoch [83/100], Step [40/111], Loss: 0.1536\n",
      "Epoch [83/100], Step [42/111], Loss: 0.2151\n",
      "Epoch [83/100], Step [44/111], Loss: 0.1506\n",
      "Epoch [83/100], Step [46/111], Loss: 0.1320\n",
      "Epoch [83/100], Step [48/111], Loss: 0.1859\n",
      "Epoch [83/100], Step [50/111], Loss: 0.1714\n",
      "Epoch [83/100], Step [52/111], Loss: 0.2204\n",
      "Epoch [83/100], Step [54/111], Loss: 0.1729\n",
      "Epoch [83/100], Step [56/111], Loss: 0.1507\n",
      "Epoch [83/100], Step [58/111], Loss: 0.1826\n",
      "Epoch [83/100], Step [60/111], Loss: 0.1649\n",
      "Epoch [83/100], Step [62/111], Loss: 0.1064\n",
      "Epoch [83/100], Step [64/111], Loss: 0.1328\n",
      "Epoch [83/100], Step [66/111], Loss: 0.1342\n",
      "Epoch [83/100], Step [68/111], Loss: 0.2962\n",
      "Epoch [83/100], Step [70/111], Loss: 4.2497\n",
      "Epoch [83/100], Step [72/111], Loss: 0.1885\n",
      "Epoch [83/100], Step [74/111], Loss: 0.1351\n",
      "Epoch [83/100], Step [76/111], Loss: 0.1620\n",
      "Epoch [83/100], Step [78/111], Loss: 0.2526\n",
      "Epoch [83/100], Step [80/111], Loss: 0.1705\n",
      "Epoch [83/100], Step [82/111], Loss: 0.2238\n",
      "Epoch [83/100], Step [84/111], Loss: 0.1487\n",
      "Epoch [83/100], Step [86/111], Loss: 0.1745\n",
      "Epoch [83/100], Step [88/111], Loss: 0.1757\n",
      "Epoch [83/100], Step [90/111], Loss: 0.1734\n",
      "Epoch [83/100], Step [92/111], Loss: 0.5368\n",
      "Epoch [83/100], Step [94/111], Loss: 0.1265\n",
      "Epoch [83/100], Step [96/111], Loss: 0.1573\n",
      "Epoch [83/100], Step [98/111], Loss: 0.2286\n",
      "Epoch [83/100], Step [100/111], Loss: 0.2723\n",
      "Epoch [83/100], Step [102/111], Loss: 2.7919\n",
      "Epoch [83/100], Step [104/111], Loss: 0.1823\n",
      "Epoch [83/100], Step [106/111], Loss: 0.2362\n",
      "Epoch [83/100], Step [108/111], Loss: 0.1549\n",
      "Epoch [83/100], Step [110/111], Loss: 0.2547\n",
      "Epoch [84/100], Step [2/111], Loss: 0.6282\n",
      "Epoch [84/100], Step [4/111], Loss: 0.2934\n",
      "Epoch [84/100], Step [6/111], Loss: 0.2859\n",
      "Epoch [84/100], Step [8/111], Loss: 0.2799\n",
      "Epoch [84/100], Step [10/111], Loss: 0.3175\n",
      "Epoch [84/100], Step [12/111], Loss: 0.2180\n",
      "Epoch [84/100], Step [14/111], Loss: 3.3430\n",
      "Epoch [84/100], Step [16/111], Loss: 0.1454\n",
      "Epoch [84/100], Step [18/111], Loss: 0.2261\n",
      "Epoch [84/100], Step [20/111], Loss: 0.1556\n",
      "Epoch [84/100], Step [22/111], Loss: 0.1483\n",
      "Epoch [84/100], Step [24/111], Loss: 0.2567\n",
      "Epoch [84/100], Step [26/111], Loss: 0.1425\n",
      "Epoch [84/100], Step [28/111], Loss: 0.1617\n",
      "Epoch [84/100], Step [30/111], Loss: 0.1982\n",
      "Epoch [84/100], Step [32/111], Loss: 0.1860\n",
      "Epoch [84/100], Step [34/111], Loss: 0.3376\n",
      "Epoch [84/100], Step [36/111], Loss: 0.1718\n",
      "Epoch [84/100], Step [38/111], Loss: 0.1899\n",
      "Epoch [84/100], Step [40/111], Loss: 0.1730\n",
      "Epoch [84/100], Step [42/111], Loss: 0.1561\n",
      "Epoch [84/100], Step [44/111], Loss: 0.2199\n",
      "Epoch [84/100], Step [46/111], Loss: 0.1420\n",
      "Epoch [84/100], Step [48/111], Loss: 0.1438\n",
      "Epoch [84/100], Step [50/111], Loss: 0.2109\n",
      "Epoch [84/100], Step [52/111], Loss: 0.1897\n",
      "Epoch [84/100], Step [54/111], Loss: 2.2027\n",
      "Epoch [84/100], Step [56/111], Loss: 0.1209\n",
      "Epoch [84/100], Step [58/111], Loss: 0.1741\n",
      "Epoch [84/100], Step [60/111], Loss: 0.1899\n",
      "Epoch [84/100], Step [62/111], Loss: 0.1709\n",
      "Epoch [84/100], Step [64/111], Loss: 0.1409\n",
      "Epoch [84/100], Step [66/111], Loss: 0.3744\n",
      "Epoch [84/100], Step [68/111], Loss: 0.1893\n",
      "Epoch [84/100], Step [70/111], Loss: 0.2142\n",
      "Epoch [84/100], Step [72/111], Loss: 0.1987\n",
      "Epoch [84/100], Step [74/111], Loss: 0.1858\n",
      "Epoch [84/100], Step [76/111], Loss: 0.1866\n",
      "Epoch [84/100], Step [78/111], Loss: 0.1378\n",
      "Epoch [84/100], Step [80/111], Loss: 0.1878\n",
      "Epoch [84/100], Step [82/111], Loss: 0.1758\n",
      "Epoch [84/100], Step [84/111], Loss: 0.1887\n",
      "Epoch [84/100], Step [86/111], Loss: 0.2278\n",
      "Epoch [84/100], Step [88/111], Loss: 0.1842\n",
      "Epoch [84/100], Step [90/111], Loss: 0.2582\n",
      "Epoch [84/100], Step [92/111], Loss: 0.1596\n",
      "Epoch [84/100], Step [94/111], Loss: 0.2379\n",
      "Epoch [84/100], Step [96/111], Loss: 0.1407\n",
      "Epoch [84/100], Step [98/111], Loss: 0.1813\n",
      "Epoch [84/100], Step [100/111], Loss: 0.2140\n",
      "Epoch [84/100], Step [102/111], Loss: 0.1774\n",
      "Epoch [84/100], Step [104/111], Loss: 0.1789\n",
      "Epoch [84/100], Step [106/111], Loss: 0.1557\n",
      "Epoch [84/100], Step [108/111], Loss: 0.2623\n",
      "Epoch [84/100], Step [110/111], Loss: 0.2046\n",
      "Epoch [85/100], Step [2/111], Loss: 0.2421\n",
      "Epoch [85/100], Step [4/111], Loss: 0.2028\n",
      "Epoch [85/100], Step [6/111], Loss: 0.2017\n",
      "Epoch [85/100], Step [8/111], Loss: 0.1707\n",
      "Epoch [85/100], Step [10/111], Loss: 0.1490\n",
      "Epoch [85/100], Step [12/111], Loss: 0.1350\n",
      "Epoch [85/100], Step [14/111], Loss: 0.1192\n",
      "Epoch [85/100], Step [16/111], Loss: 0.1778\n",
      "Epoch [85/100], Step [18/111], Loss: 0.1936\n",
      "Epoch [85/100], Step [20/111], Loss: 0.1728\n",
      "Epoch [85/100], Step [22/111], Loss: 0.1657\n",
      "Epoch [85/100], Step [24/111], Loss: 0.1333\n",
      "Epoch [85/100], Step [26/111], Loss: 0.1789\n",
      "Epoch [85/100], Step [28/111], Loss: 0.3951\n",
      "Epoch [85/100], Step [30/111], Loss: 0.2084\n",
      "Epoch [85/100], Step [32/111], Loss: 0.1984\n",
      "Epoch [85/100], Step [34/111], Loss: 0.1496\n",
      "Epoch [85/100], Step [36/111], Loss: 0.1507\n",
      "Epoch [85/100], Step [38/111], Loss: 0.1486\n",
      "Epoch [85/100], Step [40/111], Loss: 2.8797\n",
      "Epoch [85/100], Step [42/111], Loss: 0.1121\n",
      "Epoch [85/100], Step [44/111], Loss: 0.1765\n",
      "Epoch [85/100], Step [46/111], Loss: 0.1627\n",
      "Epoch [85/100], Step [48/111], Loss: 0.2221\n",
      "Epoch [85/100], Step [50/111], Loss: 2.3574\n",
      "Epoch [85/100], Step [52/111], Loss: 0.1535\n",
      "Epoch [85/100], Step [54/111], Loss: 0.1802\n",
      "Epoch [85/100], Step [56/111], Loss: 0.1896\n",
      "Epoch [85/100], Step [58/111], Loss: 0.1278\n",
      "Epoch [85/100], Step [60/111], Loss: 0.1381\n",
      "Epoch [85/100], Step [62/111], Loss: 0.1448\n",
      "Epoch [85/100], Step [64/111], Loss: 0.1753\n",
      "Epoch [85/100], Step [66/111], Loss: 0.1667\n",
      "Epoch [85/100], Step [68/111], Loss: 0.1725\n",
      "Epoch [85/100], Step [70/111], Loss: 0.1465\n",
      "Epoch [85/100], Step [72/111], Loss: 0.2511\n",
      "Epoch [85/100], Step [74/111], Loss: 0.1621\n",
      "Epoch [85/100], Step [76/111], Loss: 0.1553\n",
      "Epoch [85/100], Step [78/111], Loss: 0.1547\n",
      "Epoch [85/100], Step [80/111], Loss: 0.1383\n",
      "Epoch [85/100], Step [82/111], Loss: 0.2214\n",
      "Epoch [85/100], Step [84/111], Loss: 0.1852\n",
      "Epoch [85/100], Step [86/111], Loss: 0.1662\n",
      "Epoch [85/100], Step [88/111], Loss: 0.1866\n",
      "Epoch [85/100], Step [90/111], Loss: 0.1180\n",
      "Epoch [85/100], Step [92/111], Loss: 2.3673\n",
      "Epoch [85/100], Step [94/111], Loss: 0.1176\n",
      "Epoch [85/100], Step [96/111], Loss: 0.1451\n",
      "Epoch [85/100], Step [98/111], Loss: 0.1321\n",
      "Epoch [85/100], Step [100/111], Loss: 0.1207\n",
      "Epoch [85/100], Step [102/111], Loss: 0.2345\n",
      "Epoch [85/100], Step [104/111], Loss: 0.8927\n",
      "Epoch [85/100], Step [106/111], Loss: 4.4416\n",
      "Epoch [85/100], Step [108/111], Loss: 0.1598\n",
      "Epoch [85/100], Step [110/111], Loss: 0.1616\n",
      "Epoch [86/100], Step [2/111], Loss: 0.2034\n",
      "Epoch [86/100], Step [4/111], Loss: 0.1803\n",
      "Epoch [86/100], Step [6/111], Loss: 0.2029\n",
      "Epoch [86/100], Step [8/111], Loss: 0.1787\n",
      "Epoch [86/100], Step [10/111], Loss: 0.1713\n",
      "Epoch [86/100], Step [12/111], Loss: 0.1700\n",
      "Epoch [86/100], Step [14/111], Loss: 0.1349\n",
      "Epoch [86/100], Step [16/111], Loss: 0.1415\n",
      "Epoch [86/100], Step [18/111], Loss: 3.1247\n",
      "Epoch [86/100], Step [20/111], Loss: 0.1748\n",
      "Epoch [86/100], Step [22/111], Loss: 2.7744\n",
      "Epoch [86/100], Step [24/111], Loss: 0.0996\n",
      "Epoch [86/100], Step [26/111], Loss: 0.1447\n",
      "Epoch [86/100], Step [28/111], Loss: 0.1314\n",
      "Epoch [86/100], Step [30/111], Loss: 0.1631\n",
      "Epoch [86/100], Step [32/111], Loss: 0.1513\n",
      "Epoch [86/100], Step [34/111], Loss: 0.1278\n",
      "Epoch [86/100], Step [36/111], Loss: 0.1309\n",
      "Epoch [86/100], Step [38/111], Loss: 0.2043\n",
      "Epoch [86/100], Step [40/111], Loss: 0.2154\n",
      "Epoch [86/100], Step [42/111], Loss: 0.2286\n",
      "Epoch [86/100], Step [44/111], Loss: 0.1597\n",
      "Epoch [86/100], Step [46/111], Loss: 0.1692\n",
      "Epoch [86/100], Step [48/111], Loss: 0.1967\n",
      "Epoch [86/100], Step [50/111], Loss: 0.1415\n",
      "Epoch [86/100], Step [52/111], Loss: 0.1585\n",
      "Epoch [86/100], Step [54/111], Loss: 0.2136\n",
      "Epoch [86/100], Step [56/111], Loss: 0.2795\n",
      "Epoch [86/100], Step [58/111], Loss: 0.1770\n",
      "Epoch [86/100], Step [60/111], Loss: 0.1384\n",
      "Epoch [86/100], Step [62/111], Loss: 0.1831\n",
      "Epoch [86/100], Step [64/111], Loss: 0.1498\n",
      "Epoch [86/100], Step [66/111], Loss: 0.1685\n",
      "Epoch [86/100], Step [68/111], Loss: 0.1630\n",
      "Epoch [86/100], Step [70/111], Loss: 0.2069\n",
      "Epoch [86/100], Step [72/111], Loss: 0.1779\n",
      "Epoch [86/100], Step [74/111], Loss: 0.1337\n",
      "Epoch [86/100], Step [76/111], Loss: 0.1634\n",
      "Epoch [86/100], Step [78/111], Loss: 0.1733\n",
      "Epoch [86/100], Step [80/111], Loss: 0.1991\n",
      "Epoch [86/100], Step [82/111], Loss: 0.1796\n",
      "Epoch [86/100], Step [84/111], Loss: 3.2827\n",
      "Epoch [86/100], Step [86/111], Loss: 0.2046\n",
      "Epoch [86/100], Step [88/111], Loss: 0.1444\n",
      "Epoch [86/100], Step [90/111], Loss: 2.4868\n",
      "Epoch [86/100], Step [92/111], Loss: 0.2111\n",
      "Epoch [86/100], Step [94/111], Loss: 0.2029\n",
      "Epoch [86/100], Step [96/111], Loss: 0.3323\n",
      "Epoch [86/100], Step [98/111], Loss: 0.1558\n",
      "Epoch [86/100], Step [100/111], Loss: 0.2378\n",
      "Epoch [86/100], Step [102/111], Loss: 0.1705\n",
      "Epoch [86/100], Step [104/111], Loss: 0.1869\n",
      "Epoch [86/100], Step [106/111], Loss: 0.1611\n",
      "Epoch [86/100], Step [108/111], Loss: 0.1936\n",
      "Epoch [86/100], Step [110/111], Loss: 0.2283\n",
      "Epoch [87/100], Step [2/111], Loss: 0.2002\n",
      "Epoch [87/100], Step [4/111], Loss: 0.1874\n",
      "Epoch [87/100], Step [6/111], Loss: 0.2023\n",
      "Epoch [87/100], Step [8/111], Loss: 0.1476\n",
      "Epoch [87/100], Step [10/111], Loss: 0.1999\n",
      "Epoch [87/100], Step [12/111], Loss: 0.3699\n",
      "Epoch [87/100], Step [14/111], Loss: 0.2573\n",
      "Epoch [87/100], Step [16/111], Loss: 0.1785\n",
      "Epoch [87/100], Step [18/111], Loss: 0.2175\n",
      "Epoch [87/100], Step [20/111], Loss: 0.2373\n",
      "Epoch [87/100], Step [22/111], Loss: 0.2226\n",
      "Epoch [87/100], Step [24/111], Loss: 0.1897\n",
      "Epoch [87/100], Step [26/111], Loss: 0.1415\n",
      "Epoch [87/100], Step [28/111], Loss: 0.2165\n",
      "Epoch [87/100], Step [30/111], Loss: 0.1159\n",
      "Epoch [87/100], Step [32/111], Loss: 0.1783\n",
      "Epoch [87/100], Step [34/111], Loss: 0.1549\n",
      "Epoch [87/100], Step [36/111], Loss: 0.1725\n",
      "Epoch [87/100], Step [38/111], Loss: 0.1560\n",
      "Epoch [87/100], Step [40/111], Loss: 2.0951\n",
      "Epoch [87/100], Step [42/111], Loss: 0.7540\n",
      "Epoch [87/100], Step [44/111], Loss: 0.2365\n",
      "Epoch [87/100], Step [46/111], Loss: 0.1883\n",
      "Epoch [87/100], Step [48/111], Loss: 0.2529\n",
      "Epoch [87/100], Step [50/111], Loss: 0.2589\n",
      "Epoch [87/100], Step [52/111], Loss: 0.2767\n",
      "Epoch [87/100], Step [54/111], Loss: 0.3312\n",
      "Epoch [87/100], Step [56/111], Loss: 0.1969\n",
      "Epoch [87/100], Step [58/111], Loss: 0.2281\n",
      "Epoch [87/100], Step [60/111], Loss: 0.2556\n",
      "Epoch [87/100], Step [62/111], Loss: 0.2224\n",
      "Epoch [87/100], Step [64/111], Loss: 0.2982\n",
      "Epoch [87/100], Step [66/111], Loss: 0.1943\n",
      "Epoch [87/100], Step [68/111], Loss: 0.1621\n",
      "Epoch [87/100], Step [70/111], Loss: 0.2001\n",
      "Epoch [87/100], Step [72/111], Loss: 0.2513\n",
      "Epoch [87/100], Step [74/111], Loss: 0.1630\n",
      "Epoch [87/100], Step [76/111], Loss: 0.1712\n",
      "Epoch [87/100], Step [78/111], Loss: 0.1969\n",
      "Epoch [87/100], Step [80/111], Loss: 0.1755\n",
      "Epoch [87/100], Step [82/111], Loss: 0.1166\n",
      "Epoch [87/100], Step [84/111], Loss: 0.1643\n",
      "Epoch [87/100], Step [86/111], Loss: 0.1465\n",
      "Epoch [87/100], Step [88/111], Loss: 4.3205\n",
      "Epoch [87/100], Step [90/111], Loss: 0.2088\n",
      "Epoch [87/100], Step [92/111], Loss: 0.2092\n",
      "Epoch [87/100], Step [94/111], Loss: 0.1612\n",
      "Epoch [87/100], Step [96/111], Loss: 0.1473\n",
      "Epoch [87/100], Step [98/111], Loss: 0.1586\n",
      "Epoch [87/100], Step [100/111], Loss: 0.1883\n",
      "Epoch [87/100], Step [102/111], Loss: 0.2153\n",
      "Epoch [87/100], Step [104/111], Loss: 0.2807\n",
      "Epoch [87/100], Step [106/111], Loss: 0.2186\n",
      "Epoch [87/100], Step [108/111], Loss: 0.1665\n",
      "Epoch [87/100], Step [110/111], Loss: 0.3017\n",
      "Epoch [88/100], Step [2/111], Loss: 0.2700\n",
      "Epoch [88/100], Step [4/111], Loss: 0.2155\n",
      "Epoch [88/100], Step [6/111], Loss: 0.2590\n",
      "Epoch [88/100], Step [8/111], Loss: 0.2926\n",
      "Epoch [88/100], Step [10/111], Loss: 0.2147\n",
      "Epoch [88/100], Step [12/111], Loss: 0.2015\n",
      "Epoch [88/100], Step [14/111], Loss: 0.4269\n",
      "Epoch [88/100], Step [16/111], Loss: 0.2062\n",
      "Epoch [88/100], Step [18/111], Loss: 0.2674\n",
      "Epoch [88/100], Step [20/111], Loss: 0.3894\n",
      "Epoch [88/100], Step [22/111], Loss: 0.2009\n",
      "Epoch [88/100], Step [24/111], Loss: 0.2091\n",
      "Epoch [88/100], Step [26/111], Loss: 0.1432\n",
      "Epoch [88/100], Step [28/111], Loss: 0.1976\n",
      "Epoch [88/100], Step [30/111], Loss: 0.1727\n",
      "Epoch [88/100], Step [32/111], Loss: 0.4409\n",
      "Epoch [88/100], Step [34/111], Loss: 0.1616\n",
      "Epoch [88/100], Step [36/111], Loss: 0.1722\n",
      "Epoch [88/100], Step [38/111], Loss: 0.1745\n",
      "Epoch [88/100], Step [40/111], Loss: 0.1683\n",
      "Epoch [88/100], Step [42/111], Loss: 0.2101\n",
      "Epoch [88/100], Step [44/111], Loss: 0.2540\n",
      "Epoch [88/100], Step [46/111], Loss: 0.1754\n",
      "Epoch [88/100], Step [48/111], Loss: 0.1878\n",
      "Epoch [88/100], Step [50/111], Loss: 0.2569\n",
      "Epoch [88/100], Step [52/111], Loss: 0.1449\n",
      "Epoch [88/100], Step [54/111], Loss: 0.3336\n",
      "Epoch [88/100], Step [56/111], Loss: 0.1553\n",
      "Epoch [88/100], Step [58/111], Loss: 0.1455\n",
      "Epoch [88/100], Step [60/111], Loss: 0.1656\n",
      "Epoch [88/100], Step [62/111], Loss: 0.3018\n",
      "Epoch [88/100], Step [64/111], Loss: 0.1614\n",
      "Epoch [88/100], Step [66/111], Loss: 0.1611\n",
      "Epoch [88/100], Step [68/111], Loss: 0.1290\n",
      "Epoch [88/100], Step [70/111], Loss: 0.2223\n",
      "Epoch [88/100], Step [72/111], Loss: 0.2040\n",
      "Epoch [88/100], Step [74/111], Loss: 0.2105\n",
      "Epoch [88/100], Step [76/111], Loss: 0.1783\n",
      "Epoch [88/100], Step [78/111], Loss: 0.1105\n",
      "Epoch [88/100], Step [80/111], Loss: 0.3177\n",
      "Epoch [88/100], Step [82/111], Loss: 0.2923\n",
      "Epoch [88/100], Step [84/111], Loss: 0.2705\n",
      "Epoch [88/100], Step [86/111], Loss: 0.1755\n",
      "Epoch [88/100], Step [88/111], Loss: 0.1682\n",
      "Epoch [88/100], Step [90/111], Loss: 0.2700\n",
      "Epoch [88/100], Step [92/111], Loss: 0.2012\n",
      "Epoch [88/100], Step [94/111], Loss: 0.1975\n",
      "Epoch [88/100], Step [96/111], Loss: 0.1154\n",
      "Epoch [88/100], Step [98/111], Loss: 0.1605\n",
      "Epoch [88/100], Step [100/111], Loss: 0.1317\n",
      "Epoch [88/100], Step [102/111], Loss: 0.1609\n",
      "Epoch [88/100], Step [104/111], Loss: 0.2549\n",
      "Epoch [88/100], Step [106/111], Loss: 0.1804\n",
      "Epoch [88/100], Step [108/111], Loss: 0.2149\n",
      "Epoch [88/100], Step [110/111], Loss: 0.1544\n",
      "Epoch [89/100], Step [2/111], Loss: 0.3006\n",
      "Epoch [89/100], Step [4/111], Loss: 0.1786\n",
      "Epoch [89/100], Step [6/111], Loss: 0.1863\n",
      "Epoch [89/100], Step [8/111], Loss: 0.1715\n",
      "Epoch [89/100], Step [10/111], Loss: 0.1484\n",
      "Epoch [89/100], Step [12/111], Loss: 0.1272\n",
      "Epoch [89/100], Step [14/111], Loss: 0.1488\n",
      "Epoch [89/100], Step [16/111], Loss: 0.1906\n",
      "Epoch [89/100], Step [18/111], Loss: 0.1689\n",
      "Epoch [89/100], Step [20/111], Loss: 0.1467\n",
      "Epoch [89/100], Step [22/111], Loss: 0.1571\n",
      "Epoch [89/100], Step [24/111], Loss: 0.1719\n",
      "Epoch [89/100], Step [26/111], Loss: 0.1091\n",
      "Epoch [89/100], Step [28/111], Loss: 0.1965\n",
      "Epoch [89/100], Step [30/111], Loss: 0.1609\n",
      "Epoch [89/100], Step [32/111], Loss: 0.1654\n",
      "Epoch [89/100], Step [34/111], Loss: 0.1207\n",
      "Epoch [89/100], Step [36/111], Loss: 0.1296\n",
      "Epoch [89/100], Step [38/111], Loss: 0.1147\n",
      "Epoch [89/100], Step [40/111], Loss: 0.1330\n",
      "Epoch [89/100], Step [42/111], Loss: 0.1227\n",
      "Epoch [89/100], Step [44/111], Loss: 0.1394\n",
      "Epoch [89/100], Step [46/111], Loss: 0.2100\n",
      "Epoch [89/100], Step [48/111], Loss: 2.7595\n",
      "Epoch [89/100], Step [50/111], Loss: 0.1683\n",
      "Epoch [89/100], Step [52/111], Loss: 0.2432\n",
      "Epoch [89/100], Step [54/111], Loss: 0.1237\n",
      "Epoch [89/100], Step [56/111], Loss: 0.2477\n",
      "Epoch [89/100], Step [58/111], Loss: 0.1391\n",
      "Epoch [89/100], Step [60/111], Loss: 2.4880\n",
      "Epoch [89/100], Step [62/111], Loss: 0.1636\n",
      "Epoch [89/100], Step [64/111], Loss: 0.2248\n",
      "Epoch [89/100], Step [66/111], Loss: 0.2058\n",
      "Epoch [89/100], Step [68/111], Loss: 0.2107\n",
      "Epoch [89/100], Step [70/111], Loss: 0.1594\n",
      "Epoch [89/100], Step [72/111], Loss: 0.3326\n",
      "Epoch [89/100], Step [74/111], Loss: 0.1272\n",
      "Epoch [89/100], Step [76/111], Loss: 0.1940\n",
      "Epoch [89/100], Step [78/111], Loss: 0.1266\n",
      "Epoch [89/100], Step [80/111], Loss: 0.1319\n",
      "Epoch [89/100], Step [82/111], Loss: 0.1391\n",
      "Epoch [89/100], Step [84/111], Loss: 0.1473\n",
      "Epoch [89/100], Step [86/111], Loss: 0.1400\n",
      "Epoch [89/100], Step [88/111], Loss: 0.1166\n",
      "Epoch [89/100], Step [90/111], Loss: 0.1360\n",
      "Epoch [89/100], Step [92/111], Loss: 0.1702\n",
      "Epoch [89/100], Step [94/111], Loss: 0.1679\n",
      "Epoch [89/100], Step [96/111], Loss: 0.1399\n",
      "Epoch [89/100], Step [98/111], Loss: 0.1610\n",
      "Epoch [89/100], Step [100/111], Loss: 0.1675\n",
      "Epoch [89/100], Step [102/111], Loss: 0.1611\n",
      "Epoch [89/100], Step [104/111], Loss: 0.1980\n",
      "Epoch [89/100], Step [106/111], Loss: 0.1498\n",
      "Epoch [89/100], Step [108/111], Loss: 0.1529\n",
      "Epoch [89/100], Step [110/111], Loss: 0.1550\n",
      "Epoch [90/100], Step [2/111], Loss: 0.1935\n",
      "Epoch [90/100], Step [4/111], Loss: 2.6513\n",
      "Epoch [90/100], Step [6/111], Loss: 0.1377\n",
      "Epoch [90/100], Step [8/111], Loss: 0.1408\n",
      "Epoch [90/100], Step [10/111], Loss: 0.2329\n",
      "Epoch [90/100], Step [12/111], Loss: 0.1665\n",
      "Epoch [90/100], Step [14/111], Loss: 0.1495\n",
      "Epoch [90/100], Step [16/111], Loss: 0.2457\n",
      "Epoch [90/100], Step [18/111], Loss: 0.1733\n",
      "Epoch [90/100], Step [20/111], Loss: 0.2319\n",
      "Epoch [90/100], Step [22/111], Loss: 0.2009\n",
      "Epoch [90/100], Step [24/111], Loss: 0.1427\n",
      "Epoch [90/100], Step [26/111], Loss: 0.2790\n",
      "Epoch [90/100], Step [28/111], Loss: 0.1377\n",
      "Epoch [90/100], Step [30/111], Loss: 0.2337\n",
      "Epoch [90/100], Step [32/111], Loss: 0.2449\n",
      "Epoch [90/100], Step [34/111], Loss: 0.2419\n",
      "Epoch [90/100], Step [36/111], Loss: 0.2268\n",
      "Epoch [90/100], Step [38/111], Loss: 0.1933\n",
      "Epoch [90/100], Step [40/111], Loss: 0.2215\n",
      "Epoch [90/100], Step [42/111], Loss: 0.1445\n",
      "Epoch [90/100], Step [44/111], Loss: 0.1751\n",
      "Epoch [90/100], Step [46/111], Loss: 0.0999\n",
      "Epoch [90/100], Step [48/111], Loss: 4.1444\n",
      "Epoch [90/100], Step [50/111], Loss: 0.2089\n",
      "Epoch [90/100], Step [52/111], Loss: 0.1931\n",
      "Epoch [90/100], Step [54/111], Loss: 0.2142\n",
      "Epoch [90/100], Step [56/111], Loss: 0.2987\n",
      "Epoch [90/100], Step [58/111], Loss: 0.1822\n",
      "Epoch [90/100], Step [60/111], Loss: 0.1651\n",
      "Epoch [90/100], Step [62/111], Loss: 0.0861\n",
      "Epoch [90/100], Step [64/111], Loss: 0.2847\n",
      "Epoch [90/100], Step [66/111], Loss: 0.1518\n",
      "Epoch [90/100], Step [68/111], Loss: 0.1417\n",
      "Epoch [90/100], Step [70/111], Loss: 0.1213\n",
      "Epoch [90/100], Step [72/111], Loss: 0.1476\n",
      "Epoch [90/100], Step [74/111], Loss: 0.1515\n",
      "Epoch [90/100], Step [76/111], Loss: 0.1588\n",
      "Epoch [90/100], Step [78/111], Loss: 0.1512\n",
      "Epoch [90/100], Step [80/111], Loss: 0.2202\n",
      "Epoch [90/100], Step [82/111], Loss: 0.2031\n",
      "Epoch [90/100], Step [84/111], Loss: 0.1640\n",
      "Epoch [90/100], Step [86/111], Loss: 0.1512\n",
      "Epoch [90/100], Step [88/111], Loss: 0.1945\n",
      "Epoch [90/100], Step [90/111], Loss: 0.1129\n",
      "Epoch [90/100], Step [92/111], Loss: 0.2170\n",
      "Epoch [90/100], Step [94/111], Loss: 0.2256\n",
      "Epoch [90/100], Step [96/111], Loss: 0.1970\n",
      "Epoch [90/100], Step [98/111], Loss: 0.1524\n",
      "Epoch [90/100], Step [100/111], Loss: 0.1809\n",
      "Epoch [90/100], Step [102/111], Loss: 0.2372\n",
      "Epoch [90/100], Step [104/111], Loss: 0.3343\n",
      "Epoch [90/100], Step [106/111], Loss: 0.2366\n",
      "Epoch [90/100], Step [108/111], Loss: 0.1554\n",
      "Epoch [90/100], Step [110/111], Loss: 0.1727\n",
      "Epoch [91/100], Step [2/111], Loss: 0.2277\n",
      "Epoch [91/100], Step [4/111], Loss: 0.2095\n",
      "Epoch [91/100], Step [6/111], Loss: 0.2460\n",
      "Epoch [91/100], Step [8/111], Loss: 0.1698\n",
      "Epoch [91/100], Step [10/111], Loss: 3.3563\n",
      "Epoch [91/100], Step [12/111], Loss: 0.1690\n",
      "Epoch [91/100], Step [14/111], Loss: 0.1354\n",
      "Epoch [91/100], Step [16/111], Loss: 0.1491\n",
      "Epoch [91/100], Step [18/111], Loss: 0.1807\n",
      "Epoch [91/100], Step [20/111], Loss: 0.1928\n",
      "Epoch [91/100], Step [22/111], Loss: 0.1574\n",
      "Epoch [91/100], Step [24/111], Loss: 0.1463\n",
      "Epoch [91/100], Step [26/111], Loss: 0.2160\n",
      "Epoch [91/100], Step [28/111], Loss: 0.2402\n",
      "Epoch [91/100], Step [30/111], Loss: 0.1473\n",
      "Epoch [91/100], Step [32/111], Loss: 0.1193\n",
      "Epoch [91/100], Step [34/111], Loss: 0.1556\n",
      "Epoch [91/100], Step [36/111], Loss: 0.2173\n",
      "Epoch [91/100], Step [38/111], Loss: 0.1448\n",
      "Epoch [91/100], Step [40/111], Loss: 0.2067\n",
      "Epoch [91/100], Step [42/111], Loss: 0.1939\n",
      "Epoch [91/100], Step [44/111], Loss: 0.2097\n",
      "Epoch [91/100], Step [46/111], Loss: 0.1413\n",
      "Epoch [91/100], Step [48/111], Loss: 0.1303\n",
      "Epoch [91/100], Step [50/111], Loss: 0.1367\n",
      "Epoch [91/100], Step [52/111], Loss: 0.1971\n",
      "Epoch [91/100], Step [54/111], Loss: 0.1541\n",
      "Epoch [91/100], Step [56/111], Loss: 0.1414\n",
      "Epoch [91/100], Step [58/111], Loss: 0.1503\n",
      "Epoch [91/100], Step [60/111], Loss: 0.1367\n",
      "Epoch [91/100], Step [62/111], Loss: 0.1812\n",
      "Epoch [91/100], Step [64/111], Loss: 0.1877\n",
      "Epoch [91/100], Step [66/111], Loss: 0.1457\n",
      "Epoch [91/100], Step [68/111], Loss: 0.1547\n",
      "Epoch [91/100], Step [70/111], Loss: 0.2016\n",
      "Epoch [91/100], Step [72/111], Loss: 0.1943\n",
      "Epoch [91/100], Step [74/111], Loss: 0.1135\n",
      "Epoch [91/100], Step [76/111], Loss: 0.1825\n",
      "Epoch [91/100], Step [78/111], Loss: 0.1267\n",
      "Epoch [91/100], Step [80/111], Loss: 0.4418\n",
      "Epoch [91/100], Step [82/111], Loss: 0.1648\n",
      "Epoch [91/100], Step [84/111], Loss: 0.1433\n",
      "Epoch [91/100], Step [86/111], Loss: 0.1515\n",
      "Epoch [91/100], Step [88/111], Loss: 0.1447\n",
      "Epoch [91/100], Step [90/111], Loss: 0.1193\n",
      "Epoch [91/100], Step [92/111], Loss: 0.1361\n",
      "Epoch [91/100], Step [94/111], Loss: 2.1274\n",
      "Epoch [91/100], Step [96/111], Loss: 0.1756\n",
      "Epoch [91/100], Step [98/111], Loss: 0.2158\n",
      "Epoch [91/100], Step [100/111], Loss: 0.2474\n",
      "Epoch [91/100], Step [102/111], Loss: 0.2366\n",
      "Epoch [91/100], Step [104/111], Loss: 0.1410\n",
      "Epoch [91/100], Step [106/111], Loss: 0.2351\n",
      "Epoch [91/100], Step [108/111], Loss: 0.1578\n",
      "Epoch [91/100], Step [110/111], Loss: 0.1808\n",
      "Epoch [92/100], Step [2/111], Loss: 0.1368\n",
      "Epoch [92/100], Step [4/111], Loss: 0.1749\n",
      "Epoch [92/100], Step [6/111], Loss: 0.1565\n",
      "Epoch [92/100], Step [8/111], Loss: 0.2538\n",
      "Epoch [92/100], Step [10/111], Loss: 2.7136\n",
      "Epoch [92/100], Step [12/111], Loss: 0.1994\n",
      "Epoch [92/100], Step [14/111], Loss: 0.1424\n",
      "Epoch [92/100], Step [16/111], Loss: 0.1940\n",
      "Epoch [92/100], Step [18/111], Loss: 0.1745\n",
      "Epoch [92/100], Step [20/111], Loss: 0.1688\n",
      "Epoch [92/100], Step [22/111], Loss: 0.2060\n",
      "Epoch [92/100], Step [24/111], Loss: 0.2428\n",
      "Epoch [92/100], Step [26/111], Loss: 0.1689\n",
      "Epoch [92/100], Step [28/111], Loss: 0.1231\n",
      "Epoch [92/100], Step [30/111], Loss: 0.2166\n",
      "Epoch [92/100], Step [32/111], Loss: 0.1464\n",
      "Epoch [92/100], Step [34/111], Loss: 0.2073\n",
      "Epoch [92/100], Step [36/111], Loss: 0.1536\n",
      "Epoch [92/100], Step [38/111], Loss: 0.2059\n",
      "Epoch [92/100], Step [40/111], Loss: 0.2111\n",
      "Epoch [92/100], Step [42/111], Loss: 0.1810\n",
      "Epoch [92/100], Step [44/111], Loss: 0.5767\n",
      "Epoch [92/100], Step [46/111], Loss: 0.1382\n",
      "Epoch [92/100], Step [48/111], Loss: 0.1044\n",
      "Epoch [92/100], Step [50/111], Loss: 0.1611\n",
      "Epoch [92/100], Step [52/111], Loss: 0.1605\n",
      "Epoch [92/100], Step [54/111], Loss: 0.1391\n",
      "Epoch [92/100], Step [56/111], Loss: 0.1770\n",
      "Epoch [92/100], Step [58/111], Loss: 0.1421\n",
      "Epoch [92/100], Step [60/111], Loss: 0.1888\n",
      "Epoch [92/100], Step [62/111], Loss: 0.1565\n",
      "Epoch [92/100], Step [64/111], Loss: 0.1344\n",
      "Epoch [92/100], Step [66/111], Loss: 0.1573\n",
      "Epoch [92/100], Step [68/111], Loss: 0.1611\n",
      "Epoch [92/100], Step [70/111], Loss: 0.1659\n",
      "Epoch [92/100], Step [72/111], Loss: 0.5570\n",
      "Epoch [92/100], Step [74/111], Loss: 0.2056\n",
      "Epoch [92/100], Step [76/111], Loss: 0.1752\n",
      "Epoch [92/100], Step [78/111], Loss: 0.5770\n",
      "Epoch [92/100], Step [80/111], Loss: 0.1386\n",
      "Epoch [92/100], Step [82/111], Loss: 0.1533\n",
      "Epoch [92/100], Step [84/111], Loss: 0.1664\n",
      "Epoch [92/100], Step [86/111], Loss: 0.1854\n",
      "Epoch [92/100], Step [88/111], Loss: 0.1572\n",
      "Epoch [92/100], Step [90/111], Loss: 0.1258\n",
      "Epoch [92/100], Step [92/111], Loss: 0.1842\n",
      "Epoch [92/100], Step [94/111], Loss: 0.2444\n",
      "Epoch [92/100], Step [96/111], Loss: 0.1955\n",
      "Epoch [92/100], Step [98/111], Loss: 0.1535\n",
      "Epoch [92/100], Step [100/111], Loss: 0.1555\n",
      "Epoch [92/100], Step [102/111], Loss: 0.1360\n",
      "Epoch [92/100], Step [104/111], Loss: 0.2241\n",
      "Epoch [92/100], Step [106/111], Loss: 0.1436\n",
      "Epoch [92/100], Step [108/111], Loss: 0.1710\n",
      "Epoch [92/100], Step [110/111], Loss: 0.1602\n",
      "Epoch [93/100], Step [2/111], Loss: 0.2338\n",
      "Epoch [93/100], Step [4/111], Loss: 1.5508\n",
      "Epoch [93/100], Step [6/111], Loss: 0.1764\n",
      "Epoch [93/100], Step [8/111], Loss: 0.1601\n",
      "Epoch [93/100], Step [10/111], Loss: 0.2051\n",
      "Epoch [93/100], Step [12/111], Loss: 0.2005\n",
      "Epoch [93/100], Step [14/111], Loss: 0.2668\n",
      "Epoch [93/100], Step [16/111], Loss: 0.1933\n",
      "Epoch [93/100], Step [18/111], Loss: 0.2346\n",
      "Epoch [93/100], Step [20/111], Loss: 0.5576\n",
      "Epoch [93/100], Step [22/111], Loss: 0.1880\n",
      "Epoch [93/100], Step [24/111], Loss: 0.2944\n",
      "Epoch [93/100], Step [26/111], Loss: 0.2553\n",
      "Epoch [93/100], Step [28/111], Loss: 0.1972\n",
      "Epoch [93/100], Step [30/111], Loss: 0.2519\n",
      "Epoch [93/100], Step [32/111], Loss: 0.2137\n",
      "Epoch [93/100], Step [34/111], Loss: 0.2359\n",
      "Epoch [93/100], Step [36/111], Loss: 0.1765\n",
      "Epoch [93/100], Step [38/111], Loss: 0.1496\n",
      "Epoch [93/100], Step [40/111], Loss: 0.1914\n",
      "Epoch [93/100], Step [42/111], Loss: 0.2407\n",
      "Epoch [93/100], Step [44/111], Loss: 0.1612\n",
      "Epoch [93/100], Step [46/111], Loss: 0.2198\n",
      "Epoch [93/100], Step [48/111], Loss: 0.1767\n",
      "Epoch [93/100], Step [50/111], Loss: 0.2206\n",
      "Epoch [93/100], Step [52/111], Loss: 0.1496\n",
      "Epoch [93/100], Step [54/111], Loss: 0.2238\n",
      "Epoch [93/100], Step [56/111], Loss: 0.1332\n",
      "Epoch [93/100], Step [58/111], Loss: 0.2113\n",
      "Epoch [93/100], Step [60/111], Loss: 0.2198\n",
      "Epoch [93/100], Step [62/111], Loss: 0.2694\n",
      "Epoch [93/100], Step [64/111], Loss: 0.2062\n",
      "Epoch [93/100], Step [66/111], Loss: 0.2312\n",
      "Epoch [93/100], Step [68/111], Loss: 0.1914\n",
      "Epoch [93/100], Step [70/111], Loss: 0.1432\n",
      "Epoch [93/100], Step [72/111], Loss: 0.1556\n",
      "Epoch [93/100], Step [74/111], Loss: 0.2168\n",
      "Epoch [93/100], Step [76/111], Loss: 0.1293\n",
      "Epoch [93/100], Step [78/111], Loss: 0.2402\n",
      "Epoch [93/100], Step [80/111], Loss: 0.1204\n",
      "Epoch [93/100], Step [82/111], Loss: 0.1904\n",
      "Epoch [93/100], Step [84/111], Loss: 0.1473\n",
      "Epoch [93/100], Step [86/111], Loss: 0.1578\n",
      "Epoch [93/100], Step [88/111], Loss: 0.2024\n",
      "Epoch [93/100], Step [90/111], Loss: 0.1867\n",
      "Epoch [93/100], Step [92/111], Loss: 0.1476\n",
      "Epoch [93/100], Step [94/111], Loss: 0.1511\n",
      "Epoch [93/100], Step [96/111], Loss: 0.1081\n",
      "Epoch [93/100], Step [98/111], Loss: 0.2635\n",
      "Epoch [93/100], Step [100/111], Loss: 0.1673\n",
      "Epoch [93/100], Step [102/111], Loss: 0.1679\n",
      "Epoch [93/100], Step [104/111], Loss: 0.1046\n",
      "Epoch [93/100], Step [106/111], Loss: 0.1965\n",
      "Epoch [93/100], Step [108/111], Loss: 0.1173\n",
      "Epoch [93/100], Step [110/111], Loss: 0.1012\n",
      "Epoch [94/100], Step [2/111], Loss: 0.1481\n",
      "Epoch [94/100], Step [4/111], Loss: 0.1660\n",
      "Epoch [94/100], Step [6/111], Loss: 0.1701\n",
      "Epoch [94/100], Step [8/111], Loss: 0.1434\n",
      "Epoch [94/100], Step [10/111], Loss: 0.8884\n",
      "Epoch [94/100], Step [12/111], Loss: 0.1166\n",
      "Epoch [94/100], Step [14/111], Loss: 0.1459\n",
      "Epoch [94/100], Step [16/111], Loss: 0.1498\n",
      "Epoch [94/100], Step [18/111], Loss: 0.1796\n",
      "Epoch [94/100], Step [20/111], Loss: 0.2630\n",
      "Epoch [94/100], Step [22/111], Loss: 0.1448\n",
      "Epoch [94/100], Step [24/111], Loss: 0.1899\n",
      "Epoch [94/100], Step [26/111], Loss: 1.9615\n",
      "Epoch [94/100], Step [28/111], Loss: 0.2612\n",
      "Epoch [94/100], Step [30/111], Loss: 0.1574\n",
      "Epoch [94/100], Step [32/111], Loss: 0.1557\n",
      "Epoch [94/100], Step [34/111], Loss: 0.2131\n",
      "Epoch [94/100], Step [36/111], Loss: 0.1437\n",
      "Epoch [94/100], Step [38/111], Loss: 0.1307\n",
      "Epoch [94/100], Step [40/111], Loss: 0.1238\n",
      "Epoch [94/100], Step [42/111], Loss: 0.1852\n",
      "Epoch [94/100], Step [44/111], Loss: 0.1519\n",
      "Epoch [94/100], Step [46/111], Loss: 0.2082\n",
      "Epoch [94/100], Step [48/111], Loss: 0.2172\n",
      "Epoch [94/100], Step [50/111], Loss: 0.1625\n",
      "Epoch [94/100], Step [52/111], Loss: 0.2007\n",
      "Epoch [94/100], Step [54/111], Loss: 0.1540\n",
      "Epoch [94/100], Step [56/111], Loss: 0.1190\n",
      "Epoch [94/100], Step [58/111], Loss: 0.1727\n",
      "Epoch [94/100], Step [60/111], Loss: 0.1513\n",
      "Epoch [94/100], Step [62/111], Loss: 1.8241\n",
      "Epoch [94/100], Step [64/111], Loss: 0.1735\n",
      "Epoch [94/100], Step [66/111], Loss: 0.1659\n",
      "Epoch [94/100], Step [68/111], Loss: 0.1677\n",
      "Epoch [94/100], Step [70/111], Loss: 0.1185\n",
      "Epoch [94/100], Step [72/111], Loss: 3.0712\n",
      "Epoch [94/100], Step [74/111], Loss: 0.1894\n",
      "Epoch [94/100], Step [76/111], Loss: 0.1761\n",
      "Epoch [94/100], Step [78/111], Loss: 0.1289\n",
      "Epoch [94/100], Step [80/111], Loss: 0.1930\n",
      "Epoch [94/100], Step [82/111], Loss: 0.1725\n",
      "Epoch [94/100], Step [84/111], Loss: 0.1579\n",
      "Epoch [94/100], Step [86/111], Loss: 0.1379\n",
      "Epoch [94/100], Step [88/111], Loss: 0.3137\n",
      "Epoch [94/100], Step [90/111], Loss: 0.1506\n",
      "Epoch [94/100], Step [92/111], Loss: 0.1531\n",
      "Epoch [94/100], Step [94/111], Loss: 0.1229\n",
      "Epoch [94/100], Step [96/111], Loss: 0.1844\n",
      "Epoch [94/100], Step [98/111], Loss: 0.1338\n",
      "Epoch [94/100], Step [100/111], Loss: 0.4734\n",
      "Epoch [94/100], Step [102/111], Loss: 0.1976\n",
      "Epoch [94/100], Step [104/111], Loss: 0.2317\n",
      "Epoch [94/100], Step [106/111], Loss: 0.1455\n",
      "Epoch [94/100], Step [108/111], Loss: 0.1882\n",
      "Epoch [94/100], Step [110/111], Loss: 0.2731\n",
      "Epoch [95/100], Step [2/111], Loss: 0.2012\n",
      "Epoch [95/100], Step [4/111], Loss: 0.1907\n",
      "Epoch [95/100], Step [6/111], Loss: 0.3478\n",
      "Epoch [95/100], Step [8/111], Loss: 0.1613\n",
      "Epoch [95/100], Step [10/111], Loss: 0.1382\n",
      "Epoch [95/100], Step [12/111], Loss: 0.1782\n",
      "Epoch [95/100], Step [14/111], Loss: 0.1144\n",
      "Epoch [95/100], Step [16/111], Loss: 0.1525\n",
      "Epoch [95/100], Step [18/111], Loss: 0.1121\n",
      "Epoch [95/100], Step [20/111], Loss: 0.1978\n",
      "Epoch [95/100], Step [22/111], Loss: 0.1390\n",
      "Epoch [95/100], Step [24/111], Loss: 0.2071\n",
      "Epoch [95/100], Step [26/111], Loss: 0.1894\n",
      "Epoch [95/100], Step [28/111], Loss: 0.6131\n",
      "Epoch [95/100], Step [30/111], Loss: 0.1489\n",
      "Epoch [95/100], Step [32/111], Loss: 0.2418\n",
      "Epoch [95/100], Step [34/111], Loss: 0.0990\n",
      "Epoch [95/100], Step [36/111], Loss: 0.1596\n",
      "Epoch [95/100], Step [38/111], Loss: 0.2691\n",
      "Epoch [95/100], Step [40/111], Loss: 0.2810\n",
      "Epoch [95/100], Step [42/111], Loss: 0.1558\n",
      "Epoch [95/100], Step [44/111], Loss: 0.2737\n",
      "Epoch [95/100], Step [46/111], Loss: 2.0031\n",
      "Epoch [95/100], Step [48/111], Loss: 0.2452\n",
      "Epoch [95/100], Step [50/111], Loss: 0.2691\n",
      "Epoch [95/100], Step [52/111], Loss: 0.2283\n",
      "Epoch [95/100], Step [54/111], Loss: 0.2239\n",
      "Epoch [95/100], Step [56/111], Loss: 0.1831\n",
      "Epoch [95/100], Step [58/111], Loss: 0.2057\n",
      "Epoch [95/100], Step [60/111], Loss: 0.1636\n",
      "Epoch [95/100], Step [62/111], Loss: 0.1214\n",
      "Epoch [95/100], Step [64/111], Loss: 0.1938\n",
      "Epoch [95/100], Step [66/111], Loss: 0.1766\n",
      "Epoch [95/100], Step [68/111], Loss: 0.2218\n",
      "Epoch [95/100], Step [70/111], Loss: 0.1464\n",
      "Epoch [95/100], Step [72/111], Loss: 0.1376\n",
      "Epoch [95/100], Step [74/111], Loss: 0.1531\n",
      "Epoch [95/100], Step [76/111], Loss: 0.1632\n",
      "Epoch [95/100], Step [78/111], Loss: 0.2356\n",
      "Epoch [95/100], Step [80/111], Loss: 0.2138\n",
      "Epoch [95/100], Step [82/111], Loss: 0.1156\n",
      "Epoch [95/100], Step [84/111], Loss: 0.1307\n",
      "Epoch [95/100], Step [86/111], Loss: 0.1692\n",
      "Epoch [95/100], Step [88/111], Loss: 0.1442\n",
      "Epoch [95/100], Step [90/111], Loss: 0.1596\n",
      "Epoch [95/100], Step [92/111], Loss: 0.1518\n",
      "Epoch [95/100], Step [94/111], Loss: 0.1751\n",
      "Epoch [95/100], Step [96/111], Loss: 0.1630\n",
      "Epoch [95/100], Step [98/111], Loss: 0.1238\n",
      "Epoch [95/100], Step [100/111], Loss: 0.2226\n",
      "Epoch [95/100], Step [102/111], Loss: 0.1520\n",
      "Epoch [95/100], Step [104/111], Loss: 0.1591\n",
      "Epoch [95/100], Step [106/111], Loss: 0.2109\n",
      "Epoch [95/100], Step [108/111], Loss: 0.1332\n",
      "Epoch [95/100], Step [110/111], Loss: 0.2092\n",
      "Epoch [96/100], Step [2/111], Loss: 0.2582\n",
      "Epoch [96/100], Step [4/111], Loss: 0.2203\n",
      "Epoch [96/100], Step [6/111], Loss: 1.9690\n",
      "Epoch [96/100], Step [8/111], Loss: 0.2168\n",
      "Epoch [96/100], Step [10/111], Loss: 0.2650\n",
      "Epoch [96/100], Step [12/111], Loss: 0.1419\n",
      "Epoch [96/100], Step [14/111], Loss: 0.2847\n",
      "Epoch [96/100], Step [16/111], Loss: 0.1816\n",
      "Epoch [96/100], Step [18/111], Loss: 0.1230\n",
      "Epoch [96/100], Step [20/111], Loss: 0.1223\n",
      "Epoch [96/100], Step [22/111], Loss: 0.2165\n",
      "Epoch [96/100], Step [24/111], Loss: 0.1137\n",
      "Epoch [96/100], Step [26/111], Loss: 0.1178\n",
      "Epoch [96/100], Step [28/111], Loss: 3.1364\n",
      "Epoch [96/100], Step [30/111], Loss: 0.1398\n",
      "Epoch [96/100], Step [32/111], Loss: 0.1841\n",
      "Epoch [96/100], Step [34/111], Loss: 0.2204\n",
      "Epoch [96/100], Step [36/111], Loss: 0.1439\n",
      "Epoch [96/100], Step [38/111], Loss: 0.2210\n",
      "Epoch [96/100], Step [40/111], Loss: 0.1447\n",
      "Epoch [96/100], Step [42/111], Loss: 0.1226\n",
      "Epoch [96/100], Step [44/111], Loss: 0.1640\n",
      "Epoch [96/100], Step [46/111], Loss: 0.1450\n",
      "Epoch [96/100], Step [48/111], Loss: 0.1765\n",
      "Epoch [96/100], Step [50/111], Loss: 0.1109\n",
      "Epoch [96/100], Step [52/111], Loss: 0.1625\n",
      "Epoch [96/100], Step [54/111], Loss: 0.2435\n",
      "Epoch [96/100], Step [56/111], Loss: 0.1701\n",
      "Epoch [96/100], Step [58/111], Loss: 0.1724\n",
      "Epoch [96/100], Step [60/111], Loss: 0.2065\n",
      "Epoch [96/100], Step [62/111], Loss: 0.1424\n",
      "Epoch [96/100], Step [64/111], Loss: 0.1632\n",
      "Epoch [96/100], Step [66/111], Loss: 0.1724\n",
      "Epoch [96/100], Step [68/111], Loss: 0.1880\n",
      "Epoch [96/100], Step [70/111], Loss: 0.1649\n",
      "Epoch [96/100], Step [72/111], Loss: 3.4910\n",
      "Epoch [96/100], Step [74/111], Loss: 0.1688\n",
      "Epoch [96/100], Step [76/111], Loss: 0.1542\n",
      "Epoch [96/100], Step [78/111], Loss: 0.1704\n",
      "Epoch [96/100], Step [80/111], Loss: 0.1952\n",
      "Epoch [96/100], Step [82/111], Loss: 0.2085\n",
      "Epoch [96/100], Step [84/111], Loss: 0.1799\n",
      "Epoch [96/100], Step [86/111], Loss: 0.2342\n",
      "Epoch [96/100], Step [88/111], Loss: 0.1723\n",
      "Epoch [96/100], Step [90/111], Loss: 0.1959\n",
      "Epoch [96/100], Step [92/111], Loss: 0.1780\n",
      "Epoch [96/100], Step [94/111], Loss: 0.1492\n",
      "Epoch [96/100], Step [96/111], Loss: 0.1567\n",
      "Epoch [96/100], Step [98/111], Loss: 0.1822\n",
      "Epoch [96/100], Step [100/111], Loss: 0.1083\n",
      "Epoch [96/100], Step [102/111], Loss: 0.1883\n",
      "Epoch [96/100], Step [104/111], Loss: 0.1545\n",
      "Epoch [96/100], Step [106/111], Loss: 0.1688\n",
      "Epoch [96/100], Step [108/111], Loss: 0.1693\n",
      "Epoch [96/100], Step [110/111], Loss: 0.1673\n",
      "Epoch [97/100], Step [2/111], Loss: 0.1995\n",
      "Epoch [97/100], Step [4/111], Loss: 0.1437\n",
      "Epoch [97/100], Step [6/111], Loss: 0.1964\n",
      "Epoch [97/100], Step [8/111], Loss: 3.4943\n",
      "Epoch [97/100], Step [10/111], Loss: 0.2278\n",
      "Epoch [97/100], Step [12/111], Loss: 0.1811\n",
      "Epoch [97/100], Step [14/111], Loss: 0.1164\n",
      "Epoch [97/100], Step [16/111], Loss: 0.2197\n",
      "Epoch [97/100], Step [18/111], Loss: 0.1392\n",
      "Epoch [97/100], Step [20/111], Loss: 0.1631\n",
      "Epoch [97/100], Step [22/111], Loss: 0.1427\n",
      "Epoch [97/100], Step [24/111], Loss: 0.1436\n",
      "Epoch [97/100], Step [26/111], Loss: 3.0995\n",
      "Epoch [97/100], Step [28/111], Loss: 0.1303\n",
      "Epoch [97/100], Step [30/111], Loss: 0.1405\n",
      "Epoch [97/100], Step [32/111], Loss: 0.1367\n",
      "Epoch [97/100], Step [34/111], Loss: 0.2063\n",
      "Epoch [97/100], Step [36/111], Loss: 0.1660\n",
      "Epoch [97/100], Step [38/111], Loss: 0.1211\n",
      "Epoch [97/100], Step [40/111], Loss: 0.1481\n",
      "Epoch [97/100], Step [42/111], Loss: 0.0949\n",
      "Epoch [97/100], Step [44/111], Loss: 0.0995\n",
      "Epoch [97/100], Step [46/111], Loss: 0.1312\n",
      "Epoch [97/100], Step [48/111], Loss: 0.1547\n",
      "Epoch [97/100], Step [50/111], Loss: 0.1654\n",
      "Epoch [97/100], Step [52/111], Loss: 0.1273\n",
      "Epoch [97/100], Step [54/111], Loss: 0.1904\n",
      "Epoch [97/100], Step [56/111], Loss: 0.2397\n",
      "Epoch [97/100], Step [58/111], Loss: 0.1451\n",
      "Epoch [97/100], Step [60/111], Loss: 0.2183\n",
      "Epoch [97/100], Step [62/111], Loss: 0.1224\n",
      "Epoch [97/100], Step [64/111], Loss: 0.2496\n",
      "Epoch [97/100], Step [66/111], Loss: 0.1069\n",
      "Epoch [97/100], Step [68/111], Loss: 0.2065\n",
      "Epoch [97/100], Step [70/111], Loss: 0.1774\n",
      "Epoch [97/100], Step [72/111], Loss: 0.1189\n",
      "Epoch [97/100], Step [74/111], Loss: 0.1515\n",
      "Epoch [97/100], Step [76/111], Loss: 0.2092\n",
      "Epoch [97/100], Step [78/111], Loss: 0.1578\n",
      "Epoch [97/100], Step [80/111], Loss: 0.1781\n",
      "Epoch [97/100], Step [82/111], Loss: 0.1547\n",
      "Epoch [97/100], Step [84/111], Loss: 0.1869\n",
      "Epoch [97/100], Step [86/111], Loss: 0.1977\n",
      "Epoch [97/100], Step [88/111], Loss: 0.3478\n",
      "Epoch [97/100], Step [90/111], Loss: 0.1667\n",
      "Epoch [97/100], Step [92/111], Loss: 0.2256\n",
      "Epoch [97/100], Step [94/111], Loss: 0.2206\n",
      "Epoch [97/100], Step [96/111], Loss: 0.1305\n",
      "Epoch [97/100], Step [98/111], Loss: 0.2029\n",
      "Epoch [97/100], Step [100/111], Loss: 0.2000\n",
      "Epoch [97/100], Step [102/111], Loss: 0.1709\n",
      "Epoch [97/100], Step [104/111], Loss: 0.1488\n",
      "Epoch [97/100], Step [106/111], Loss: 0.2363\n",
      "Epoch [97/100], Step [108/111], Loss: 0.1953\n",
      "Epoch [97/100], Step [110/111], Loss: 3.1782\n",
      "Epoch [98/100], Step [2/111], Loss: 0.1433\n",
      "Epoch [98/100], Step [4/111], Loss: 0.3826\n",
      "Epoch [98/100], Step [6/111], Loss: 0.2324\n",
      "Epoch [98/100], Step [8/111], Loss: 0.2286\n",
      "Epoch [98/100], Step [10/111], Loss: 0.1493\n",
      "Epoch [98/100], Step [12/111], Loss: 0.2725\n",
      "Epoch [98/100], Step [14/111], Loss: 0.1649\n",
      "Epoch [98/100], Step [16/111], Loss: 0.2504\n",
      "Epoch [98/100], Step [18/111], Loss: 0.2562\n",
      "Epoch [98/100], Step [20/111], Loss: 0.2018\n",
      "Epoch [98/100], Step [22/111], Loss: 0.1583\n",
      "Epoch [98/100], Step [24/111], Loss: 0.1315\n",
      "Epoch [98/100], Step [26/111], Loss: 0.1432\n",
      "Epoch [98/100], Step [28/111], Loss: 0.1113\n",
      "Epoch [98/100], Step [30/111], Loss: 0.1556\n",
      "Epoch [98/100], Step [32/111], Loss: 0.1245\n",
      "Epoch [98/100], Step [34/111], Loss: 0.1680\n",
      "Epoch [98/100], Step [36/111], Loss: 0.1427\n",
      "Epoch [98/100], Step [38/111], Loss: 0.1862\n",
      "Epoch [98/100], Step [40/111], Loss: 2.2872\n",
      "Epoch [98/100], Step [42/111], Loss: 0.1087\n",
      "Epoch [98/100], Step [44/111], Loss: 0.1858\n",
      "Epoch [98/100], Step [46/111], Loss: 3.9647\n",
      "Epoch [98/100], Step [48/111], Loss: 0.1288\n",
      "Epoch [98/100], Step [50/111], Loss: 0.1427\n",
      "Epoch [98/100], Step [52/111], Loss: 0.1257\n",
      "Epoch [98/100], Step [54/111], Loss: 0.1204\n",
      "Epoch [98/100], Step [56/111], Loss: 0.2371\n",
      "Epoch [98/100], Step [58/111], Loss: 0.2214\n",
      "Epoch [98/100], Step [60/111], Loss: 0.1732\n",
      "Epoch [98/100], Step [62/111], Loss: 0.2164\n",
      "Epoch [98/100], Step [64/111], Loss: 0.1292\n",
      "Epoch [98/100], Step [66/111], Loss: 0.2200\n",
      "Epoch [98/100], Step [68/111], Loss: 0.2888\n",
      "Epoch [98/100], Step [70/111], Loss: 0.1696\n",
      "Epoch [98/100], Step [72/111], Loss: 0.2054\n",
      "Epoch [98/100], Step [74/111], Loss: 0.1205\n",
      "Epoch [98/100], Step [76/111], Loss: 0.1484\n",
      "Epoch [98/100], Step [78/111], Loss: 0.1746\n",
      "Epoch [98/100], Step [80/111], Loss: 0.1956\n",
      "Epoch [98/100], Step [82/111], Loss: 0.1937\n",
      "Epoch [98/100], Step [84/111], Loss: 0.1461\n",
      "Epoch [98/100], Step [86/111], Loss: 0.1704\n",
      "Epoch [98/100], Step [88/111], Loss: 0.1636\n",
      "Epoch [98/100], Step [90/111], Loss: 0.1762\n",
      "Epoch [98/100], Step [92/111], Loss: 0.1800\n",
      "Epoch [98/100], Step [94/111], Loss: 0.1161\n",
      "Epoch [98/100], Step [96/111], Loss: 0.1375\n",
      "Epoch [98/100], Step [98/111], Loss: 0.1472\n",
      "Epoch [98/100], Step [100/111], Loss: 0.1347\n",
      "Epoch [98/100], Step [102/111], Loss: 0.2576\n",
      "Epoch [98/100], Step [104/111], Loss: 0.1318\n",
      "Epoch [98/100], Step [106/111], Loss: 0.1295\n",
      "Epoch [98/100], Step [108/111], Loss: 0.1920\n",
      "Epoch [98/100], Step [110/111], Loss: 0.2144\n",
      "Epoch [99/100], Step [2/111], Loss: 0.1699\n",
      "Epoch [99/100], Step [4/111], Loss: 0.1319\n",
      "Epoch [99/100], Step [6/111], Loss: 0.1728\n",
      "Epoch [99/100], Step [8/111], Loss: 0.1790\n",
      "Epoch [99/100], Step [10/111], Loss: 0.1388\n",
      "Epoch [99/100], Step [12/111], Loss: 0.2075\n",
      "Epoch [99/100], Step [14/111], Loss: 0.1273\n",
      "Epoch [99/100], Step [16/111], Loss: 0.1056\n",
      "Epoch [99/100], Step [18/111], Loss: 0.1015\n",
      "Epoch [99/100], Step [20/111], Loss: 0.1523\n",
      "Epoch [99/100], Step [22/111], Loss: 0.1190\n",
      "Epoch [99/100], Step [24/111], Loss: 0.1333\n",
      "Epoch [99/100], Step [26/111], Loss: 0.1590\n",
      "Epoch [99/100], Step [28/111], Loss: 0.1578\n",
      "Epoch [99/100], Step [30/111], Loss: 0.1713\n",
      "Epoch [99/100], Step [32/111], Loss: 0.1666\n",
      "Epoch [99/100], Step [34/111], Loss: 0.1591\n",
      "Epoch [99/100], Step [36/111], Loss: 0.2314\n",
      "Epoch [99/100], Step [38/111], Loss: 0.2121\n",
      "Epoch [99/100], Step [40/111], Loss: 0.1482\n",
      "Epoch [99/100], Step [42/111], Loss: 0.1165\n",
      "Epoch [99/100], Step [44/111], Loss: 0.1458\n",
      "Epoch [99/100], Step [46/111], Loss: 0.1395\n",
      "Epoch [99/100], Step [48/111], Loss: 0.1594\n",
      "Epoch [99/100], Step [50/111], Loss: 0.1714\n",
      "Epoch [99/100], Step [52/111], Loss: 0.1197\n",
      "Epoch [99/100], Step [54/111], Loss: 0.1294\n",
      "Epoch [99/100], Step [56/111], Loss: 0.1056\n",
      "Epoch [99/100], Step [58/111], Loss: 0.1234\n",
      "Epoch [99/100], Step [60/111], Loss: 0.1873\n",
      "Epoch [99/100], Step [62/111], Loss: 0.1477\n",
      "Epoch [99/100], Step [64/111], Loss: 0.1611\n",
      "Epoch [99/100], Step [66/111], Loss: 0.1830\n",
      "Epoch [99/100], Step [68/111], Loss: 0.1302\n",
      "Epoch [99/100], Step [70/111], Loss: 0.1259\n",
      "Epoch [99/100], Step [72/111], Loss: 0.1757\n",
      "Epoch [99/100], Step [74/111], Loss: 2.6914\n",
      "Epoch [99/100], Step [76/111], Loss: 0.2483\n",
      "Epoch [99/100], Step [78/111], Loss: 0.1864\n",
      "Epoch [99/100], Step [80/111], Loss: 0.1928\n",
      "Epoch [99/100], Step [82/111], Loss: 0.1280\n",
      "Epoch [99/100], Step [84/111], Loss: 0.1796\n",
      "Epoch [99/100], Step [86/111], Loss: 0.1824\n",
      "Epoch [99/100], Step [88/111], Loss: 0.1745\n",
      "Epoch [99/100], Step [90/111], Loss: 0.2281\n",
      "Epoch [99/100], Step [92/111], Loss: 0.1640\n",
      "Epoch [99/100], Step [94/111], Loss: 0.1474\n",
      "Epoch [99/100], Step [96/111], Loss: 0.1676\n",
      "Epoch [99/100], Step [98/111], Loss: 0.1121\n",
      "Epoch [99/100], Step [100/111], Loss: 0.1813\n",
      "Epoch [99/100], Step [102/111], Loss: 0.1659\n",
      "Epoch [99/100], Step [104/111], Loss: 0.1416\n",
      "Epoch [99/100], Step [106/111], Loss: 0.1861\n",
      "Epoch [99/100], Step [108/111], Loss: 0.1371\n",
      "Epoch [99/100], Step [110/111], Loss: 0.1334\n",
      "Epoch [100/100], Step [2/111], Loss: 0.1069\n",
      "Epoch [100/100], Step [4/111], Loss: 0.2092\n",
      "Epoch [100/100], Step [6/111], Loss: 0.1966\n",
      "Epoch [100/100], Step [8/111], Loss: 0.1312\n",
      "Epoch [100/100], Step [10/111], Loss: 0.1708\n",
      "Epoch [100/100], Step [12/111], Loss: 0.1628\n",
      "Epoch [100/100], Step [14/111], Loss: 0.1791\n",
      "Epoch [100/100], Step [16/111], Loss: 0.1223\n",
      "Epoch [100/100], Step [18/111], Loss: 0.2000\n",
      "Epoch [100/100], Step [20/111], Loss: 0.1145\n",
      "Epoch [100/100], Step [22/111], Loss: 0.1463\n",
      "Epoch [100/100], Step [24/111], Loss: 0.1785\n",
      "Epoch [100/100], Step [26/111], Loss: 0.1384\n",
      "Epoch [100/100], Step [28/111], Loss: 0.1767\n",
      "Epoch [100/100], Step [30/111], Loss: 0.1385\n",
      "Epoch [100/100], Step [32/111], Loss: 0.1895\n",
      "Epoch [100/100], Step [34/111], Loss: 0.1253\n",
      "Epoch [100/100], Step [36/111], Loss: 0.1285\n",
      "Epoch [100/100], Step [38/111], Loss: 0.1242\n",
      "Epoch [100/100], Step [40/111], Loss: 0.1255\n",
      "Epoch [100/100], Step [42/111], Loss: 0.1665\n",
      "Epoch [100/100], Step [44/111], Loss: 0.1479\n",
      "Epoch [100/100], Step [46/111], Loss: 0.1228\n",
      "Epoch [100/100], Step [48/111], Loss: 0.1199\n",
      "Epoch [100/100], Step [50/111], Loss: 0.1928\n",
      "Epoch [100/100], Step [52/111], Loss: 0.1270\n",
      "Epoch [100/100], Step [54/111], Loss: 0.1495\n",
      "Epoch [100/100], Step [56/111], Loss: 0.1463\n",
      "Epoch [100/100], Step [58/111], Loss: 0.1542\n",
      "Epoch [100/100], Step [60/111], Loss: 0.1621\n",
      "Epoch [100/100], Step [62/111], Loss: 0.1576\n",
      "Epoch [100/100], Step [64/111], Loss: 0.1059\n",
      "Epoch [100/100], Step [66/111], Loss: 0.1304\n",
      "Epoch [100/100], Step [68/111], Loss: 0.1149\n",
      "Epoch [100/100], Step [70/111], Loss: 0.1710\n",
      "Epoch [100/100], Step [72/111], Loss: 0.1075\n",
      "Epoch [100/100], Step [74/111], Loss: 0.1500\n",
      "Epoch [100/100], Step [76/111], Loss: 0.1328\n",
      "Epoch [100/100], Step [78/111], Loss: 0.1165\n",
      "Epoch [100/100], Step [80/111], Loss: 0.0921\n",
      "Epoch [100/100], Step [82/111], Loss: 0.1221\n",
      "Epoch [100/100], Step [84/111], Loss: 0.1178\n",
      "Epoch [100/100], Step [86/111], Loss: 0.1512\n",
      "Epoch [100/100], Step [88/111], Loss: 0.1540\n",
      "Epoch [100/100], Step [90/111], Loss: 0.1951\n",
      "Epoch [100/100], Step [92/111], Loss: 0.1347\n",
      "Epoch [100/100], Step [94/111], Loss: 0.1230\n",
      "Epoch [100/100], Step [96/111], Loss: 0.1782\n",
      "Epoch [100/100], Step [98/111], Loss: 0.2335\n",
      "Epoch [100/100], Step [100/111], Loss: 0.1406\n",
      "Epoch [100/100], Step [102/111], Loss: 0.1382\n",
      "Epoch [100/100], Step [104/111], Loss: 0.1900\n",
      "Epoch [100/100], Step [106/111], Loss: 0.1731\n",
      "Epoch [100/100], Step [108/111], Loss: 0.2115\n",
      "Epoch [100/100], Step [110/111], Loss: 0.2457\n"
     ]
    }
   ],
   "source": [
    "#train the model\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        #forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        #backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (i+1) % 2 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
    "                  .format(epoch+1, epochs, i+1, len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8083148c435d231f703449331507e72b23a2d1daf1c5ab6243dbd5548bf4abd5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
